{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassificationModel_Wine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D5MXeNqXMXe6",
        "umwZABDXo4FT",
        "6sMVEJYkt6hO",
        "uyPkgYySwlGS",
        "aH9nWFQq2zd3",
        "nCo55yH45zx2",
        "ktMf2VVrARVH"
      ],
      "history_visible": true,
      "authorship_tag": "ABX9TyPXNC3u6YXAyVznojHJ/3/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZefraAlseif/Project1_Wine_Network/blob/main/ClassificationModel_Wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adapting the original wine data to a regression model and classification model"
      ],
      "metadata": {
        "id": "D5MXeNqXMXe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data as Numpy Arrays\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# This time we need to also import pandas\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Read in white wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
        "\n",
        "# Read in red wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep =';')\n",
        "\n",
        "red['type'] = 1\n",
        "white['type'] = 0\n",
        "\n",
        "wines = red.append(white, ignore_index = True)\n",
        "\n",
        "# Import SKLEARN\n",
        "import sklearn\n",
        "\n",
        "# Import `train_test_split` from `sklearn.model_selection`\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Specify the data -\n",
        "X1 = wines.iloc[:, 0:11]\n",
        "X2 = wines.iloc[:,12]\n",
        "X = pd.concat([X1,X2],axis = 1)\n",
        "\n",
        "y = np.ravel(wines.quality)\n",
        "\n",
        "# Splitting the data set for training and validating - Done with SKLEARN\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = 0.25, random_state = 45)\n",
        "\n",
        "# Converting X_train & X_test DataFrame s to TF sensors\n",
        "# Will use NumPy, TF, & Keras after this\n",
        "# import tensorflow as tf\n",
        "\n",
        "Xtrain = X_train.to_numpy()\n",
        "X_valid = X_valid.to_numpy()\n",
        "\n",
        "X_valid\n",
        "# In reality:\n",
        "# [1] ALL THE Xtrain patterns (with their y_train targets)\n",
        "# will be used for TRAINING ([TR]), as Xtrain & y_train\n",
        "# [2] MOST OF THE X_valid patterns (and their y_valid targets)\n",
        "# will be used for VALIDATION ([TT]), as X_val & y_val\n",
        "# BUT WE WILL SET ASIDE THE LAST 10 for \"testing\" ([TS])\n",
        "# as X_tst & y_tst\n",
        "\n",
        "# Retain the first 1615 patterns for validation ([TT])\n",
        "Xval = X_valid[:1615]\n",
        "Xval.shape\n",
        "\n",
        "# and now set aside the last 10 for test\n",
        "Xtst = X_valid[1615:]\n",
        "Xtst.shape\n",
        "\n",
        "# Same for the corresponding targets\n",
        "# Retain the first 1615 for validation ([TT])\n",
        "y_val = y_valid[:1615]\n",
        "y_val.shape\n",
        "\n",
        "y_tst = y_valid[1615:]\n",
        "y_tst.shape \n",
        "y_tst\n",
        "\n",
        "# Now, in addition, create the targets as one-hot-encoded 4 quality levels\n",
        "# We will track these few targets through the conversion process\n",
        "y_train[272:283]\n",
        "\n",
        "# Function create rank-1 arrays where 3,4,5,6,7,8,9 are mapped to 1 or 2 or 3 or 4 \n",
        "def to_4cs(x):\n",
        "  lx = len(x)\n",
        "  results = np.zeros(lx)\n",
        "  for i in range(lx):\n",
        "    # print(\"start\")\n",
        "    xa = x[i];\n",
        "    if xa <= 3:\n",
        "      results[i] = 1\n",
        "    elif xa <= 6:\n",
        "      results[i] = 2\n",
        "    elif xa <= 8:\n",
        "      results[i] = 3\n",
        "    else:\n",
        "      results[i] = 4\n",
        "    # results [i, label] = 1\n",
        "  results = results.astype(int)\n",
        "  return results\n",
        "\n",
        "train_labels = to_4cs(y_train)\n",
        "val_labels = to_4cs(y_val)\n",
        "tst_labels = to_4cs(y_tst)\n",
        "\n",
        "# Let's verify that the training targets that we are tracking \n",
        "# were converted to levels (1 = BAD; 2 = Medium; 3 = GOOD; 4- Excellent) correctly:\n",
        "train_labels[272:283]\n",
        "\n",
        "# Now, one shot encoding of all 3 target arrays\n",
        "# define a function to do the \n",
        "\n",
        "def to_one_hot(labels, dimension = 4):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels-1):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_val_labels = to_one_hot(val_labels)\n",
        "one_hot_tst_labels = to_one_hot(tst_labels)\n",
        "\n",
        "#Let's verify that the training targets we have tracked were\n",
        "# one-hot encoded correctly\n",
        "Xtrain.shape\n",
        "\n",
        "# SO, AFTER EXECUTING THIS CELL, YOU WILL HAVE:\n",
        "# FOR TRAINING:\n",
        "# Xtrain (4872, 12)...y_train (4872,)...train_labels(4872,)....one_hot_train_labels (4872,4)\n",
        "# FOR VALIDATING:\n",
        "# Xval (1615, 12)...y_val (1615,)...val_labels(1615,)...one_hot_val_labels (1615,4)\n",
        "# FOR TESTING:\n",
        "# Xtst (10, 12)...y_tst (10,)...tst_labels(10,)... one_hot_tst_labels (10,4)\n",
        "# PLEASE DO NOT CHANGE THE NAMES OF THESE VARIABLES (So that instructor can use them)\n"
      ],
      "metadata": {
        "id": "RALOila3bW_c",
        "cellView": "code",
        "outputId": "e5ea8347-3437-4488-afb2-6b9f1472a8b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4872, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NrLabofBokqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.0 Estimating"
      ],
      "metadata": {
        "id": "umwZABDXo4FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "y_val_copy = copy.copy(y_val)\n",
        "np.random.shuffle(y_val)\n",
        "hits_array = np.array(y_val) == np.array(y_val_copy)\n",
        "print(\"Accuracy using  as set: \",hits_array.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9r_dUNIo_0q",
        "outputId": "713a20b7-3188-418c-df82-e036c8159e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using one_hot_val_labels as set:  0.8303405572755418\n",
            "Accuracy using val_labels as set:  0.31826625386996904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.1 Classification Model 1 (clasmodl1)"
      ],
      "metadata": {
        "id": "6sMVEJYkt6hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl1():\n",
        "  clasmodl1 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(8, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl1.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl1\n",
        "\n",
        "clasmodl1 = build_clasmodl1()\n",
        "history_clasmodl1 = clasmodl1.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 32, epochs = 50, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "\n",
        "clasmodl1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efgVAKb2uAn6",
        "outputId": "2a00f12e-c9ba-4911-ab34-8b0eef93fe22"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "153/153 - 1s - loss: 8.1582 - accuracy: 0.1511 - val_loss: 0.6619 - val_accuracy: 0.7839 - 941ms/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "153/153 - 0s - loss: 0.4557 - accuracy: 0.8038 - val_loss: 0.3794 - val_accuracy: 0.7839 - 277ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "153/153 - 0s - loss: 0.2856 - accuracy: 0.8038 - val_loss: 0.2657 - val_accuracy: 0.7845 - 366ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "153/153 - 0s - loss: 0.2514 - accuracy: 0.8036 - val_loss: 0.2747 - val_accuracy: 0.7839 - 283ms/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "153/153 - 0s - loss: 0.2494 - accuracy: 0.8040 - val_loss: 0.2629 - val_accuracy: 0.7833 - 265ms/epoch - 2ms/step\n",
            "Epoch 6/50\n",
            "153/153 - 0s - loss: 0.2471 - accuracy: 0.8050 - val_loss: 0.2683 - val_accuracy: 0.7845 - 279ms/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "153/153 - 0s - loss: 0.2458 - accuracy: 0.8042 - val_loss: 0.2609 - val_accuracy: 0.7845 - 281ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "153/153 - 0s - loss: 0.2445 - accuracy: 0.8048 - val_loss: 0.2537 - val_accuracy: 0.7833 - 267ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "153/153 - 0s - loss: 0.2425 - accuracy: 0.8036 - val_loss: 0.2670 - val_accuracy: 0.7845 - 364ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "153/153 - 0s - loss: 0.2403 - accuracy: 0.8062 - val_loss: 0.2661 - val_accuracy: 0.7913 - 294ms/epoch - 2ms/step\n",
            "Epoch 11/50\n",
            "153/153 - 0s - loss: 0.2397 - accuracy: 0.8050 - val_loss: 0.2579 - val_accuracy: 0.7907 - 270ms/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "153/153 - 0s - loss: 0.2384 - accuracy: 0.8058 - val_loss: 0.2529 - val_accuracy: 0.7845 - 287ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "153/153 - 0s - loss: 0.2372 - accuracy: 0.8044 - val_loss: 0.2465 - val_accuracy: 0.7845 - 280ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "153/153 - 0s - loss: 0.2361 - accuracy: 0.8054 - val_loss: 0.2478 - val_accuracy: 0.7839 - 291ms/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "153/153 - 0s - loss: 0.2363 - accuracy: 0.8046 - val_loss: 0.2488 - val_accuracy: 0.7833 - 274ms/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "153/153 - 0s - loss: 0.2347 - accuracy: 0.8058 - val_loss: 0.2525 - val_accuracy: 0.7845 - 277ms/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "153/153 - 0s - loss: 0.2338 - accuracy: 0.8073 - val_loss: 0.2822 - val_accuracy: 0.7845 - 282ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "153/153 - 0s - loss: 0.2327 - accuracy: 0.8097 - val_loss: 0.2533 - val_accuracy: 0.7839 - 287ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "153/153 - 0s - loss: 0.2332 - accuracy: 0.8060 - val_loss: 0.2453 - val_accuracy: 0.7851 - 272ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "153/153 - 0s - loss: 0.2326 - accuracy: 0.8052 - val_loss: 0.2710 - val_accuracy: 0.7845 - 290ms/epoch - 2ms/step\n",
            "Epoch 21/50\n",
            "153/153 - 0s - loss: 0.2328 - accuracy: 0.8040 - val_loss: 0.2432 - val_accuracy: 0.7876 - 295ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "153/153 - 0s - loss: 0.2325 - accuracy: 0.8040 - val_loss: 0.2441 - val_accuracy: 0.7920 - 272ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "153/153 - 0s - loss: 0.2310 - accuracy: 0.8062 - val_loss: 0.2424 - val_accuracy: 0.7864 - 286ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "153/153 - 0s - loss: 0.2307 - accuracy: 0.8087 - val_loss: 0.2731 - val_accuracy: 0.7845 - 282ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "153/153 - 0s - loss: 0.2306 - accuracy: 0.8025 - val_loss: 0.2614 - val_accuracy: 0.7845 - 265ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "153/153 - 0s - loss: 0.2306 - accuracy: 0.8069 - val_loss: 0.2433 - val_accuracy: 0.7864 - 289ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "153/153 - 0s - loss: 0.2302 - accuracy: 0.8067 - val_loss: 0.2474 - val_accuracy: 0.7851 - 281ms/epoch - 2ms/step\n",
            "Epoch 28/50\n",
            "153/153 - 0s - loss: 0.2308 - accuracy: 0.8091 - val_loss: 0.2442 - val_accuracy: 0.7864 - 280ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "153/153 - 0s - loss: 0.2298 - accuracy: 0.8064 - val_loss: 0.2451 - val_accuracy: 0.7858 - 274ms/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "153/153 - 0s - loss: 0.2289 - accuracy: 0.8064 - val_loss: 0.2582 - val_accuracy: 0.7839 - 273ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "153/153 - 0s - loss: 0.2300 - accuracy: 0.8079 - val_loss: 0.2432 - val_accuracy: 0.7913 - 278ms/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "153/153 - 0s - loss: 0.2291 - accuracy: 0.8054 - val_loss: 0.2451 - val_accuracy: 0.7858 - 281ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "153/153 - 0s - loss: 0.2292 - accuracy: 0.8075 - val_loss: 0.2469 - val_accuracy: 0.7845 - 288ms/epoch - 2ms/step\n",
            "Epoch 34/50\n",
            "153/153 - 0s - loss: 0.2281 - accuracy: 0.8052 - val_loss: 0.2482 - val_accuracy: 0.7845 - 266ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "153/153 - 0s - loss: 0.2282 - accuracy: 0.8077 - val_loss: 0.2462 - val_accuracy: 0.7864 - 287ms/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "153/153 - 0s - loss: 0.2283 - accuracy: 0.8064 - val_loss: 0.2442 - val_accuracy: 0.7864 - 277ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "153/153 - 0s - loss: 0.2277 - accuracy: 0.8032 - val_loss: 0.2542 - val_accuracy: 0.7889 - 282ms/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "153/153 - 0s - loss: 0.2274 - accuracy: 0.8081 - val_loss: 0.2446 - val_accuracy: 0.7981 - 280ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "153/153 - 0s - loss: 0.2276 - accuracy: 0.8099 - val_loss: 0.2432 - val_accuracy: 0.7864 - 285ms/epoch - 2ms/step\n",
            "Epoch 40/50\n",
            "153/153 - 0s - loss: 0.2271 - accuracy: 0.8056 - val_loss: 0.2494 - val_accuracy: 0.7858 - 273ms/epoch - 2ms/step\n",
            "Epoch 41/50\n",
            "153/153 - 0s - loss: 0.2266 - accuracy: 0.8058 - val_loss: 0.2941 - val_accuracy: 0.7276 - 279ms/epoch - 2ms/step\n",
            "Epoch 42/50\n",
            "153/153 - 0s - loss: 0.2258 - accuracy: 0.8108 - val_loss: 0.2456 - val_accuracy: 0.7851 - 361ms/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "153/153 - 0s - loss: 0.2264 - accuracy: 0.8050 - val_loss: 0.2576 - val_accuracy: 0.7827 - 273ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "153/153 - 0s - loss: 0.2265 - accuracy: 0.8075 - val_loss: 0.2716 - val_accuracy: 0.7833 - 297ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "153/153 - 0s - loss: 0.2270 - accuracy: 0.8083 - val_loss: 0.2435 - val_accuracy: 0.7876 - 274ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "153/153 - 0s - loss: 0.2255 - accuracy: 0.8077 - val_loss: 0.2434 - val_accuracy: 0.7907 - 280ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "153/153 - 0s - loss: 0.2242 - accuracy: 0.8093 - val_loss: 0.2399 - val_accuracy: 0.7876 - 272ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "153/153 - 0s - loss: 0.2244 - accuracy: 0.8089 - val_loss: 0.2565 - val_accuracy: 0.7839 - 289ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "153/153 - 0s - loss: 0.2247 - accuracy: 0.8089 - val_loss: 0.2665 - val_accuracy: 0.7827 - 352ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "153/153 - 0s - loss: 0.2240 - accuracy: 0.8095 - val_loss: 0.2418 - val_accuracy: 0.7876 - 273ms/epoch - 2ms/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140\n",
            "Trainable params: 140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Classification Model 1 and Final Values"
      ],
      "metadata": {
        "id": "qUavWkEcvnCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl1.history['val_loss']) + 1), history_clasmodl1.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl1.history['loss']) + 1), history_clasmodl1.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl1.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl1.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl1.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl1.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SAUCbNZpvsG7",
        "outputId": "2287e8c1-72e7-4505-e96c-f434c1c671aa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU1b3/8fd3Lky4CChEqyAEexQvILeAFbWC2h4rXo63Kg/2iLZFeTzV+murtvxatDVP7ak9Wo5tffCo9ZQUtFppqVaraMXW/ioBuYhi6yUoeAu0BBCBXL6/P2bPZBKSMLnshOz5vHwwk7X37LX2ZPKdb9Zeey1zd0REJHpi3d0AEREJhwK8iEhEKcCLiESUAryISEQpwIuIRFSiuxuQa/DgwV5SUtLdzRAR6TFWrFix2d2Lm9u2XwX4kpISKioqursZIiI9hpltaGmbumhERCJKAV5EJKIU4EVEImq/6oMXka5RU1PDxo0b2bVrV3c3RfJUVFTE0KFDSSaTeT9HAV6kAG3cuJEDDjiAkpISzKy7myP74O5s2bKFjRs3MmLEiLyfpy4akQK0a9cuBg0apODeQ5gZgwYNavNfXArwIgVKwb1nac/PKxIBft7Sv/Pc36q6uxkiIvuVSAT4u597g+cV4EV6jKlTp/Lkk082KrvzzjuZPXt2i8+ZMmVK9kbIs846i61bt+61z80338ztt9/eat2LFy/mlVdeyX7/ne98h6effrotzW/WH//4R84+++wOH6czhRrgzex6M1tnZi+b2UIzKwqjnqJknN219WEcWkSA8rXllNxZQuyWGCV3llC+trxDx5s+fTqLFi1qVLZo0SKmT5+e1/Mff/xxBg4c2K66mwb47373u5xxxhntOtb+LrQAb2ZDgGuBUncfBcSBS8OoK5WIsaumLoxDixS88rXlzFoyiw3VG3CcDdUbmLVkVoeC/EUXXcRjjz3Gnj17AKisrOTdd9/llFNOYfbs2ZSWlnLccccxd+7cZp9fUlLC5s2bASgrK+Ooo47i5JNP5rXXXsvuc8899zBx4kTGjBnDhRdeyM6dO3nhhRf47W9/yze+8Q3Gjh3LG2+8wcyZM3n44YcBWLp0KePGjWP06NFceeWV7N69O1vf3LlzGT9+PKNHj2b9+vV5n+vChQsZPXo0o0aN4sYbbwSgrq6OmTNnMmrUKEaPHs0dd9wBwLx58zj22GM5/vjjufTSjofLsLtoEkBvM0sAfYB3w6gklYgpgxcJyZylc9hZs7NR2c6ancxZOqfdxzzooIOYNGkSv//974F09v75z38eM6OsrIyKigrWrFnDc889x5o1a1o8zooVK1i0aBGrVq3i8ccfZ/ny5dltF1xwAcuXL2f16tUcc8wx3HvvvUyePJlzzz2XH/7wh6xatYpPfvKT2f137drFzJkzefDBB1m7di21tbX87Gc/y24fPHgwK1euZPbs2fvsBsp49913ufHGG3nmmWdYtWoVy5cvZ/HixaxatYpNmzbx8ssvs3btWq644goAbrvtNl566SXWrFnD3Xff3abXtDmhBXh33wTcDrwNvAdUu/sfmu5nZrPMrMLMKqqq2tePnu6iUQYvEoa3q99uU3m+crtpcrtnHnroIcaPH8+4ceNYt25do+6Upp5//nnOP/98+vTpQ//+/Tn33HOz215++WVOOeUURo8eTXl5OevWrWu1Pa+99hojRozgqKOOAuDyyy9n2bJl2e0XXHABABMmTKCysjKvc1y+fDlTpkyhuLiYRCLBjBkzWLZsGUcccQRvvvkmX/nKV3jiiSfo378/AMcffzwzZsxgwYIFJBIdv00pzC6aA4HzgBHAYUBfM7us6X7uPt/dS929tLi42Rkv9yndRaMMXiQMwwYMa1N5vs477zyWLl3KypUr2blzJxMmTOCtt97i9ttvZ+nSpaxZs4Zp06a1+27bmTNnctddd7F27Vrmzp3b4bt2U6kUAPF4nNra2g4d68ADD2T16tVMmTKFu+++my996UsAPPbYY1xzzTWsXLmSiRMndrieMLtozgDecvcqd68Bfg1MDqOiVEIZvEhYyk4vo0+yT6OyPsk+lJ1e1qHj9uvXj6lTp3LllVdms/dt27bRt29fBgwYwAcffJDtwmnJpz/9aRYvXszHH3/M9u3bWbJkSXbb9u3bOfTQQ6mpqaG8vOF6wQEHHMD27dv3OtbIkSOprKzk9ddfB+AXv/gFp556aofOcdKkSTz33HNs3ryZuro6Fi5cyKmnnsrmzZupr6/nwgsv5NZbb2XlypXU19fzzjvvMHXqVH7wgx9QXV3Njh07OlR/mFMVvA18ysz6AB8DpwOhTPaeSsbYsbtjn3Qi0rwZo2cA6b74t6vfZtiAYZSdXpYt74jp06dz/vnnZ7tqxowZw7hx4zj66KM5/PDDOemkk1p9/vjx47nkkksYM2YMBx98MBMnTsxu+973vscJJ5xAcXExJ5xwQjaoX3rppXz5y19m3rx52YurkJ7r5f777+fiiy+mtraWiRMncvXVV7fpfJYuXcrQoUOz3//qV7/itttuY+rUqbg706ZN47zzzmP16tVcccUV1Nenex6+//3vU1dXx2WXXUZ1dTXuzrXXXtvukUIZ5u4dOkCrBze7BbgEqAVeAr7k7rtb2r+0tNTbs+DHlx6o4N2tH/P4dae0u60iheTVV1/lmGOO6e5mSBs193MzsxXuXtrc/qFONubuc4Hmxzl1olQyxi510YiINBKJO1lTiRi7dZFVRKSRSAR43ckqIrK3SAT4dAavLhoRkVwRCfDK4EVEmopIgI+xp66e+vrwRgSJiPQ0kQjwRck4AHvqlMWL9ARbtmxh7NixjB07lk984hMMGTIk+31mArKWVFRUcO211+6zjsmTO+e+yv1xGuB8RWJN1lQi/Tm1q6YuG+xFZP81aNAgVq1aBaTncO/Xrx9f//rXs9tra2tbnIultLSU0tJmh3038sILL3ROY3uwSGTwqWT6NNQPL9JzzZw5k6uvvpoTTjiBG264gRdffJETTzyRcePGMXny5OxUwLkZ9c0338yVV17JlClTOOKII5g3b172eP369cvuP2XKFC666CKOPvpoZsyYQeYGz8cff5yjjz6aCRMmcO2117YpU+/OaYDzFYkMviiRzto1Fl6k7W5Zso5X3t3Wqcc89rD+zD3nuDY/b+PGjbzwwgvE43G2bdvG888/TyKR4Omnn+Zb3/oWjzzyyF7PWb9+Pc8++yzbt29n5MiRzJ49m2Qy2Wifl156iXXr1nHYYYdx0kkn8ec//5nS0lKuuuoqli1bxogRI/JebAQapgFesWIFBx54IJ/97GdZvHgxhx9+eHYaYCC76tRtt93GW2+9RSqVanYlqrBEKoPX3awiPdvFF19MPJ5O2Kqrq7n44osZNWoU119/fYvT/U6bNo1UKsXgwYM5+OCD+eCDD/baZ9KkSQwdOpRYLMbYsWOprKxk/fr1HHHEEYwYMQKgTQG+u6cBzlckMviUMniRdmtPph2Wvn37Zh9/+9vfZurUqTz66KNUVlYyZcqUZp+TmcYXWp7KN599OkNmGuAnn3ySu+++m4ceeoj77ruPxx57jGXLlrFkyRLKyspYu3ZtlwT6aGTwiUwfvDJ4kaiorq5myJAhAPz85z/v9OOPHDmSN998M7t4x4MPPpj3c7t7GuB8RSKDz4yc0UVWkei44YYbuPzyy7n11luZNm1apx+/d+/e/PSnP+XMM8+kb9++jaYabmp/mwY4X6FOF9xW7Z0uePU7WznvJ3/m3stLOf2YQ0JomUi0aLrgtB07dtCvXz/cnWuuuYYjjzyS66+/vrub1aK2ThccjS4aDZMUkXa45557GDt2LMcddxzV1dVcddVV3d2kThWNLprMRVb1wYtIG1x//fX7dcbeUWEuuj3SzFbl/NtmZl8No67sMEmNohHJ2/7UPSv71p6fV2gZvLu/BowFMLM4sAl4NIy6GoZJKoMXyUdRURFbtmxh0KBBmFl3N0f2wd3ZsmULRUVFbXpeV3XRnA684e4bwjh4wzBJZfAi+Rg6dCgbN26kqqqqu5sieSoqKmo0kicfXRXgLwUWNrfBzGYBswCGDRvWroMrwIu0TTKZzN7BKdEV+igaM+sFnAv8qrnt7j7f3UvdvbS4uLhddSTiMRIxY5e6aEREsrpimOTngJXuvvcEEZ0olYgpgxcRydEVAX46LXTPdKb0wtvK4EVEMkIN8GbWF/gM8Osw64F0Bq9hkiIiDUK9yOruHwGDwqwjI5XUwtsiIrkiMVUBBH3wusgqIpIVnQCvDF5EpJHoBPhETMMkRURyRCrAK4MXEWkQmQBfpC4aEZFGIhPgdZFVRKSxCAV4ZfAiIrmiE+CTMd3JKiKSIzIBvigRZ7fuZBURyYpMgE8lY+xSBi8ikhWdAJ+IUVPn1NVrGTIREYhQgC9Kppft26MLrSIiQIQCfGZVJ93NKiKSFqEAHyy8rQxeRASIVIDPrMuqDF5EBCIU4DN98MrgRUTSwl7RaaCZPWxm683sVTM7May61AcvItJYqCs6AT8GnnD3i8ysF9AnrIpSyUwXjTJ4EREIMcCb2QDg08BMAHffA+wJq75sF43uZhURAcLtohkBVAH3m9lLZvY/wSLcjZjZLDOrMLOKqqqqdlemLhoRkcbCDPAJYDzwM3cfB3wE3NR0J3ef7+6l7l5aXFzc7so0TFJEpLEwA/xGYKO7/zX4/mHSAT8UGiYpItJYaAHe3d8H3jGzkUHR6cArYdWnYZIiIo2FPYrmK0B5MILmTeCKsCpSH7yISGOhBnh3XwWUhllHhoZJiog0Fpk7WbMXWTVMUkQEiFCAj8eMZNy06IeISCAyAR6ChbeVwYuIAJEL8Fp4W0QkI1IBvigZ10VWEZFApAJ8KhHTMEkRkUCkAnyvREwZvIhIIFIBXl00IiINIhXg1UUjItIgWgFeGbyISFa0Anwixm5l8CIiQMQCfFEyzh5l8CIiQMQCvPrgRUQaRC7Aqw9eRCQtUgFewyRFRBpEKsCri0ZEpEGoC36YWSWwHagDat091MU/Uok4tfVObV09iXikPrtERNos7CX7AKa6++YuqCe7qtMeBXgRkWh10RQF67JqTngRkfADvAN/MLMVZjaruR3MbJaZVZhZRVVVVYcqSyXTy/ZpVScRkfAD/MnuPh74HHCNmX266Q7uPt/dS929tLi4uEOVpZTBi4hkhRrg3X1T8PVD4FFgUpj1FQUZvIZKioiEGODNrK+ZHZB5DHwWeDms+qAhg9dQSRGRcEfRHAI8amaZen7p7k+EWB+phDJ4EZGM0AK8u78JjAnr+M3JDJPUwtsiIpEbJhlk8LrIKiISrQCfyeA1TFJEJGoBXsMkRUSy8g7wZtYnzIZ0Bg2TFBFpsM8Ab2aTzewVYH3w/Rgz+2noLWsHDZMUEWmQTwZ/B/CvwBYAd18N7HVH6v5AwyRFRBrk1UXj7u80KdovU+RsH7wusoqI5DUO/h0zmwy4mSWB64BXw21W+8RiRq+4lu0TEYH8MvirgWuAIcAmYGzw/X5JqzqJiKTtM4MPFuuY0QVt6RSppDJ4ERHII8Cb2f2k53VvxN2vDKVFHZRKxDUOXkSE/Prgf5fzuAg4H3g3nOZ0XCoZ052sIiLk10XzSO73ZrYQ+FNoLeogZfAiImntmargSODgzm5IZ0klYhomKSJCfn3w20n3wVvw9X3gxpDb1W5FusgqIgLk10VzQFc0pLOkEnG27tzT3c0QEel2LQZ4Mxvf2hPdfWU+FZhZHKgANrn72W1rXtulu2iUwYuItJbB/6iVbQ6clmcdmTtf++fbqI4oSsYV4EVEaCXAu/vUjh7czIYC04Ay4P909Hj50J2sIiJpea3JamajgGNJj4MHwN3/N4+n3gncALTYj29ms4BZAMOGDcunOa3SnawiImn5zAc/F/jv4N9U4D+Bc/N43tnAh+6+orX93H2+u5e6e2lxcXF+rW5Fehy8MngRkXzGwV8EnA687+5XAGOAAXk87yTgXDOrBBYBp5nZgvY2NF8aJikikpZPgN/l7vVArZn1Bz4EDt/Xk9z9m+4+1N1LgEuBZ9z9sg61Ng+pRJzaeqe2TkFeRApba8MkfwIsBF40s4HAPcAKYAfwl65pXts1LPpRTyIeqTXFRUTapLWLrH8DfggcBnxEOth/Bujv7mvaUom7/xH4Y/ua2Da5Ab5vqitqFBHZP7WY4rr7j939RNLrr24B7gOeAM43syO7qH1tVpRMr8uqoZIiUuj22Yfh7hvc/QfuPg6YDvwbsD70lrVTKtmQwYuIFLJ8hkkmzOwcMysHfg+8BlwQesvaKZVIZ/CaUVJECl1rF1k/QzpjPwt4kfRQx1nu/lEXta1dijIZvOaEF5EC19pF1m8CvwS+5u7/7KL2dFgmg1cfvIgUutbmosl3MrH9Su4oGhGRQha5geINffAK8CJS2CIX4DN98OqiEZFCF7kArwxeRCQtegE+Ow5eGbyIFLbIBfiiTAavYZIiUuAiF+AzGfwuZfAiUuAiF+B7xXWjk4gIRDDAx2JGr7gW/RARiVyAh3Q3jYZJikihi2aAT8SVwYtIwQstwJtZkZm9aGarzWydmd0SVl1NpRIxDZMUkYLX2mRjHbUbOM3dd5hZEviTmf3e3f9fiHUCWnhbRARCDPDu7qTXbwVIBv88rPpypRJxdqsPXkQKXKh98GYWN7NVwIfAU+7+12b2mWVmFWZWUVVV1Sn1ppTBi4iEG+Ddvc7dxwJDgUlmNqqZfea7e6m7lxYXF3dKvalETOPgRaTgdckoGnffCjwLnNkV9RUl47qTVUQKXpijaIrNbGDwuDfwGbposW5l8CIi4Y6iORR4wMzipD9IHnL334VYX1Z6HLwyeBEpbGGOolkDjAvr+K3RMEkRkQjfyaqpCkSk0EU0wCuDFxGJZoBXF42ISDQDfFEiTl29U1OnIC8ihSuSAb5hXVYFeBEpXNEM8Nl1WXWhVUQKVyQDfJEyeBGRaAb4TAavoZIiUsgiGuCVwYuIRDPAq4tGRCSaAb5IXTQiItEM8MrgRUSiGuA1TFJEJJoBXsMkRUQiGuA1TFJEJLIBXhm8iEiYS/YdbmbPmtkrZrbOzK4Lq66msn3wCvAiUsDCXLKvFviau680swOAFWb2lLu/EmKdQMMoGnXRiEghCy2Dd/f33H1l8Hg78CowJKz6cqmLRkSki/rgzayE9Pqsf21m2ywzqzCziqqqqs6qj16JmBbeFpGCFnqAN7N+wCPAV919W9Pt7j7f3UvdvbS4uLjT6i1KxNhdowxeRApXqAHezJKkg3u5u/86zLqaSiXjyuBFpKCFOYrGgHuBV939v8KqpyUpZfAiUuDCzOBPAr4AnGZmq4J/Z4VYXyOphBbeFpHCFtowSXf/E2BhHX9fipJxDZMUkYIWyTtZQRm8iEiEA7wusopIYYtsgC9KKoMXkcIW2QCfSqgPXkQKW3QDvDJ4ESlw0Q3wGgcvIgUusgG+KBlnly6yikgBi2yAVwYvIoUuwgE+PUzS3bu7KSIi3SKyAb4oGaPeobZeAV5EClNkA7wW3haRQhfdAJ/Uqk4iUtiiG+C1bJ+IFLjIBviipLpoRKSwRTbAZzN4DZUUkQIV5opO95nZh2b2clh1tCZzkVUzSopIoQozg/85cGaIx2+VLrKKSKELLcC7+zLgH2Edf180TFJECl30++CVwYtIger2AG9ms8yswswqqqqqOu24ReqiEZEC1+0B3t3nu3upu5cWFxd32nHVRSMiha7bA3xYdJFVRApdmMMkFwJ/AUaa2UYz+2JYdTUnO0xSGbyIFKhEWAd29+lhHTsf6oMXkULX47toyteWU3JnCbFbYpTcWUL52nIAesUzd7IqgxeRwhRaBt8VyteWM2vJLHbW7ARgQ/UGZi2ZBcCM0TPSqzopgxeRAtWjM/g5S+dkg3vGzpqdzFk6B0ABXkQKWo8O8G9Xv91qeVEyrmGSIlKwenSAHzZgWKvlqaQyeBEpXD06wJedXkafZJ9GZX2SfSg7vQxoWHhbRKQQ9egAP2P0DOafM5/hA4ZjGMMHDGf+OfOZMXoGkB4qqfngRaRQmbt3dxuySktLvaKiolOOVb62nDkPbWF3bQ2pg++i7Ixbs4FfRCQqzGyFu5c2t61HZ/AtyQyfrPaVpPxodlV9mat/863sGHkRkUIQyQCfGT65NfEAW5Lz6FV/JAfuuJ05S37H/vQXS9S0dNOZSHvpPdUxkQzw2eGTBjsSf+Dd1H+wJ/YGbLuMM+/6DSU/On6vN0xrb6SWtoVd3pPqyPzVtKF6A45nbzrLbNNrG73zK9T3VGu6oo62iGQffMmdJWyo3tC40I1PxC6l186LqWcXW5O/YE/s7yR7VfPvYy/igdUPNLppqk+yD/PPmQ/Q6G7ZzLbLx1ze7HM6q7wr6u7MOnonerPl4y17/SwG9R7Ex7Uf67WN2PkV6nsqM4ijfG05c5bO4e3qtxk2YFh25F5n1J07UCQfrfXBRzLAN53CABreMNUf9WbwnutJ+cjstjq2UWvvUxt7j1r7EKcWcAYW9Qecf+76B+CA49SD1RMD6qlLfx9sA8fMcK8j/apmtkHMoN7r8ey+9WCOBcfJ7OvBtkP6FgPO+x+9F2zLcGJm1Htmf8DSx4xhwbE82DP9vLgZdV6XfX6mfMgBhwLOpu2bss9JM2IWC+og59yduMWo89psnQ3H9Eb75v7zRuXp4w/rfzhgvL3tnSY/vUwdew9vjVs8j/KGemPZ8849Dxg+YDgEGWHQnDbWse/y4QOGg9M40bDOraPVumHvJKeH1d1WXXHewwcMp+z0shbjS3MfSO2po/KrlXuVt6TgAjzQ7CfsF379hXS48RhJH0bCDyVZ/wkSfigJz3wdDMSxaPZeSQg85wM4n/eN0/TDqGFLQwJgGEbDp0/u46bPzX0eOfs1/d1u/Jy9t+c+t/UzaPr/5uvK57jezGNvskfTcg8SjNwyA899rfYl8/o2bU1OcmINj3PLk7E4NfV7Wj12848b15R7nnVWzQepm7Itq5+b//Du1gJ8j55srDUzRs/Y68+cOUvnpD/drZ4aq6SGSj6Ot/BJ6jB8QAlgbKh+J/jFNQi+xi1BvUPmMoYF2+LEqQs+NBt+2Y2Yxal3J/OLmt3f0vun9w3q8BiH9jsUMN7fUdUkaGSy68yxyB4zbrGgTQ1lYMSJU595M3lDeXGfYsDYvHNLUNbwhmv4K6HxsWIWDy5UZ16P9Pa+yX7U1Newp64m+4vTK5YiGe/FRzU7c+pN13FQ74EA/GNX7rrs6V/SdN1NW5T5K2jvoNTwemR+DhaUx4PjNA6OA4sOBGDrrq2NyoHgr6Bm6mixPE49ua9T+hd3YGog4GzdvTVnW/prjBieLbOcY8Vo/Gsd/FWINflLMfMeigWBp/FxBqT6A1C9e1vOsSz4Lxb8/Bqfd/ovz70DrFkM99xWWU550w8U6B/UvW339jx+fsFPptljGUWJFLX1ddTW12bPMRFLkLAEu+t273UO/Xr1BZzte3bQVPo13PuDouG8c1+TWM7PCCCePUq/ZL/0+znW+P28t5zXkNwPqUyJ5bTJqKfhr4GW7tBvj8gG+Oa09KdVs31hvfpQdsatQEv9ajNC7css+9z/baXu5p/z7y2Uf6GlOs5uuc/yshae01L5j4L+z3z7Jcta6S9ta90tlbf42nZBX21X1NF1dS/oxLr/N+9jzWvje+rHXfCa//ic+Q2JYhMtXRto888vOMdO4e6h/QPOBF4DXgdu2tf+EyZM8LAtWLPAh98x3O1m8+F3DPcFaxa0Wt6e53RWeU+ro62vuV5b1d1T31N9yvo4N5P916esjy9YsyD0824OUOEtxNTQ+uDNLA78DfgMsBFYDkx391daek5n9sGLiISluWt83XWnfHf1wU8CXnf3N4NGLALOA1oM8CIiPUFz1/j2R2EOFRkC5I6B2xiUNWJms8yswswqqqqqQmyOiEhh6faxgO4+391L3b20uLi4u5sjIhIZYQb4TcDhOd8PDcpERKQLhBnglwNHmtkIM+sFXAr8NsT6REQkR2gXWd291sz+A3iS9J0C97n7urDqExGRxvarqQrMrArY+w6CxgYDm7ugOfsbnXdh0XkXlo6c93B3b/YC5n4V4PNhZhUtjfmMMp13YdF5F5awzrvbR9GIiEg4FOBFRCKqJwb4+d3dgG6i8y4sOu/CEsp597g+eBERyU9PzOBFRCQPCvAiIhHVYwK8mZ1pZq+Z2etmdlN3tydMZnafmX1oZi/nlB1kZk+Z2d+Drwd2Zxs7m5kdbmbPmtkrZrbOzK4LyqN+3kVm9qKZrQ7O+5agfISZ/TV4vz8Y3A0eOWYWN7OXzOx3wfeFct6VZrbWzFaZWUVQ1unv9R4R4IO55X8CfA44FphuZsd2b6tC9XPSi6XkuglY6u5HAkuD76OkFviaux8LfAq4JvgZR/28dwOnufsYYCxwppl9CvgBcIe7/wvwT+CL3djGMF0HvJrzfaGcN8BUdx+bM/6909/rPSLAkzO3vLvvATJzy0eSuy8D/tGk+DzggeDxA8C/dWmjQubu77n7yuDxdtK/9EOI/nm7u2cWEU0G/xw4DXg4KI/ceQOY2VBgGvA/wfdGAZx3Kzr9vd5TAnxec8tH3CHu/l7w+H3gkO5sTJjMrAQYB/yVAjjvoJtiFfAh8BTwBrDV3WuDXaL6fr8TuAGya40PojDOG9If4n8wsxVmNiso6/T3ekEtuh0V7u5mFsnxrWbWD3gE+Kq7b0sndWlRPW93rwPGmtlA4FHg6G5uUujM7GzgQ3dfYWZTurs93eBkd99kZgcDT5nZ+tyNnfVe7ykZvOaWhw/M7FCA4OuH3dyeTmdmSdLBvdzdfx0UR/68M9x9K/AscCIw0MwyCVgU3+8nAeeaWSXpLtfTgB8T/fMGwN03BV8/JP2hPokQ3us9JcBrbvn0+V4ePL4c+E03tqXTBf2v9wKvuvt/5WyK+nkXB5k7Ztab9CL1r5IO9BcFu0XuvN39m+4+1N1LSP8+P+PuM4j4eQOYWV8zOyDzGPgs8DIhvNd7zJ2sZnYW6T67zNzyZd3cpND6lp0AAAJUSURBVNCY2UJgCukpRD8A5gKLgYeAYaSnVP68uze9ENtjmdnJwPPAWhr6ZL9Fuh8+yud9POkLanHSCddD7v5dMzuCdGZ7EPAScJm77+6+loYn6KL5urufXQjnHZzjo8G3CeCX7l5mZoPo5Pd6jwnwIiLSNj2li0ZERNpIAV5EJKIU4EVEIkoBXkQkohTgRUQiSgFeIs/M6oJZ+zL/Om3CMjMryZ31U2R/oqkKpBB87O5ju7sRIl1NGbwUrGBO7v8M5uV+0cz+JSgvMbNnzGyNmS01s2FB+SFm9mgwd/tqM5scHCpuZvcE87n/IbgjFTO7Npjffo2ZLeqm05QCpgAvhaB3ky6aS3K2Vbv7aOAu0ndKA/w38IC7Hw+UA/OC8nnAc8Hc7eOBdUH5kcBP3P04YCtwYVB+EzAuOM7VYZ2cSEt0J6tEnpntcPd+zZRXkl5s481gorP33X2QmW0GDnX3mqD8PXcfbGZVwNDcW+eDqY2fChZpwMxuBJLufquZPQHsID3NxOKced9FuoQyeCl03sLjtsidK6WOhmtb00ivRDYeWJ4zS6JIl1CAl0J3Sc7XvwSPXyA9wyHADNKToEF6GbXZkF2kY0BLBzWzGHC4uz8L3AgMAPb6K0IkTMoopBD0DlZMynjC3TNDJQ80szWks/DpQdlXgPvN7BtAFXBFUH4dMN/Mvkg6U58NvEfz4sCC4EPAgHnBfO8iXUZ98FKwgj74Unff3N1tEQmDumhERCJKGbyISEQpgxcRiSgFeBGRiFKAFxGJKAV4EZGIUoAXEYmo/w/hnUA6XyS/+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.223992258310318 \n",
            "Final Training Accuracy:  0.8095238208770752\n",
            "Final Validation loss:  0.2417786419391632 \n",
            "Final Validation Accuracy:  0.7876160740852356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.2 Classification Model 2 (clasmodl2)"
      ],
      "metadata": {
        "id": "uyPkgYySwlGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl2():\n",
        "  clasmodl2 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(512, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(30, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl2.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl2\n",
        "\n",
        "clasmodl2 = build_clasmodl2()\n",
        "history_clasmodl2 = clasmodl2.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 128, epochs = 200, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "\n",
        "#clasmodl2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YtEXogowx_y",
        "outputId": "b4691d69-627f-401a-c231-5903f30a4df0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 - 1s - loss: 0.3339 - accuracy: 0.7779 - val_loss: 0.2816 - val_accuracy: 0.7839 - 1s/epoch - 30ms/step\n",
            "Epoch 2/200\n",
            "39/39 - 0s - loss: 0.2644 - accuracy: 0.8038 - val_loss: 0.4418 - val_accuracy: 0.7839 - 206ms/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "39/39 - 0s - loss: 0.2619 - accuracy: 0.8038 - val_loss: 0.2695 - val_accuracy: 0.7839 - 225ms/epoch - 6ms/step\n",
            "Epoch 4/200\n",
            "39/39 - 0s - loss: 0.2611 - accuracy: 0.8038 - val_loss: 0.2740 - val_accuracy: 0.7839 - 207ms/epoch - 5ms/step\n",
            "Epoch 5/200\n",
            "39/39 - 0s - loss: 0.2535 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7839 - 241ms/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "39/39 - 0s - loss: 0.2566 - accuracy: 0.8038 - val_loss: 0.2911 - val_accuracy: 0.7839 - 210ms/epoch - 5ms/step\n",
            "Epoch 7/200\n",
            "39/39 - 0s - loss: 0.2517 - accuracy: 0.8038 - val_loss: 0.2672 - val_accuracy: 0.7839 - 223ms/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "39/39 - 0s - loss: 0.2491 - accuracy: 0.8028 - val_loss: 0.2790 - val_accuracy: 0.7839 - 249ms/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "39/39 - 0s - loss: 0.2469 - accuracy: 0.8038 - val_loss: 0.3637 - val_accuracy: 0.7839 - 208ms/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "39/39 - 0s - loss: 0.2469 - accuracy: 0.8036 - val_loss: 0.3027 - val_accuracy: 0.7864 - 207ms/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "39/39 - 0s - loss: 0.2443 - accuracy: 0.8034 - val_loss: 0.4518 - val_accuracy: 0.7839 - 237ms/epoch - 6ms/step\n",
            "Epoch 12/200\n",
            "39/39 - 0s - loss: 0.2464 - accuracy: 0.8042 - val_loss: 0.2941 - val_accuracy: 0.7839 - 224ms/epoch - 6ms/step\n",
            "Epoch 13/200\n",
            "39/39 - 0s - loss: 0.2385 - accuracy: 0.8038 - val_loss: 0.2624 - val_accuracy: 0.7839 - 215ms/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "39/39 - 0s - loss: 0.2408 - accuracy: 0.8040 - val_loss: 0.2701 - val_accuracy: 0.7839 - 251ms/epoch - 6ms/step\n",
            "Epoch 15/200\n",
            "39/39 - 0s - loss: 0.2376 - accuracy: 0.8023 - val_loss: 0.2736 - val_accuracy: 0.7771 - 199ms/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "39/39 - 0s - loss: 0.2356 - accuracy: 0.8040 - val_loss: 0.4883 - val_accuracy: 0.7839 - 220ms/epoch - 6ms/step\n",
            "Epoch 17/200\n",
            "39/39 - 0s - loss: 0.2366 - accuracy: 0.8040 - val_loss: 0.2461 - val_accuracy: 0.7845 - 213ms/epoch - 5ms/step\n",
            "Epoch 18/200\n",
            "39/39 - 0s - loss: 0.2356 - accuracy: 0.8007 - val_loss: 0.2659 - val_accuracy: 0.7839 - 250ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "39/39 - 0s - loss: 0.2309 - accuracy: 0.8025 - val_loss: 0.2491 - val_accuracy: 0.7759 - 197ms/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "39/39 - 0s - loss: 0.2313 - accuracy: 0.8021 - val_loss: 0.3990 - val_accuracy: 0.7839 - 205ms/epoch - 5ms/step\n",
            "Epoch 21/200\n",
            "39/39 - 0s - loss: 0.2306 - accuracy: 0.8021 - val_loss: 0.2698 - val_accuracy: 0.7839 - 236ms/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "39/39 - 0s - loss: 0.2312 - accuracy: 0.8067 - val_loss: 0.2717 - val_accuracy: 0.7839 - 221ms/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "39/39 - 0s - loss: 0.2296 - accuracy: 0.8011 - val_loss: 0.2945 - val_accuracy: 0.7839 - 240ms/epoch - 6ms/step\n",
            "Epoch 24/200\n",
            "39/39 - 0s - loss: 0.2290 - accuracy: 0.8007 - val_loss: 0.2451 - val_accuracy: 0.7858 - 244ms/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "39/39 - 0s - loss: 0.2249 - accuracy: 0.8046 - val_loss: 0.2425 - val_accuracy: 0.7845 - 257ms/epoch - 7ms/step\n",
            "Epoch 26/200\n",
            "39/39 - 0s - loss: 0.2239 - accuracy: 0.8079 - val_loss: 0.2476 - val_accuracy: 0.7845 - 203ms/epoch - 5ms/step\n",
            "Epoch 27/200\n",
            "39/39 - 0s - loss: 0.2223 - accuracy: 0.8058 - val_loss: 0.3091 - val_accuracy: 0.6861 - 208ms/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "39/39 - 0s - loss: 0.2259 - accuracy: 0.8030 - val_loss: 0.2560 - val_accuracy: 0.7833 - 204ms/epoch - 5ms/step\n",
            "Epoch 29/200\n",
            "39/39 - 0s - loss: 0.2210 - accuracy: 0.8093 - val_loss: 0.2668 - val_accuracy: 0.7839 - 196ms/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "39/39 - 0s - loss: 0.2221 - accuracy: 0.8052 - val_loss: 0.4095 - val_accuracy: 0.7839 - 234ms/epoch - 6ms/step\n",
            "Epoch 31/200\n",
            "39/39 - 0s - loss: 0.2215 - accuracy: 0.8052 - val_loss: 0.3921 - val_accuracy: 0.7839 - 246ms/epoch - 6ms/step\n",
            "Epoch 32/200\n",
            "39/39 - 0s - loss: 0.2202 - accuracy: 0.8062 - val_loss: 0.3584 - val_accuracy: 0.7845 - 229ms/epoch - 6ms/step\n",
            "Epoch 33/200\n",
            "39/39 - 0s - loss: 0.2209 - accuracy: 0.8093 - val_loss: 0.2690 - val_accuracy: 0.7715 - 206ms/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "39/39 - 0s - loss: 0.2157 - accuracy: 0.8097 - val_loss: 0.2515 - val_accuracy: 0.7808 - 206ms/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "39/39 - 0s - loss: 0.2192 - accuracy: 0.8081 - val_loss: 0.2453 - val_accuracy: 0.7864 - 209ms/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "39/39 - 0s - loss: 0.2161 - accuracy: 0.8040 - val_loss: 0.2469 - val_accuracy: 0.7839 - 209ms/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "39/39 - 0s - loss: 0.2148 - accuracy: 0.8073 - val_loss: 0.3302 - val_accuracy: 0.5232 - 209ms/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "39/39 - 0s - loss: 0.2196 - accuracy: 0.8032 - val_loss: 0.2443 - val_accuracy: 0.7851 - 211ms/epoch - 5ms/step\n",
            "Epoch 39/200\n",
            "39/39 - 0s - loss: 0.2161 - accuracy: 0.8097 - val_loss: 0.3778 - val_accuracy: 0.7839 - 258ms/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "39/39 - 0s - loss: 0.2163 - accuracy: 0.8085 - val_loss: 0.2355 - val_accuracy: 0.7938 - 211ms/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "39/39 - 0s - loss: 0.2149 - accuracy: 0.8136 - val_loss: 0.2579 - val_accuracy: 0.7783 - 245ms/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "39/39 - 0s - loss: 0.2119 - accuracy: 0.8075 - val_loss: 0.2417 - val_accuracy: 0.7783 - 246ms/epoch - 6ms/step\n",
            "Epoch 43/200\n",
            "39/39 - 0s - loss: 0.2158 - accuracy: 0.8095 - val_loss: 0.3298 - val_accuracy: 0.7839 - 210ms/epoch - 5ms/step\n",
            "Epoch 44/200\n",
            "39/39 - 0s - loss: 0.2138 - accuracy: 0.8097 - val_loss: 0.2568 - val_accuracy: 0.7517 - 244ms/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "39/39 - 0s - loss: 0.2147 - accuracy: 0.8095 - val_loss: 0.2360 - val_accuracy: 0.7913 - 214ms/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "39/39 - 0s - loss: 0.2142 - accuracy: 0.8124 - val_loss: 0.2407 - val_accuracy: 0.7907 - 251ms/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "39/39 - 0s - loss: 0.2108 - accuracy: 0.8142 - val_loss: 0.2512 - val_accuracy: 0.7721 - 206ms/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "39/39 - 0s - loss: 0.2153 - accuracy: 0.8093 - val_loss: 0.2430 - val_accuracy: 0.7920 - 219ms/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "39/39 - 0s - loss: 0.2121 - accuracy: 0.8079 - val_loss: 0.3498 - val_accuracy: 0.7845 - 217ms/epoch - 6ms/step\n",
            "Epoch 50/200\n",
            "39/39 - 0s - loss: 0.2129 - accuracy: 0.8151 - val_loss: 0.2760 - val_accuracy: 0.7294 - 208ms/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "39/39 - 0s - loss: 0.2124 - accuracy: 0.8124 - val_loss: 0.2579 - val_accuracy: 0.7647 - 210ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "39/39 - 0s - loss: 0.2099 - accuracy: 0.8077 - val_loss: 0.2660 - val_accuracy: 0.7907 - 224ms/epoch - 6ms/step\n",
            "Epoch 53/200\n",
            "39/39 - 0s - loss: 0.2096 - accuracy: 0.8116 - val_loss: 0.2353 - val_accuracy: 0.7932 - 248ms/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "39/39 - 0s - loss: 0.2096 - accuracy: 0.8136 - val_loss: 0.2991 - val_accuracy: 0.7845 - 242ms/epoch - 6ms/step\n",
            "Epoch 55/200\n",
            "39/39 - 0s - loss: 0.2088 - accuracy: 0.8183 - val_loss: 0.2751 - val_accuracy: 0.7176 - 209ms/epoch - 5ms/step\n",
            "Epoch 56/200\n",
            "39/39 - 0s - loss: 0.2115 - accuracy: 0.8085 - val_loss: 0.2579 - val_accuracy: 0.7851 - 205ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "39/39 - 0s - loss: 0.2064 - accuracy: 0.8138 - val_loss: 0.2328 - val_accuracy: 0.7765 - 263ms/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "39/39 - 0s - loss: 0.2071 - accuracy: 0.8112 - val_loss: 0.2652 - val_accuracy: 0.7944 - 201ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "39/39 - 0s - loss: 0.2078 - accuracy: 0.8157 - val_loss: 0.2501 - val_accuracy: 0.7690 - 242ms/epoch - 6ms/step\n",
            "Epoch 60/200\n",
            "39/39 - 0s - loss: 0.2042 - accuracy: 0.8175 - val_loss: 0.2274 - val_accuracy: 0.7938 - 243ms/epoch - 6ms/step\n",
            "Epoch 61/200\n",
            "39/39 - 0s - loss: 0.2075 - accuracy: 0.8120 - val_loss: 0.2576 - val_accuracy: 0.7827 - 248ms/epoch - 6ms/step\n",
            "Epoch 62/200\n",
            "39/39 - 0s - loss: 0.2047 - accuracy: 0.8175 - val_loss: 0.2326 - val_accuracy: 0.7963 - 251ms/epoch - 6ms/step\n",
            "Epoch 63/200\n",
            "39/39 - 0s - loss: 0.2072 - accuracy: 0.8126 - val_loss: 0.2354 - val_accuracy: 0.7975 - 207ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "39/39 - 0s - loss: 0.2041 - accuracy: 0.8163 - val_loss: 0.2922 - val_accuracy: 0.7839 - 247ms/epoch - 6ms/step\n",
            "Epoch 65/200\n",
            "39/39 - 0s - loss: 0.2060 - accuracy: 0.8159 - val_loss: 0.3577 - val_accuracy: 0.7864 - 216ms/epoch - 6ms/step\n",
            "Epoch 66/200\n",
            "39/39 - 0s - loss: 0.2077 - accuracy: 0.8206 - val_loss: 0.2339 - val_accuracy: 0.7870 - 242ms/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "39/39 - 0s - loss: 0.2043 - accuracy: 0.8151 - val_loss: 0.2345 - val_accuracy: 0.7876 - 233ms/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "39/39 - 0s - loss: 0.2030 - accuracy: 0.8186 - val_loss: 0.2970 - val_accuracy: 0.7876 - 235ms/epoch - 6ms/step\n",
            "Epoch 69/200\n",
            "39/39 - 0s - loss: 0.2057 - accuracy: 0.8163 - val_loss: 0.2610 - val_accuracy: 0.7845 - 201ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "39/39 - 0s - loss: 0.2019 - accuracy: 0.8153 - val_loss: 0.2301 - val_accuracy: 0.7913 - 218ms/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "39/39 - 0s - loss: 0.2030 - accuracy: 0.8169 - val_loss: 0.2771 - val_accuracy: 0.7443 - 240ms/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "39/39 - 0s - loss: 0.2042 - accuracy: 0.8144 - val_loss: 0.2500 - val_accuracy: 0.7901 - 201ms/epoch - 5ms/step\n",
            "Epoch 73/200\n",
            "39/39 - 0s - loss: 0.2012 - accuracy: 0.8183 - val_loss: 0.2894 - val_accuracy: 0.7864 - 200ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "39/39 - 0s - loss: 0.2041 - accuracy: 0.8138 - val_loss: 0.2383 - val_accuracy: 0.7938 - 268ms/epoch - 7ms/step\n",
            "Epoch 75/200\n",
            "39/39 - 0s - loss: 0.2021 - accuracy: 0.8192 - val_loss: 0.2640 - val_accuracy: 0.7901 - 245ms/epoch - 6ms/step\n",
            "Epoch 76/200\n",
            "39/39 - 0s - loss: 0.2019 - accuracy: 0.8165 - val_loss: 0.2256 - val_accuracy: 0.7938 - 235ms/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "39/39 - 0s - loss: 0.2006 - accuracy: 0.8222 - val_loss: 0.2267 - val_accuracy: 0.7913 - 207ms/epoch - 5ms/step\n",
            "Epoch 78/200\n",
            "39/39 - 0s - loss: 0.2007 - accuracy: 0.8204 - val_loss: 0.2280 - val_accuracy: 0.7895 - 252ms/epoch - 6ms/step\n",
            "Epoch 79/200\n",
            "39/39 - 0s - loss: 0.2016 - accuracy: 0.8169 - val_loss: 0.2463 - val_accuracy: 0.7833 - 202ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "39/39 - 0s - loss: 0.1995 - accuracy: 0.8183 - val_loss: 0.2619 - val_accuracy: 0.7319 - 241ms/epoch - 6ms/step\n",
            "Epoch 81/200\n",
            "39/39 - 0s - loss: 0.2006 - accuracy: 0.8181 - val_loss: 0.3004 - val_accuracy: 0.6582 - 207ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "39/39 - 0s - loss: 0.2025 - accuracy: 0.8142 - val_loss: 0.2614 - val_accuracy: 0.7864 - 259ms/epoch - 7ms/step\n",
            "Epoch 83/200\n",
            "39/39 - 0s - loss: 0.1986 - accuracy: 0.8186 - val_loss: 0.2663 - val_accuracy: 0.7907 - 252ms/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "39/39 - 0s - loss: 0.1983 - accuracy: 0.8225 - val_loss: 0.2458 - val_accuracy: 0.7759 - 195ms/epoch - 5ms/step\n",
            "Epoch 85/200\n",
            "39/39 - 0s - loss: 0.1993 - accuracy: 0.8190 - val_loss: 0.2408 - val_accuracy: 0.7703 - 238ms/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "39/39 - 0s - loss: 0.1969 - accuracy: 0.8214 - val_loss: 0.3176 - val_accuracy: 0.7851 - 199ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "39/39 - 0s - loss: 0.1987 - accuracy: 0.8229 - val_loss: 0.2451 - val_accuracy: 0.7920 - 227ms/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "39/39 - 0s - loss: 0.1971 - accuracy: 0.8233 - val_loss: 0.2440 - val_accuracy: 0.7988 - 214ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "39/39 - 0s - loss: 0.1976 - accuracy: 0.8239 - val_loss: 0.2278 - val_accuracy: 0.8000 - 244ms/epoch - 6ms/step\n",
            "Epoch 90/200\n",
            "39/39 - 0s - loss: 0.1952 - accuracy: 0.8249 - val_loss: 0.3551 - val_accuracy: 0.7882 - 202ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "39/39 - 0s - loss: 0.1997 - accuracy: 0.8220 - val_loss: 0.2921 - val_accuracy: 0.7851 - 201ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "39/39 - 0s - loss: 0.1958 - accuracy: 0.8243 - val_loss: 0.3159 - val_accuracy: 0.7876 - 207ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "39/39 - 0s - loss: 0.1954 - accuracy: 0.8227 - val_loss: 0.2480 - val_accuracy: 0.7882 - 195ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "39/39 - 0s - loss: 0.1981 - accuracy: 0.8192 - val_loss: 0.2724 - val_accuracy: 0.7802 - 202ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "39/39 - 0s - loss: 0.1964 - accuracy: 0.8237 - val_loss: 0.2622 - val_accuracy: 0.7851 - 210ms/epoch - 5ms/step\n",
            "Epoch 96/200\n",
            "39/39 - 0s - loss: 0.1975 - accuracy: 0.8214 - val_loss: 0.2412 - val_accuracy: 0.7845 - 202ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "39/39 - 0s - loss: 0.1941 - accuracy: 0.8272 - val_loss: 0.2385 - val_accuracy: 0.7994 - 216ms/epoch - 6ms/step\n",
            "Epoch 98/200\n",
            "39/39 - 0s - loss: 0.1934 - accuracy: 0.8245 - val_loss: 0.2825 - val_accuracy: 0.7882 - 211ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "39/39 - 0s - loss: 0.1938 - accuracy: 0.8229 - val_loss: 0.2508 - val_accuracy: 0.7690 - 206ms/epoch - 5ms/step\n",
            "Epoch 100/200\n",
            "39/39 - 0s - loss: 0.1986 - accuracy: 0.8196 - val_loss: 0.2568 - val_accuracy: 0.7598 - 206ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "39/39 - 0s - loss: 0.1934 - accuracy: 0.8276 - val_loss: 0.2479 - val_accuracy: 0.7641 - 255ms/epoch - 7ms/step\n",
            "Epoch 102/200\n",
            "39/39 - 0s - loss: 0.1928 - accuracy: 0.8268 - val_loss: 0.2425 - val_accuracy: 0.7944 - 246ms/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "39/39 - 0s - loss: 0.1923 - accuracy: 0.8264 - val_loss: 0.3181 - val_accuracy: 0.7858 - 206ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "39/39 - 0s - loss: 0.1954 - accuracy: 0.8259 - val_loss: 0.3390 - val_accuracy: 0.7728 - 245ms/epoch - 6ms/step\n",
            "Epoch 105/200\n",
            "39/39 - 0s - loss: 0.1965 - accuracy: 0.8212 - val_loss: 0.2489 - val_accuracy: 0.7771 - 207ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "39/39 - 0s - loss: 0.1962 - accuracy: 0.8220 - val_loss: 0.2374 - val_accuracy: 0.7833 - 223ms/epoch - 6ms/step\n",
            "Epoch 107/200\n",
            "39/39 - 0s - loss: 0.1933 - accuracy: 0.8264 - val_loss: 0.2471 - val_accuracy: 0.7839 - 201ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "39/39 - 0s - loss: 0.1925 - accuracy: 0.8288 - val_loss: 0.2889 - val_accuracy: 0.7672 - 213ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "39/39 - 0s - loss: 0.1923 - accuracy: 0.8278 - val_loss: 0.2730 - val_accuracy: 0.7907 - 251ms/epoch - 6ms/step\n",
            "Epoch 110/200\n",
            "39/39 - 0s - loss: 0.1930 - accuracy: 0.8266 - val_loss: 0.2575 - val_accuracy: 0.8043 - 210ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "39/39 - 0s - loss: 0.1916 - accuracy: 0.8249 - val_loss: 0.2285 - val_accuracy: 0.7907 - 209ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "39/39 - 0s - loss: 0.1912 - accuracy: 0.8335 - val_loss: 0.2328 - val_accuracy: 0.7963 - 210ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "39/39 - 0s - loss: 0.1915 - accuracy: 0.8282 - val_loss: 0.2502 - val_accuracy: 0.7827 - 207ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "39/39 - 0s - loss: 0.1930 - accuracy: 0.8261 - val_loss: 0.2389 - val_accuracy: 0.7876 - 203ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "39/39 - 0s - loss: 0.1907 - accuracy: 0.8292 - val_loss: 0.2445 - val_accuracy: 0.7895 - 224ms/epoch - 6ms/step\n",
            "Epoch 116/200\n",
            "39/39 - 0s - loss: 0.1895 - accuracy: 0.8303 - val_loss: 0.3025 - val_accuracy: 0.7678 - 198ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "39/39 - 0s - loss: 0.1931 - accuracy: 0.8303 - val_loss: 0.2715 - val_accuracy: 0.7399 - 207ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "39/39 - 0s - loss: 0.1928 - accuracy: 0.8253 - val_loss: 0.3187 - val_accuracy: 0.7777 - 203ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "39/39 - 0s - loss: 0.1895 - accuracy: 0.8290 - val_loss: 0.3378 - val_accuracy: 0.7858 - 203ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "39/39 - 0s - loss: 0.1911 - accuracy: 0.8290 - val_loss: 0.2583 - val_accuracy: 0.7944 - 252ms/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "39/39 - 0s - loss: 0.1904 - accuracy: 0.8296 - val_loss: 0.3026 - val_accuracy: 0.6848 - 201ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "39/39 - 0s - loss: 0.1914 - accuracy: 0.8264 - val_loss: 0.2663 - val_accuracy: 0.7901 - 233ms/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "39/39 - 0s - loss: 0.1908 - accuracy: 0.8218 - val_loss: 0.2261 - val_accuracy: 0.7926 - 209ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "39/39 - 0s - loss: 0.1878 - accuracy: 0.8290 - val_loss: 0.2330 - val_accuracy: 0.7981 - 213ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "39/39 - 0s - loss: 0.1900 - accuracy: 0.8292 - val_loss: 0.2420 - val_accuracy: 0.8019 - 216ms/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "39/39 - 0s - loss: 0.1878 - accuracy: 0.8288 - val_loss: 0.2782 - val_accuracy: 0.7907 - 203ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "39/39 - 0s - loss: 0.1897 - accuracy: 0.8305 - val_loss: 0.3644 - val_accuracy: 0.7709 - 207ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "39/39 - 0s - loss: 0.1863 - accuracy: 0.8296 - val_loss: 0.2523 - val_accuracy: 0.7901 - 250ms/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "39/39 - 0s - loss: 0.1873 - accuracy: 0.8339 - val_loss: 0.3220 - val_accuracy: 0.6644 - 223ms/epoch - 6ms/step\n",
            "Epoch 130/200\n",
            "39/39 - 0s - loss: 0.1901 - accuracy: 0.8276 - val_loss: 0.2657 - val_accuracy: 0.7740 - 204ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "39/39 - 0s - loss: 0.1899 - accuracy: 0.8282 - val_loss: 0.2316 - val_accuracy: 0.7913 - 247ms/epoch - 6ms/step\n",
            "Epoch 132/200\n",
            "39/39 - 0s - loss: 0.1858 - accuracy: 0.8309 - val_loss: 0.2612 - val_accuracy: 0.7839 - 247ms/epoch - 6ms/step\n",
            "Epoch 133/200\n",
            "39/39 - 0s - loss: 0.1868 - accuracy: 0.8327 - val_loss: 0.2546 - val_accuracy: 0.7969 - 249ms/epoch - 6ms/step\n",
            "Epoch 134/200\n",
            "39/39 - 0s - loss: 0.1860 - accuracy: 0.8313 - val_loss: 0.2337 - val_accuracy: 0.7988 - 191ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "39/39 - 0s - loss: 0.1838 - accuracy: 0.8376 - val_loss: 0.2478 - val_accuracy: 0.8080 - 201ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "39/39 - 0s - loss: 0.1892 - accuracy: 0.8292 - val_loss: 0.2277 - val_accuracy: 0.7957 - 215ms/epoch - 6ms/step\n",
            "Epoch 137/200\n",
            "39/39 - 0s - loss: 0.1870 - accuracy: 0.8290 - val_loss: 0.2344 - val_accuracy: 0.7988 - 205ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "39/39 - 0s - loss: 0.1807 - accuracy: 0.8337 - val_loss: 0.3188 - val_accuracy: 0.7511 - 210ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "39/39 - 0s - loss: 0.1869 - accuracy: 0.8282 - val_loss: 0.2508 - val_accuracy: 0.8000 - 243ms/epoch - 6ms/step\n",
            "Epoch 140/200\n",
            "39/39 - 0s - loss: 0.1832 - accuracy: 0.8333 - val_loss: 0.2400 - val_accuracy: 0.7845 - 254ms/epoch - 7ms/step\n",
            "Epoch 141/200\n",
            "39/39 - 0s - loss: 0.1845 - accuracy: 0.8261 - val_loss: 0.2339 - val_accuracy: 0.7889 - 215ms/epoch - 6ms/step\n",
            "Epoch 142/200\n",
            "39/39 - 0s - loss: 0.1830 - accuracy: 0.8298 - val_loss: 0.2312 - val_accuracy: 0.7969 - 215ms/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "39/39 - 0s - loss: 0.1833 - accuracy: 0.8346 - val_loss: 0.3438 - val_accuracy: 0.7839 - 207ms/epoch - 5ms/step\n",
            "Epoch 144/200\n",
            "39/39 - 0s - loss: 0.1841 - accuracy: 0.8358 - val_loss: 0.2577 - val_accuracy: 0.7913 - 207ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "39/39 - 0s - loss: 0.1834 - accuracy: 0.8348 - val_loss: 0.3235 - val_accuracy: 0.6947 - 206ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "39/39 - 0s - loss: 0.1846 - accuracy: 0.8348 - val_loss: 0.2605 - val_accuracy: 0.7548 - 240ms/epoch - 6ms/step\n",
            "Epoch 147/200\n",
            "39/39 - 0s - loss: 0.1835 - accuracy: 0.8327 - val_loss: 0.2431 - val_accuracy: 0.7994 - 216ms/epoch - 6ms/step\n",
            "Epoch 148/200\n",
            "39/39 - 0s - loss: 0.1813 - accuracy: 0.8376 - val_loss: 0.3100 - val_accuracy: 0.7864 - 199ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "39/39 - 0s - loss: 0.1817 - accuracy: 0.8344 - val_loss: 0.2381 - val_accuracy: 0.8062 - 223ms/epoch - 6ms/step\n",
            "Epoch 150/200\n",
            "39/39 - 0s - loss: 0.1813 - accuracy: 0.8315 - val_loss: 0.2533 - val_accuracy: 0.8050 - 209ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "39/39 - 0s - loss: 0.1798 - accuracy: 0.8362 - val_loss: 0.2462 - val_accuracy: 0.8012 - 247ms/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "39/39 - 0s - loss: 0.1846 - accuracy: 0.8321 - val_loss: 0.2693 - val_accuracy: 0.7474 - 210ms/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "39/39 - 0s - loss: 0.1798 - accuracy: 0.8354 - val_loss: 0.4104 - val_accuracy: 0.7882 - 240ms/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "39/39 - 0s - loss: 0.1813 - accuracy: 0.8339 - val_loss: 0.2515 - val_accuracy: 0.7988 - 236ms/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "39/39 - 0s - loss: 0.1797 - accuracy: 0.8405 - val_loss: 0.2407 - val_accuracy: 0.8043 - 254ms/epoch - 7ms/step\n",
            "Epoch 156/200\n",
            "39/39 - 0s - loss: 0.1802 - accuracy: 0.8366 - val_loss: 0.2286 - val_accuracy: 0.8037 - 206ms/epoch - 5ms/step\n",
            "Epoch 157/200\n",
            "39/39 - 0s - loss: 0.1780 - accuracy: 0.8389 - val_loss: 0.2548 - val_accuracy: 0.7950 - 211ms/epoch - 5ms/step\n",
            "Epoch 158/200\n",
            "39/39 - 0s - loss: 0.1795 - accuracy: 0.8381 - val_loss: 0.2685 - val_accuracy: 0.8031 - 212ms/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "39/39 - 0s - loss: 0.1819 - accuracy: 0.8378 - val_loss: 0.2396 - val_accuracy: 0.8124 - 208ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "39/39 - 0s - loss: 0.1780 - accuracy: 0.8401 - val_loss: 0.3557 - val_accuracy: 0.7839 - 211ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "39/39 - 0s - loss: 0.1824 - accuracy: 0.8358 - val_loss: 0.2489 - val_accuracy: 0.8025 - 208ms/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "39/39 - 0s - loss: 0.1798 - accuracy: 0.8370 - val_loss: 0.2369 - val_accuracy: 0.7907 - 240ms/epoch - 6ms/step\n",
            "Epoch 163/200\n",
            "39/39 - 0s - loss: 0.1793 - accuracy: 0.8413 - val_loss: 0.2842 - val_accuracy: 0.7913 - 250ms/epoch - 6ms/step\n",
            "Epoch 164/200\n",
            "39/39 - 0s - loss: 0.1772 - accuracy: 0.8385 - val_loss: 0.2706 - val_accuracy: 0.7666 - 208ms/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "39/39 - 0s - loss: 0.1807 - accuracy: 0.8405 - val_loss: 0.2602 - val_accuracy: 0.7957 - 244ms/epoch - 6ms/step\n",
            "Epoch 166/200\n",
            "39/39 - 0s - loss: 0.1802 - accuracy: 0.8346 - val_loss: 0.3108 - val_accuracy: 0.7814 - 206ms/epoch - 5ms/step\n",
            "Epoch 167/200\n",
            "39/39 - 0s - loss: 0.1786 - accuracy: 0.8368 - val_loss: 0.2615 - val_accuracy: 0.7690 - 229ms/epoch - 6ms/step\n",
            "Epoch 168/200\n",
            "39/39 - 0s - loss: 0.1773 - accuracy: 0.8391 - val_loss: 0.2712 - val_accuracy: 0.7511 - 257ms/epoch - 7ms/step\n",
            "Epoch 169/200\n",
            "39/39 - 0s - loss: 0.1794 - accuracy: 0.8397 - val_loss: 0.2515 - val_accuracy: 0.8006 - 210ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "39/39 - 0s - loss: 0.1802 - accuracy: 0.8411 - val_loss: 0.3059 - val_accuracy: 0.7319 - 251ms/epoch - 6ms/step\n",
            "Epoch 171/200\n",
            "39/39 - 0s - loss: 0.1815 - accuracy: 0.8362 - val_loss: 0.2504 - val_accuracy: 0.8019 - 206ms/epoch - 5ms/step\n",
            "Epoch 172/200\n",
            "39/39 - 0s - loss: 0.1754 - accuracy: 0.8381 - val_loss: 0.2346 - val_accuracy: 0.7950 - 253ms/epoch - 6ms/step\n",
            "Epoch 173/200\n",
            "39/39 - 0s - loss: 0.1738 - accuracy: 0.8417 - val_loss: 0.2495 - val_accuracy: 0.7938 - 214ms/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "39/39 - 0s - loss: 0.1767 - accuracy: 0.8381 - val_loss: 0.2562 - val_accuracy: 0.7870 - 221ms/epoch - 6ms/step\n",
            "Epoch 175/200\n",
            "39/39 - 0s - loss: 0.1775 - accuracy: 0.8411 - val_loss: 0.2609 - val_accuracy: 0.7864 - 212ms/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "39/39 - 0s - loss: 0.1736 - accuracy: 0.8442 - val_loss: 0.3378 - val_accuracy: 0.7820 - 225ms/epoch - 6ms/step\n",
            "Epoch 177/200\n",
            "39/39 - 0s - loss: 0.1801 - accuracy: 0.8352 - val_loss: 0.2594 - val_accuracy: 0.8068 - 222ms/epoch - 6ms/step\n",
            "Epoch 178/200\n",
            "39/39 - 0s - loss: 0.1773 - accuracy: 0.8417 - val_loss: 0.2473 - val_accuracy: 0.7907 - 204ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "39/39 - 0s - loss: 0.1752 - accuracy: 0.8448 - val_loss: 0.2529 - val_accuracy: 0.7988 - 212ms/epoch - 5ms/step\n",
            "Epoch 180/200\n",
            "39/39 - 0s - loss: 0.1751 - accuracy: 0.8432 - val_loss: 0.2411 - val_accuracy: 0.7994 - 209ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "39/39 - 0s - loss: 0.1781 - accuracy: 0.8383 - val_loss: 0.2800 - val_accuracy: 0.7963 - 247ms/epoch - 6ms/step\n",
            "Epoch 182/200\n",
            "39/39 - 0s - loss: 0.1760 - accuracy: 0.8415 - val_loss: 0.2655 - val_accuracy: 0.7759 - 204ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "39/39 - 0s - loss: 0.1732 - accuracy: 0.8411 - val_loss: 0.2821 - val_accuracy: 0.8012 - 208ms/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "39/39 - 0s - loss: 0.1766 - accuracy: 0.8405 - val_loss: 0.2604 - val_accuracy: 0.7740 - 245ms/epoch - 6ms/step\n",
            "Epoch 185/200\n",
            "39/39 - 0s - loss: 0.1749 - accuracy: 0.8393 - val_loss: 0.2934 - val_accuracy: 0.7418 - 207ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "39/39 - 0s - loss: 0.1756 - accuracy: 0.8407 - val_loss: 0.3455 - val_accuracy: 0.7988 - 217ms/epoch - 6ms/step\n",
            "Epoch 187/200\n",
            "39/39 - 0s - loss: 0.1784 - accuracy: 0.8403 - val_loss: 0.3279 - val_accuracy: 0.7858 - 220ms/epoch - 6ms/step\n",
            "Epoch 188/200\n",
            "39/39 - 0s - loss: 0.1750 - accuracy: 0.8413 - val_loss: 0.2594 - val_accuracy: 0.8000 - 225ms/epoch - 6ms/step\n",
            "Epoch 189/200\n",
            "39/39 - 0s - loss: 0.1726 - accuracy: 0.8467 - val_loss: 0.2469 - val_accuracy: 0.8099 - 212ms/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "39/39 - 0s - loss: 0.1713 - accuracy: 0.8411 - val_loss: 0.2599 - val_accuracy: 0.7969 - 216ms/epoch - 6ms/step\n",
            "Epoch 191/200\n",
            "39/39 - 0s - loss: 0.1759 - accuracy: 0.8362 - val_loss: 0.3775 - val_accuracy: 0.7740 - 212ms/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "39/39 - 0s - loss: 0.1782 - accuracy: 0.8415 - val_loss: 0.2538 - val_accuracy: 0.8025 - 203ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "39/39 - 0s - loss: 0.1752 - accuracy: 0.8385 - val_loss: 0.3204 - val_accuracy: 0.7300 - 222ms/epoch - 6ms/step\n",
            "Epoch 194/200\n",
            "39/39 - 0s - loss: 0.1751 - accuracy: 0.8391 - val_loss: 0.2580 - val_accuracy: 0.7963 - 250ms/epoch - 6ms/step\n",
            "Epoch 195/200\n",
            "39/39 - 0s - loss: 0.1747 - accuracy: 0.8456 - val_loss: 0.3094 - val_accuracy: 0.7833 - 206ms/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "39/39 - 0s - loss: 0.1719 - accuracy: 0.8438 - val_loss: 0.2751 - val_accuracy: 0.7858 - 241ms/epoch - 6ms/step\n",
            "Epoch 197/200\n",
            "39/39 - 0s - loss: 0.1703 - accuracy: 0.8477 - val_loss: 0.3362 - val_accuracy: 0.7659 - 216ms/epoch - 6ms/step\n",
            "Epoch 198/200\n",
            "39/39 - 0s - loss: 0.1764 - accuracy: 0.8440 - val_loss: 0.2986 - val_accuracy: 0.7994 - 202ms/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "39/39 - 0s - loss: 0.1730 - accuracy: 0.8426 - val_loss: 0.2391 - val_accuracy: 0.8062 - 211ms/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "39/39 - 0s - loss: 0.1723 - accuracy: 0.8446 - val_loss: 0.2473 - val_accuracy: 0.7981 - 245ms/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Classification Model 2 and Final Values"
      ],
      "metadata": {
        "id": "Ug0InJvL07v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl2.history['val_loss']) + 1), history_clasmodl2.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl2.history['loss']) + 1), history_clasmodl2.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl2.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl2.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl2.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl2.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "pSEQkTqp1HRn",
        "outputId": "4cdcd2a4-105f-4704-d486-4fa39c8a465b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.17227403819561005 \n",
            "Final Training Accuracy:  0.8446223139762878\n",
            "Final Validation loss:  0.24727697670459747 \n",
            "Final Validation Accuracy:  0.7981424331665039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.3 Classification Model 3 (clasmodl3)"
      ],
      "metadata": {
        "id": "aH9nWFQq2zd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl3():\n",
        "  clasmodl3 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(512, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(30, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl3.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl3\n",
        "\n",
        "clasmodl3 = build_clasmodl3()\n",
        "history_clasmodl3 = clasmodl3.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 128, epochs = 50, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "\n",
        "#clasmodl3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbNm6nJG3mBE",
        "outputId": "6d91be1a-d2c3-4a8a-d89b-6c773052481e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "39/39 - 1s - loss: 0.3442 - accuracy: 0.7724 - val_loss: 0.2667 - val_accuracy: 0.7839 - 1s/epoch - 32ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.2628 - accuracy: 0.8042 - val_loss: 0.2819 - val_accuracy: 0.7839 - 255ms/epoch - 7ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.2584 - accuracy: 0.8038 - val_loss: 0.2947 - val_accuracy: 0.7839 - 210ms/epoch - 5ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.2553 - accuracy: 0.8032 - val_loss: 0.2932 - val_accuracy: 0.7307 - 202ms/epoch - 5ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.2535 - accuracy: 0.8019 - val_loss: 0.2651 - val_accuracy: 0.7839 - 248ms/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.2510 - accuracy: 0.8021 - val_loss: 0.3019 - val_accuracy: 0.7839 - 278ms/epoch - 7ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.2499 - accuracy: 0.8019 - val_loss: 0.3109 - val_accuracy: 0.7833 - 213ms/epoch - 5ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.2452 - accuracy: 0.8028 - val_loss: 0.3505 - val_accuracy: 0.5703 - 230ms/epoch - 6ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.2461 - accuracy: 0.7982 - val_loss: 0.2892 - val_accuracy: 0.7851 - 248ms/epoch - 6ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.2409 - accuracy: 0.8003 - val_loss: 0.2650 - val_accuracy: 0.7678 - 222ms/epoch - 6ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.2414 - accuracy: 0.8009 - val_loss: 0.2696 - val_accuracy: 0.7839 - 261ms/epoch - 7ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.2360 - accuracy: 0.8005 - val_loss: 0.2521 - val_accuracy: 0.7715 - 215ms/epoch - 6ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.2354 - accuracy: 0.7993 - val_loss: 0.3015 - val_accuracy: 0.7839 - 251ms/epoch - 6ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.2343 - accuracy: 0.8007 - val_loss: 0.2693 - val_accuracy: 0.7839 - 218ms/epoch - 6ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.2309 - accuracy: 0.8015 - val_loss: 0.2824 - val_accuracy: 0.7647 - 217ms/epoch - 6ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.2296 - accuracy: 0.7995 - val_loss: 0.2484 - val_accuracy: 0.7920 - 209ms/epoch - 5ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.2304 - accuracy: 0.8028 - val_loss: 0.2552 - val_accuracy: 0.7858 - 214ms/epoch - 5ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.2258 - accuracy: 0.8054 - val_loss: 0.3603 - val_accuracy: 0.7839 - 204ms/epoch - 5ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.2265 - accuracy: 0.8028 - val_loss: 0.4331 - val_accuracy: 0.7839 - 245ms/epoch - 6ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.2262 - accuracy: 0.8021 - val_loss: 0.2654 - val_accuracy: 0.7313 - 210ms/epoch - 5ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.2242 - accuracy: 0.8007 - val_loss: 0.3808 - val_accuracy: 0.7839 - 207ms/epoch - 5ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.2239 - accuracy: 0.8056 - val_loss: 0.2721 - val_accuracy: 0.7176 - 245ms/epoch - 6ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.2225 - accuracy: 0.7989 - val_loss: 0.2691 - val_accuracy: 0.7827 - 257ms/epoch - 7ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.2203 - accuracy: 0.8038 - val_loss: 0.3415 - val_accuracy: 0.4960 - 253ms/epoch - 6ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.2227 - accuracy: 0.7976 - val_loss: 0.2621 - val_accuracy: 0.7845 - 248ms/epoch - 6ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.2195 - accuracy: 0.8046 - val_loss: 0.2375 - val_accuracy: 0.7814 - 230ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.2162 - accuracy: 0.8064 - val_loss: 0.2488 - val_accuracy: 0.8000 - 244ms/epoch - 6ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.2195 - accuracy: 0.8011 - val_loss: 0.2870 - val_accuracy: 0.7845 - 247ms/epoch - 6ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.2189 - accuracy: 0.8050 - val_loss: 0.3091 - val_accuracy: 0.7839 - 216ms/epoch - 6ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.2195 - accuracy: 0.8046 - val_loss: 0.2515 - val_accuracy: 0.7839 - 213ms/epoch - 5ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.2152 - accuracy: 0.8069 - val_loss: 0.2724 - val_accuracy: 0.7567 - 210ms/epoch - 5ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.2179 - accuracy: 0.8058 - val_loss: 0.2655 - val_accuracy: 0.7672 - 214ms/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.2144 - accuracy: 0.8038 - val_loss: 0.2363 - val_accuracy: 0.7950 - 205ms/epoch - 5ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.2186 - accuracy: 0.8091 - val_loss: 0.3611 - val_accuracy: 0.7845 - 250ms/epoch - 6ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.2151 - accuracy: 0.8064 - val_loss: 0.2522 - val_accuracy: 0.7820 - 212ms/epoch - 5ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.2128 - accuracy: 0.8114 - val_loss: 0.2711 - val_accuracy: 0.6867 - 244ms/epoch - 6ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.2161 - accuracy: 0.8040 - val_loss: 0.2420 - val_accuracy: 0.7771 - 267ms/epoch - 7ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.2147 - accuracy: 0.8134 - val_loss: 0.2904 - val_accuracy: 0.7851 - 216ms/epoch - 6ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.2126 - accuracy: 0.8058 - val_loss: 0.2371 - val_accuracy: 0.8025 - 208ms/epoch - 5ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.2098 - accuracy: 0.8132 - val_loss: 0.2362 - val_accuracy: 0.7938 - 207ms/epoch - 5ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.2127 - accuracy: 0.8081 - val_loss: 0.2626 - val_accuracy: 0.7851 - 259ms/epoch - 7ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.2095 - accuracy: 0.8095 - val_loss: 0.2479 - val_accuracy: 0.7864 - 220ms/epoch - 6ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.2129 - accuracy: 0.8163 - val_loss: 0.2516 - val_accuracy: 0.7783 - 212ms/epoch - 5ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.2059 - accuracy: 0.8198 - val_loss: 0.2574 - val_accuracy: 0.7851 - 205ms/epoch - 5ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.2124 - accuracy: 0.8087 - val_loss: 0.2520 - val_accuracy: 0.7690 - 218ms/epoch - 6ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.2082 - accuracy: 0.8108 - val_loss: 0.2914 - val_accuracy: 0.6551 - 237ms/epoch - 6ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.2093 - accuracy: 0.8122 - val_loss: 0.3267 - val_accuracy: 0.7851 - 224ms/epoch - 6ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.2109 - accuracy: 0.8091 - val_loss: 0.2485 - val_accuracy: 0.7659 - 200ms/epoch - 5ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.2082 - accuracy: 0.8130 - val_loss: 0.4160 - val_accuracy: 0.7839 - 201ms/epoch - 5ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.2121 - accuracy: 0.8132 - val_loss: 0.2487 - val_accuracy: 0.7876 - 218ms/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots for Classification Model 3 and Final Values"
      ],
      "metadata": {
        "id": "nCo55yH45zx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl3.history['val_loss']) + 1), history_clasmodl3.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl3.history['loss']) + 1), history_clasmodl3.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl3.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl3.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl3.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl3.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T5K4Hirh55WY",
        "outputId": "adc1d5da-bafd-411d-e2da-43108a4ceefa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU5bn48e+dfSVAErYEEkB2whrAHXBFUXBXiuegtkW5tNqetmpLW9SaU7tKPXUp1qWnoqj1JweL1gUXUFQIi8QgKEsIYc1CQshCtvv3x0xigElIYPa5P9eVK5l33nfyPJPJ3PNs9yOqijHGGHO8MF8XwBhjjH+yAGGMMcYlCxDGGGNcsgBhjDHGJQsQxhhjXIrwdQHcJSUlRTMzM31dDGOMCSjr1q0rUdVUV/cFTYDIzMwkNzfX18UwxpiAIiK72rrPupiMMca4ZAHCGGOMSxYgjDHGuBQ0YxCu1NfXU1RURG1tra+LYjohJiaG9PR0IiMjfV0UY0JaUAeIoqIiEhMTyczMRER8XRzTAapKaWkpRUVF9O/f39fFMSakBXUXU21tLcnJyRYcAoiIkJyc3KFW3+K8xWQuzCTswTAyF2ayOG+xF0poTOgI6hYEYMEhAHXkb7Y4bzFz35hLdX01ALsqdjH3jbkAzM6a7dHyGRMqgroFYYLX/BXzW4JDs+r6auavmO+jEhkTfCxAeNDUqVN5++23jzm2cOFC5s2b1+Y1U6ZMaVnwd/nll1NeXn7COQ888AB/+MMf2v3dS5cuZfPmzS23f/WrX/Hee+91pvguffjhh1xxxRWn/Tinq7CisFPHjTGdZwGiFXf3ac+aNYslS5Ycc2zJkiXMmjWrQ9e/+eabdO3a9ZR+9/EB4qGHHuKiiy46pcfyR/2S+nXquDGm8yxAODX3ae+q2IWiLX3apxMkrrvuOpYvX05dXR0ABQUF7N27l/POO4958+aRnZ3NiBEjWLBggcvrMzMzKSkpASAnJ4fBgwdz7rnnsnXr1pZznn76aSZMmMDo0aO59tprqa6uZvXq1Sxbtoyf/vSnjBkzhu3bt3PLLbfwz3/+E4AVK1YwduxYsrKyuO222zh69GjL71uwYAHjxo0jKyuLLVu2dLiuL730EllZWYwcOZL77rsPgMbGRm655RZGjhxJVlYWjz76KACPPfYYw4cPZ9SoUdx0002dfFYdci7MIS4y7phjcZFx5FyYc0qPZ4w5kQUIJ0/0aXfv3p2JEyfy1ltvAY7Www033ICIkJOTQ25uLps2beKjjz5i06ZNbT7OunXrWLJkCRs3buTNN99k7dq1Lfddc801rF27li+++IJhw4bxzDPPcPbZZzNjxgx+//vfs3HjRgYOHNhyfm1tLbfccgsvv/wyeXl5NDQ08OSTT7bcn5KSwvr165k3b95Ju7Ga7d27l/vuu4/333+fjRs3snbtWpYuXcrGjRvZs2cPX375JXl5edx6660APPLII2zYsIFNmzbx1FNPdeo5bTY7azaLrlxERlIGgpCRlMGiKxfZALUxbmQBwslTfdqtu5lady+98sorjBs3jrFjx5Kfn39Md9DxVq1axdVXX01cXBxdunRhxowZLfd9+eWXnHfeeWRlZbF48WLy8/PbLc/WrVvp378/gwcPBmDOnDmsXLmy5f5rrrkGgPHjx1NQUNChOq5du5YpU6aQmppKREQEs2fPZuXKlQwYMIAdO3bwgx/8gH//+9906dIFgFGjRjF79mxeeOEFIiJOfSLd7KzZFPywgKYFTRT8sMCCgzFuZgHCyVN92jNnzmTFihWsX7+e6upqxo8fz86dO/nDH/7AihUr2LRpE9OnTz/l1d633HILf/nLX8jLy2PBggWnvWo8OjoagPDwcBoaGk7rsbp168YXX3zBlClTeOqpp/je974HwPLly7nzzjtZv349EyZMOO3fY4zxDAsQTp7q005ISGDq1KncdtttLa2Hw4cPEx8fT1JSEgcOHGjpgmrL+eefz9KlS6mpqaGyspI33nij5b7Kykp69+5NfX09ixd/O16SmJhIZWXlCY81ZMgQCgoK2LZtGwD/+Mc/mDx58mnVceLEiXz00UeUlJTQ2NjISy+9xOTJkykpKaGpqYlrr72Whx9+mPXr19PU1MTu3buZOnUqv/3tb6moqODIkSOn9fuNMZ4R9AvlOqq5e2L+ivkUVhTSL6kfORfmuKXbYtasWVx99dUtXU2jR49m7NixDB06lL59+3LOOee0e/24ceO48cYbGT16ND169GDChAkt9/36179m0qRJpKamMmnSpJagcNNNN/H973+fxx57rGVwGhx5jp577jmuv/56GhoamDBhAnfccUen6rNixQrS09Nbbr/66qs88sgjTJ06FVVl+vTpzJw5ky+++IJbb72VpqYmAH7zm9/Q2NjIzTffTEVFBarK3XfffcoztYwxniWq6usyuEV2drYev2HQV199xbBhw3xUInM67G9njHeIyDpVzXZ1n3UxGWOMcckChDHGGJcsQBhjjHHJAoQxxvg5X6W2t1lMxhjjx3yZ2t5aEMYY48d8mdreAoQHlZaWMmbMGMaMGUOvXr1IS0trud2cwK8tubm53H333Sf9HWeffbZbyuovabyNMcfyZWp762LyoOTkZDZu3Ag49nBISEjgJz/5Scv9DQ0NbeYiys7OJjvb5dTkY6xevdo9hTXG+KV+Sf3YVbHL5XFPsxaEl91yyy3ccccdTJo0iXvvvZc1a9Zw1llnMXbsWM4+++yWVN6tP9E/8MAD3HbbbUyZMoUBAwbw2GOPtTxeQkJCy/lTpkzhuuuuY+jQocyePZvmRZBvvvkmQ4cOZfz48dx9992dail4O423MeZYvkxtHzItiAffyGfz3sNufczhfbqw4MoRnb6uqKiI1atXEx4ezuHDh1m1ahURERG89957/PznP+e111474ZotW7bwwQcfUFlZyZAhQ5g3bx6RkZHHnLNhwwby8/Pp06cP55xzDp988gnZ2dncfvvtrFy5kv79+3d4syL4No33unXr6NatG5dccglLly6lb9++LWm8gZZd7x555BF27txJdHS0y53wjDGd58k0QCcTMgHCn1x//fWEh4cDUFFRwZw5c/jmm28QEerr611eM336dKKjo4mOjqZHjx4cOHDgmHxI4Eia13xszJgxFBQUkJCQwIABA+jfvz/gyAu1aNGiDpWzdRpvoCWN9y9/+cuWNN7Tp0/nkksuAb5N433VVVdx1VVXdf6JMca4NDtrtk/S2YdMgDiVT/qeEh8f3/LzL3/5S6ZOncrrr79OQUEBU6ZMcXlNcxpuaDsVd0fOcYfmNN5vv/02Tz31FK+88grPPvssy5cvZ+XKlbzxxhvk5OSQl5d3Wvs9GGN8y8YgfKyiooK0tDQAnn/+ebc//pAhQ9ixY0fL5j8vv/xyh6+1NN7GhDb7eOdj9957L3PmzOHhhx9m+vTpbn/82NhYnnjiCaZNm0Z8fPwxqcKPZ2m8jTGtWbrvEHDkyBESEhJQVe68804GDRrEj370I18Xq132tzPGOyzdd4h7+umnGTNmDCNGjKCiooLbb7/d10UyxgQA62IKAT/60Y/8vsVgjPE/Hm1BiMg0EdkqIttE5P52zrtWRFREslsd+5nzuq0icumpliFYutBCif3NjPEPHgsQIhIOPA5cBgwHZonIcBfnJQL3AJ+3OjYcuAkYAUwDnnA+XqfExMRQWlpqbzgBRFUpLS0lJibG10UxJuR5sotpIrBNVXcAiMgSYCaw+bjzfg38Fvhpq2MzgSWqehTYKSLbnI/3aWcKkJ6eTlFREcXFxadYBeMLMTExJywCNMZ4nycDRBqwu9XtImBS6xNEZBzQV1WXi8hPj7v2s+OuTTv+F4jIXGAuQL9+JyauioyMbFlBbIwxpnN8NotJRMKAPwE/PtXHUNVFqpqtqtnN6SCMMca4hydbEHuAvq1upzuPNUsERgIfighAL2CZiMzowLXGGGM8zJMtiLXAIBHpLyJROAadlzXfqaoVqpqiqpmqmomjS2mGquY6z7tJRKJFpD8wCFjjwbIaY4w5jsdaEKraICJ3AW8D4cCzqpovIg8Buaq6rJ1r80XkFRwD2g3Anara6KmyGmOMOVFQp9owxhjTPku1YYwxptMsQBhjjHHJAoQxxhiXLEAYY4xxyQKEMcYYlyxAGGOMcckChDHGGJcsQBhjjHHJAoQJKYvzFpO5MJOwB8PIXJjJ4rzFvi6SMX7Lthw1IWNx3mLmvjGX6vpqAHZV7GLuG3MBmJ0125dFM8YvWQvChIz5K+a3BIdm1fXVzF8x30clMsa/WYAwIaOworBTx40JdRYgTMjol3TiroPtHTcm1FmAMCEj58Ic4iLjjjkWFxlHzoU5PiqRMf7NAoQJGbOzZrPoykVkJGUgCBlJGSy6cpENUBvTBtsPwhhjQpjtB2GMMabTLEAYY4xxyQKEMcYYlyxAGGOMcckChDHGGJcsQBhjjHHJAoQxxhiXLEAYY4xxyQKEMcYYlyxAGGM6xTZdCh0WIIzfszck/9G86dKuil0o2rLpkv1NgpMFCOPX7A3Jv9imS6HFAoTxa/aG5F9s06XQYgHC+DV7Q/IvtulSaLEAYfyavSH5F9t0KbRYgDB+zd6Q/IttuhRabMMg4/cW5y1m/or5FFYU0i+pHzkX5tgbkjFu0t6GQRYgjDEmhPlsRzkRmSYiW0Vkm4jc7+L+O0QkT0Q2isjHIjLceTxTRGqcxzeKyFOeLGegsPUAxhhvivDUA4tIOPA4cDFQBKwVkWWqurnVaS+q6lPO82cAfwKmOe/brqpjPFW+QNO8HqB5ymfzegDAuluMMR7hyRbERGCbqu5Q1TpgCTCz9QmqerjVzXggOPq7PMDWAxhjvM2TASIN2N3qdpHz2DFE5E4R2Q78Dri71V39RWSDiHwkIud5sJwBwdYDGGO8zefTXFX1cVUdCNwH/MJ5eB/QT1XHAv8FvCgiXY6/VkTmikiuiOQWFxd7r9A+YOsBjDHe5skAsQfo2+p2uvNYW5YAVwGo6lFVLXX+vA7YDgw+/gJVXaSq2aqanZqa6raC+yNbD2CM8TZPBoi1wCAR6S8iUcBNwLLWJ4jIoFY3pwPfOI+nOge5EZEBwCBghwfL6vdsgZIxxts8NotJVRtE5C7gbSAceFZV80XkISBXVZcBd4nIRUA9cAiY47z8fOAhEakHmoA7VLXME+VsbFL2VdSQGB1JUlykJ36F28zOmm0BwRjjNSG/UO7g4Vom/vcKfn3VSP7jzAwPlMwEK1vhbYJBewvlPNaCCBTd4qMAKKk86uOSmEBi61JMKPD5LCZfiwwPo1tcJKVVFiBMx9m6FBMKQj5AACQnRFNSWefrYpgAYutSTCiwAAGkJERZC8J0iq1LMaHAAgTOFsQRa0GYjrN1KSYUWIAAUhOiKTliLQjTcbYuxYSCkJ/FBJAcH0VlbQO19Y3ERIb7ujgmQNi6FBPsrAUBpCRGA1BWZd1MxhjTzAIEjhYEQKmNQxhjTAsLEHzbgrBxCGOM+VaHA4SIxJ38rMCUEm8BwhhjjnfSACEiZ4vIZmCL8/ZoEXnC4yXzopREZ7oN62IyxpgWHWlBPApcCjTvz/AFjmyrQSMuKoLYyHBKrQVhjPGwxXmLyVyYSdiDYWQuzGRx3mJfF6lNHZrmqqq7RaT1oUbPFMd3khOirIvJGONRgZbksSMtiN0icjagIhIpIj8BvvJwubwuJSGaUpvmaozxoEBL8tiRAHEHcCeQhmPL0DHO20ElJSGKYkv5bYzxoEBL8njSLiZVLQH8r+3jZikJ0XxRVOHrYhhjgli/pH7sqtjl8rg/OmmAEJHngBO2nVPV2zxSIh9JToiirKqOpiYlLExOfoExxnRSzoU5x4xBgH8neezIIPW/Wv0cA1wN7PVMcXwnJSGaxialvKae7s6V1cYY407NA9GBslVtR7qYXmt9W0ReAj72WIl8JDnh28VyFiCMMZ4SSEkeTyXVxiCgh7sL4mspCc2L5Wyg2hhjoGNjEJU4xiDE+X0/cJ+Hy+V1Kc4WhCXsM8YYh450MSV6oyC+lpJg+ZiMMaa1NgOEiIxr70JVXe/+4vhO19hIwsPEWhDGGOPUXgvij+3cp8AFbi6LT4WFCd3jLd2GMcY0azNAqOpUbxbEHyTHR1lGV2OMcerQLCYRGSkiN4jIfzZ/ebpgvpCaGO0XLYhAyvZojAleHdkPYgHwP86vqcDvgBkeLpdPJMdHUVrl2wDRnO1xV8UuFG3J9mhBwrRmHyKMN3SkBXEdcCGwX1VvBUYDSR4tlY+kJERTUunbLqZAy/ZovM8+RBhv6UiAqFXVJqBBRLoAB4G+ni2WbyQnRFNT30h1XYPPyhBo2R6N99mHCOMtbQYIEXlcRM4F1ohIV+BpYB2wHvjUS+XzqpbV1D5sRbSV1dFfsz0a77MPEcZb2mtBfA38HrgC+DnwOXAxMMfZ1RR0WhbL+XAcIufCHOIi44455s/ZHo332YcI4y1tBghV/bOqnoVj/+lS4Fng38DVIjLIS+XzquSWFoTvAsTsrNksunIRGUkZCEJGUgaLrlwUMMm9jOfZhwjjLScdg1DVXar6W1UdC8wCrgK2eLxkPtCSj8lLW4+2NRNldtZsCn5YQNOCJgp+WGDBwRzDPkQYb+lIsr4I4DLgJhyzmT4EHvBoqXykOc23N1oQgbZ5+eK8xQGTwz4UBFLKaBO42hukvlhEngWKgO8Dy4GBqnqTqv5fRx5cRKaJyFYR2SYi97u4/w4RyRORjSLysYgMb3Xfz5zXbRWRSztftc6LiQwnMSbCKy2IQJqJYtMqjQlN7XUx/QxYDQxT1Rmq+qKqVnX0gUUkHHgcR+tjODCrdQBwelFVs1R1DI4FeH9yXjscR4tlBDANeML5eB6XkuCd1dSBNBMlkIKZMcZ92hukvkBV/6aqh07xsScC21R1h6rWAUuAmcf9jsOtbsbz7d7XM4ElqnpUVXcC25yP53EpCd5J2BdIM1ECKZgZY9znVHaU66g0YHer20XOY8cQkTtFZDuOFsTdnbx2rojkikhucXGxWwqdHB/tlZTfgTQTJZCCmTHGfTwZIDpEVR9X1YE4dqn7RSevXaSq2aqanZqa6pbypCR6pwURSDNRAimYGWPc56SzmE7DHo5NyZHuPNaWJcCTp3it2yTHR3Ooup6GxiYiwk+Mn+6czRMoM1Gay2izmIwJLZ4MEGuBQSLSH8eb+03Ad1qfICKDVPUb583pQPPPy4AXReRPQB9gELDGg2VtkZLoWAtRVlVHjy4xx9zX3tRUCO430EAJZsYY9/FYgFDVBhG5C3gbCAeeVdV8EXkIyFXVZcBdInIRUA8cAuY4r80XkVeAzUADcKeqNnqqrK2lNK+FOHJigGhrNs89b91DTUNNwKxpMMaYjvDoGISqvqmqg1V1oKrmOI/9yhkcUNV7VHWEqo5R1amqmt/q2hzndUNU9S1PlrO15haEq3GItmbtlNaU2jRQY9wkWPa6CIZ6+HyQ2t8kO1sQrjYO6uysHW9NAw2GF6IxEDyLMoOlHhYgjtPSgnCR8rut2TzJsckuH8sb00CD5YVoDATPosxgqYcFiOMkRkcQFR7mMuV3W1NT/3zZn302DTRYXojmRKHYMgyWRZnBUg9PzmIKSCLiWE3dxqZB7c3m8cUspmB5IZpjBVoyR3fpl9SPXRW7XB4PJMFSD2tBuJCcEO1yDKI9vkrRbaucg1OotgyDZVFmsNTDAoQL3srH5A7B8kI0xwrVlmEgZRhoT7DUw7qYXEhOiGbL/kpfF6ND/HmVs+0hceqCpYviVATLosxgqIcFCBeSE6I4WFlD5qOZFB72/zc3f3whhmofurvkXJhzzPMH1jI03mddTC4UVubT2CQUVpTY1NFTFKp96O4SLF0UJrCJqp78rACQnZ2tubm5bnmszN9cDxW3sCd6Lg1he1uOZyRlUPDDArf8jmAX9mAYyomvLUFoWtDkgxIZY1wRkXWqmu3qPmtBuHCwZjsA4drtmOPBPkDoTja7ypjAZwHChR6JsQCEk3TMcXtz6zibXWVM4LMA4cL9k+8EIEy7thyzN7fOsT50YwKfjUG40NDYxKD5b6Lxb1LY9JTfz2IyxphT1d4YhE1zdSEiPIxu8dFcNnIeOVc/4eviGGOMT1gXUxuS46MoPeI6H5MJPsGeGC/Y62c8wwJEG1ISogMm3YY5PcGeMt3X9bPgFLgsQLQhOSGK0qrgbUHYP+23gn1Rny/r5+vgZE6PBYg2pCREU1IZnC0Id/7TBkOgaS8xXrDXz9OCPfgGOwsQbUhJiKLyaAO19Y2+LorbueufNlg+Hba1vqV7bPegrp831vWEalbaYBHyAaKtT4gpCY6tR8uCsJvJXf+0wfLpsK1FfUBQ188b63psRX1gC+kA0d4n4GRngHDHQLW/dVO465/Wnz8dduY5b2tRX1lNmcvz/aF+ndHeokVPvzZtRX1gC+mFcpkLM13m3M9IyuD1azZw9ROree6WCUwd2uOUy3V82mtw/IN4a1Wxqz0ZALeUqb3nz5dJDd31nPtr/dzFW69N2xfEv1myvja09wm4uYup+DRbEP44gwRwSxoMf/106K7n3F/r5y7eem36ajtec/pCOkC019WSnBAFcNqL5fx1Bok7/mn9Nd+Su57zU62fv3UptsWfuwjdJVD+Fv4qpFNttLdrV1xUBHFR4RSf5lRXX24d6Y03AH/czc6dz3ln6xdIO+kF+7amgfS38Fch3YI42SfEQT0TeeGzXSx872uONpzadFebQeJ9vnzOA2lml3WhmZMJ6QAB7fePPv2f45k2shcL3/uGyxauYvX2klN6fF91wwT7G0BbfPmcB1K3jb92EbpLIP0t/FVIz2LqqJVfF/OLpV9SWFbNNePSmH/5sJZpsP7OZpB4V7DPfAok7v5bBOv/UnuzmCxAdFBtfSN/eX8bf125nfjoCH588WCuG9+X2Khwj/1OE3h8Pa3ZfMudf4tg/rvaNFc3iIkM5yeXDuHNu89jcI9Efvl/+Zz1yAoeeWsLe8trfF28oBAMM06CvdsmkLjzbxGq4xnWgjgFqsrnO8t47pOdvLv5ACLCtBG9uPWcTMZndENEvFKOYBLMn9BM4At7MAzlxPdKQWha0OSDErmPdTF50O6yav7x2S6WrCnkcG0Dw3p3YfLgVM4amMyEzG7ERYX0TOIOs75748+C+fVpXUwe1Ld7HD+/fBif/uxCfn3VSBKiw3nm4x3MeXYNox98h+ueXM2f3tnKp9tLaWj0/08avurmsRkn7uHLbrpg6CIE1/Vob0ZgsNTbFY+2IERkGvBnIBz4m6o+ctz9/wV8D2gAioHbVHWX875GIM95aqGqzmjvd/mqBeFKdV0DuQWH+HRHKau3l5JXVE6TOrYxvSyrFzNGp5Gd0Y2wMP/qivJlN08wf0LzFl/+/YKli7C9egAey2vmSz7pYhKRcOBr4GKgCFgLzFLVza3OmQp8rqrVIjIPmKKqNzrvO6KqCR39ff4UII53uLae1dtK+Nemfbz31QFq65vo1SWG6aN6c+XoPmSlJRHuB8HCl2/SwfIG40u+/PsFS4DvbD2Cod6+6mKaCGxT1R2qWgcsAWa2PkFVP1DV5neEz4B0D5bHZ7rERDJtZG/+8p1xrPvFxfz5pjGMTEvifz8t4KrHP2H4r/7NtIUruevF9Sx872v+tWkvW/Yf9nqXlLe6eVw1yUN59o+7uih82U0XaF2EbT3nna2Hu+vd2deCp7u3PDmCmgbsbnW7CJjUzvnfBd5qdTtGRHJxdD89oqpL3V9E74uPjmDmmDRmjkmjorqeFVsOsHnvYbYVH2Hj7nKW5+2juVE3IDWe3107iuzM7l4pmzdy85wsP04oBITW3JkvyJe5lQIpr1N7z3ln6+HOenf2teCNXFN+MUgtIjcD2cDvWx3OcDZ7vgMsFJGBLq6bKyK5IpJbXFzspdK6T1JcJNeMS+cXVwzn+Vsn8vF9F7D5wWksv/tcfnfdKI7WN3H9Xz/lgWX5VB1t8Hh5vJGaI1Tnk7fFnc+HL1OrBFJal/ae887Ww5317uxrwRv/S54MEHuAvq1upzuPHUNELgLmAzNUtSV1qqrucX7fAXwIjD3+WlVdpKrZqpqdmprq3tL7SGxUOCP6JHFDdl/e/tH5/MeZGTy/uoBLF67k4286nwuqM7zRzRNoXRGe5s7nw5fddIHURdjec97Zeriz3r7u3nLFk4PUETgGqS/EERjWAt9R1fxW54wF/glMU9VvWh3vBlSr6lERSQE+BWa2HuA+nj8PUp+uNTvLuO+1TewsqeKG7HTunHoGJUeOsrusht1l1ew+VM3ushoam5SfTx/GmL5dfV3kNgXDoJ472fPhff76nPtqgNwng9Sq2gDcBbwNfAW8oqr5IvKQiDRPWf09kAC8KiIbRWSZ8/gwIFdEvgA+wDEG0WZwCHYT+3fnrXvO447JA/nnuiIm//5Drn3yU3748kb++O7XfLC1mKMNjew+VM11T67mrx9tp6nJPxdABlJXhDeE8vPhq/UD/vqc+7J7q02qGhRf48eP11Dw5Z5y/d9PC/T9rw7oNwcOa01dQ8t95VV1esc/cjXjvn/pfz7zuRZX1vqwpG17YdMLmvFohsoDohmPZugLm17wdZF8KhSfjxc2vaBxOXHKA7R8xeXEea3u/vqcd7Zc7qgHkKttvK9aqo0go6os/ryQh/61maTYSBbeOIZzzkjxdbGMOYa/dvOEova6mCxRUJAREW4+M4PxGd2468X13PzM58w9fwBDeyVSVlXPoao6yqrrOFRVR0VNPdNH9eY7E/tZgkHjVTZZITBYgAhSw3p34Y0fnMsDy/L560c7Wo6HCXSPj6JrXBSqyvzXv+SzHWU8ck0W8dH2cvCkYN1w5lQE0rqJUGbvCEEsLiqC3103mtsnDyRMhO5xUSTGRLTkgGpqUp78aDt/fGcrm/dW8OTN4xncM9HHpQ5O3ljU5E6eDmY5F+a4TK1ysgFWC7LeZWMQhtXbS7j7pQ1UHW3kv68ZydVjgzLjiU8FUp+7t/JidfbNvrOJ9CxwdIztB2FO6sDhWn7w4s1EkYkAABI9SURBVAbWFJTxnUn9+NUVw4mJtO1U3SWQNpzx12DWVrmSY5OpaaixRI+nyAapzUn17BLDi9+fxB/e+ZqnPtrOK2t30zUukq5xUXSPi6JrXCTd46NITYxmQGo8A1ISGJAaT2JMpK+LHhACqc/dXweQ2/r9pTWlJxxrTjlhAeL0WIAwLSLCw7j/sqGce0YKq7eXcKi6nvLqOg5V17GrtJqNu8spraqjsdUivNTEaAamxjO0Vxe+M6mfjWG04VT73H3BX4NZW+Vqi68DWjCwAGFOcO6gFM4d5HrtRF1DE4Vl1ewoPsL24ip2FB9hR0kVS9YWOnJGjejJXVMHkZWe5OVS+7fmT7KB0E/ur8GsrXLFRsS6bEX4OqAFAxuDMG5xqKqO5z7ZyfOrCzhc28D5g1O5a+oZTOzvnVTlxr38dbaQq3JB4O/q5ks2SG28prK2nn98totnVu2ktKqOCZndmDq0B8N6d2F47y70SIxuc1FebX0je8tr6BYXRbf4KC+X3AQyfw1ogcAChPG6mrpGlqwt5O+rCygo/faTXff4KIb1TmRory6owt7yGvaU17C3vIbSqjoA4qPCuf/yYcye2M/v9u02JthYgDA+VVFTz5Z9h/lq32G+2lfJV/sPs3V/JWEipHWLJa1rLH26xpLeLZZeXWJYunEPq74pYVL/7vz22lFkpsT7ugrGBC0LEMbvNDUpIrjsblJVXs0t4tfLN1Pf2MSPLx7Cbef2J9xaE8a4na2DMH6nva4jEeGGCX2ZPCSV+a/nkfPmVyzP28e904ZQ36gcOFzLgYpaDlTWcuDwUcqq6oiOCCMuKpzYqAjio8KJjQonITqCkWlJnDUwmS62XsOYTrMWhPFrqsqyL/bywLJ8DlXXH3Nft7hIenaJoXt8FPWNTVQdbaSmvpGqow3U1DVSVddAk0J4mDCmb1fOG5TCeYNSGJ3elYhwv9iO3Rifsy4mE/DKqupYs7OMlIQoenaJITUx+qSpQOoamthQeIhV35SwalsJm4rKUYXE6Aj6p8YTGxlOXFQ4cVERzu/hpCZGM6JPEiPSutAjMcZLtTPGdyxAGAOUV9exenspq74pYV9FDdV1jS0tjZq6RqrrGqmo+baV0iMxmqy0JEakJTGmbxJnD0zpUH6qA4dr+WhrMUN6JTLaj/cHNwZsDMIYALrGRXF5Vm8uz+rd5jmVtfVs3nuYL/ceJn9PBXl7Kvhg60GaFGIjw5kyJJVpI3sxdWiPY8Y1So8c5a0v9/PGF3tZU1BG8+euCZnd+O65A7h4eE8bZDcBx1oQxpxEdV0D63Yd4u38/bydf4DiyqNEhgtnD0xhYv/ufLajlNXbS2lsUgamxnPl6D5cNKwnn+8s47lPdlJ0qIZ+3eO49ZxMrs/uS4JtzGT8iHUxGeMmTU3Kht3lvJ2/n39/uZ/Csmr6dY/jilG9uXJ0H4b2Sjxm6m5DYxPvbD7AMx/vZN2uQyTGRPCdSf347jn96dGl/TGOhsYmluft4/0tB0mIjiA5Poru8VF0T4gmOT6KpNhIDtfWU3KkjpLKo5QccXyVVdVz3qAUZk/qZ4Px5qQsQBjjAapK8ZGjpCa0nT6ktQ2Fh/jbxzt5K28fEWFhXDs+ndvPH3DCQsCaukZeyd3N06t2UHSohpSEaBqbmiivqae9f9fwMCE5PorYqHB2lVYzvHcXHr56JOP6dWu3XBXV9RyqruvQgsTmWWXPfryTsf26ccfkgfRKssH8QGYBwhg/squ0ikUrd/DquiIaGpu4LKs38yYPJK1rLH//tIC/ry7gUHU94/p15Y7JA7loWE/CwoTGJuVQdR1lVY6v8up6usREkJIYTUpCNF1jIwkLE1SVt77cz0NvbGb/4VpuzO7LfZcNpXur/Fb1jU2s/LqY19YX8d7mg9Q1NnHeoBTumnoGkwYkuyz3l3sqeGBZPrm7DtE/JZ7dZdWEiXDjhL7MmzKQPl1jvfQMGneyAGGMHzp4uJZnPynghc92ceRoA1ERYdQ1NHHRsB7cPnkgEzJPLxPukaMNPLbiG579eCcJMRHcN20oWWlJvL5hD/+3cQ8lR+roHh/FjNF9SEmI4vnVBZQccSRYvOuCQZw/KAURoayqjj+8s5WX1hTSPS6Ke6cN4frxfdlTXsMTH27j1dwiROCGbEegSO8W16HyVdTU88Jnu1i/6xCDeyUyKi2JkWlJpHeL7VCLzLiHBQhj/FhFTT0vfl7I/ooaZp+Z4fZNl74+UMkvln7Jmp1lAESGCxcO7cm149OZPDiVqAjHOEVNXSMvry3kryt3sK+ilqy0JKYO7cHfVxdw5GgD/3lWBj+8aDBJsceuSi86VM2TH27nldzdAFw8vCeXjjhxplez/RW1PPPxDl78vJCqukYyk+MoOlRDg3Mjqm5xkYxMS2J0elfOHZTC+IxuRNpYisdYgDAmxDV3O5VX13PZyF7tplM/2tDI/1u/hyc/3E5hWTXnnJHMgitHnDRw7S2vYdHKHSzP29cy0+vMAclcOqIXlwzvyeHaev760Q6WbtxDY5Nyxag+zD1/ACPTkqitb2Tr/kry9lSQV+SYXvz1gUoampTEmAjOH5zKBUN6MHlIKikJ0e5+ekKaBQhjTKc1NDZRdKiGjOS4TnX5OGZ6HeKd/AO8nb//mHTvMZFh3JDdl++fN4C+3dvviqqsreeTbSW8v+UgH2wtprjyKCIwKr0rM0f34ZpxaXSNa3/fkPy9FbzwWSEVNXXcfGYGZw1Ibrcuh6rqeG51Af/atJf7pw3lkhG9OlTnj74upqGxiQuG9vB699jBylr2V9QyKv3UFmVagDDG+ISq8vWBI7yTv5+wMOGmCX1JPoUWQFOTsnnfYd7fcpB3Nx8gb08F0RFhTM/qzaxJ/cjO6Nbyxny0oZG38vbzv58WsL6wnJjIMGIjwzlUXc+o9CTmnj+AaSN6HTMFeH9FLX9btYMX1xRSXddIj8Royqrq+J9ZY7msnYWVAM99spMH39gMwLlnpLDgyuEMOsVuwsYmZW95DX26xp50YWXV0QaeXrWDRSt30KdrLO/+6PxTCk4WIIwxQWXz3sMsWVvI6+v3UHm0gTN6JHDThL6UVdXx8trdlFbV0T8lnpvPzOC6celER4bx2voi/rZqJztLqujbPZbvnTuAMwck8/zqAl5bV0RDUxMzRvdh3pQz6NM1hlufW8uG3eU8euMYZozuc0IZVJU/vvM1f/lgG5eO6MmZA5J59N2vqaprZM5Zmdxz0aATxmuOd/BwLRt2l7NxdzkbC8vZVFROVV0jvZNiuHZcOteNTz9h+nFDYxOv5Bbx6HtfU1x5lMuzevHTS4fS/xT3TbEAYYwJStV1DSzftI8X1xSyobCcMIGLhvXkP87K4JyBKSeklW9sUt7dfIBFK7ezvrAcgKjwMK7PTuf28wfSL/nbbq+qow3c+vxacgvK+OMNo7l6bPoxj/OLpXm8tGY3syb25eGrsggPO3HG108vHcL12X0pr65je3EV24uPsP3gEbYXH+HrA0fYU14DQESYMKx3F8b07crA1Hg+2FrMqm+KaVKY2L87149P5/Ks3ny6vZRH/r2FbQePkJ3RjZ9dPozxGe2vczkZCxDGmKC3vfgIcVHh9E7q2HqM3IIyNu4u58rRfejZxqr26roGvvf3XD7dUcpvrx3FDdl9qa1v5J4lG3g7/wB3TT2DH18y+ISundZrRmIiw6itb2q5LzoijAGpCZzRI4HR6UmM7deVEX2STkgEub+iltfWF/Fq7m4KSquJDBfqG5UBKfHcO20ol47o6ZbxDgsQxhhzimrrG/n+/+ay6psSfjF9GO9uPsDnO8tYcOVwbj2nf5vXqSpvbNpHbkEZGcnxDEyNZ2BqAmldYzu117qqkrvrEMs37eOMHgncOKGvW6f9WoAwxpjTUFvfyLwX1vHB1mIiwoQ/3jCamWPSfF0st7B038YYcxpiIsN56j/G8+f3vuGcM1I454wUXxfJKyxAGGNMB0RHhHPvtKG+LoZXeXT9uohME5GtIrJNRO53cf9/ichmEdkkIitEJKPVfXNE5Bvn1xxPltMYY8yJPBYgRCQceBy4DBgOzBKR4cedtgHIVtVRwD+B3zmv7Q4sACYBE4EFInJ6c7mMMcZ0iidbEBOBbaq6Q1XrgCXAzNYnqOoHqtq8Dv8zoHmi8aXAu6papqqHgHeBaR4sqzHGmON4MkCkAbtb3S5yHmvLd4G3OnOtiMwVkVwRyS0uLj7N4hpjjGnNL3LoisjNQDbw+85cp6qLVDVbVbNTU1M9UzhjjAlRngwQe4C+rW6nO48dQ0QuAuYDM1T1aGeuNcYY4zmeDBBrgUEi0l9EooCbgGWtTxCRscBfcQSHg63uehu4RES6OQenL3EeM8YY4yUeWwehqg0icheON/Zw4FlVzReRh4BcVV2Go0spAXjVmVOkUFVnqGqZiPwaR5ABeEhVyzxVVmOMMScKmlQbIlIM7DrJaSlAiReK449Cte5W79Bi9e68DFV1OYgbNAGiI0Qkt62cI8EuVOtu9Q4tVm/38otZTMYYY/yPBQhjjDEuhVqAWOTrAvhQqNbd6h1arN5uFFJjEMYYYzou1FoQxhhjOsgChDHGGJdCJkCcbG+KYCEiz4rIQRH5stWx7iLyrnNvjXeDMXW6iPQVkQ+c+4vki8g9zuNBXXcRiRGRNSLyhbPeDzqP9xeRz52v95ed2QyCjoiEi8gGEfmX83ao1LtARPJEZKOI5DqPuf21HhIBooN7UwSL5zkxNfr9wApVHQSscN4ONg3Aj1V1OHAmcKfzbxzsdT8KXKCqo4ExwDQRORP4LfCoqp4BHMKRLTkY3QN81ep2qNQbYKqqjmm1/sHtr/WQCBB0YG+KYKGqK4Hj05LMBP7u/PnvwFVeLZQXqOo+VV3v/LkSx5tGGkFed3U44rwZ6fxS4AIcm3BBENYbQETSgenA35y3hRCodzvc/loPlQDR2b0pgk1PVd3n/Hk/0NOXhfE0EckExgKfEwJ1d3azbAQO4thcaztQrqoNzlOC9fW+ELgXaHLeTiY06g2ODwHviMg6EZnrPOb217rHkvUZ/6SqKiJBO7dZRBKA14AfquphZxJIIHjrrqqNwBgR6Qq8Dgz1cZE8TkSuAA6q6joRmeLr8vjAuaq6R0R6AO+KyJbWd7rrtR4qLYhQ31/igIj0BnB+P3iS8wOSiETiCA6LVfX/OQ+HRN0BVLUc+AA4C+gqIs0fAIPx9X4OMENECnB0GV8A/JngrzcAqrrH+f0gjg8FE/HAaz1UAsRJ96YIcsuAOc6f5wD/58OyeISz//kZ4CtV/VOru4K67iKS6mw5ICKxwMU4xl8+AK5znhZ09VbVn6lquqpm4vh/fl9VZxPk9QYQkXgRSWz+Gcd+OV/igdd6yKykFpHLcfRZNu9NkePjInmEiLwETMGR/vcAsABYCrwC9MOREv2GYNtfQ0TOBVYBeXzbJ/1zHOMQQVt3ERmFY0AyHMcHvldU9SERGYDjk3V3YANwc6sdG4OKs4vpJ6p6RSjU21nH1503I4AXVTVHRJJx82s9ZAKEMcaYzgmVLiZjjDGdZAHCGGOMSxYgjDHGuGQBwhhjjEsWIIwxxrhkAcKYkxCRRmfWzOYvtyX8E5HM1pl3jfEnlmrDmJOrUdUxvi6EMd5mLQhjTpEzJ//vnHn514jIGc7jmSLyvohsEpEVItLPebyniLzu3LvhCxE52/lQ4SLytHM/h3ecK6IRkbud+1tsEpElPqqmCWEWIIw5udjjuphubHVfhapmAX/BsVIf4H+Av6vqKGAx8Jjz+GPAR869G8YB+c7jg4DHVXUEUA5c6zx+PzDW+Th3eKpyxrTFVlIbcxIickRVE1wcL8CxWc8OZ6LA/aqaLCIlQG9VrXce36eqKSJSDKS3Tv3gTE3+rnOTF0TkPiBSVR8WkX8DR3CkSlnaat8HY7zCWhDGnB5t4+fOaJ0rqJFvxwan49gJcRywtlWWUmO8wgKEMafnxlbfP3X+vBpHhlGA2TiSCIJjG8h50LLJT1JbDyoiYUBfVf0AuA9IAk5oxRjjSfaJxJiTi3Xu2Nbs36raPNW1m4hswtEKmOU89gPgORH5KVAM3Oo8fg+wSES+i6OlMA/Yh2vhwAvOICLAY879HozxGhuDMOYUOccgslW1xNdlMcYTrIvJGGOMS9aCMMYY45K1IIwxxrhkAcIYY4xLFiCMMca4ZAHCGGOMSxYgjDHGuPT/AWJ4jcNYxHv3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.21207143366336823 \n",
            "Final Training Accuracy:  0.8132184147834778\n",
            "Final Validation loss:  0.248736172914505 \n",
            "Final Validation Accuracy:  0.7876160740852356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting the Output"
      ],
      "metadata": {
        "id": "ktMf2VVrARVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the activation and inputting it alongside the targets\n",
        "# into the predict_table \n",
        "from pandas.core.arrays.sparse import dtype\n",
        "predict_labels = clasmodl3.predict(Xtst)\n",
        "predict_table = pd.DataFrame(Xtst)\n",
        "predict_table[\"activation\"]=[predict_labels[x,:] for x in range(len(predict_labels))]\n",
        "predict_table[\"target\"]=[one_hot_tst_labels[x,:] for x in range(len(one_hot_tst_labels))]\n",
        "predict_labels = np.around(predict_labels)\n",
        "# Checking which activations match their target i.e accuracy\n",
        "check = np.empty((10,4), dtype=bool)\n",
        "hits = []\n",
        "for i in range(len(predict_labels)):\n",
        "  check[i,:] = predict_labels[i,:] == one_hot_tst_labels[i,:] \n",
        "  if (np.count_nonzero(check[i,:]) == 4):\n",
        "    hits.append(\"Hit\")\n",
        "  else:\n",
        "    hits.append(\"Missed\")\n",
        "predict_table[\"accuracy\"] = hits\n",
        "\n",
        "# Renaming the columns of the table\n",
        "predict_table.columns.values[0] = \"f1\"\n",
        "predict_table.columns.values[1] = \"f2\"\n",
        "predict_table.columns.values[2] = \"f3\"\n",
        "predict_table.columns.values[3] = \"f4\"\n",
        "predict_table.columns.values[4] = \"f5\"\n",
        "predict_table.columns.values[5] = \"f6\"\n",
        "predict_table.columns.values[6] = \"f7\"\n",
        "predict_table.columns.values[7] = \"f8\"\n",
        "predict_table.columns.values[8] = \"f9\"\n",
        "predict_table.columns.values[9] = \"f10\"\n",
        "predict_table.columns.values[10] = \"f11\"\n",
        "predict_table.columns.values[11] = \"f12\"\n",
        "display(predict_table)"
      ],
      "metadata": {
        "id": "uA_kLXhgDF-s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2e4c4759-4a80-47a8-de31-561eb88afde0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-39d39ea1-0f0e-490d-bedb-02c66d3698eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>activation</th>\n",
              "      <th>target</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.20</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.049</td>\n",
              "      <td>44.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.44</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0031860892, 0.64141995, 0.35539395, 1.44440...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>16.3</td>\n",
              "      <td>0.038</td>\n",
              "      <td>43.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>0.99924</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.41</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.00013117753, 0.9493072, 0.050561704, 1.1904...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.034</td>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.98815</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.50</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.005315407, 0.64430344, 0.34066117, 0.0097199]</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>Missed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.045</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[0.00068076415, 0.99382967, 0.005489281, 3.191...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.055</td>\n",
              "      <td>47.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.99340</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.45</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.008190612, 0.9305429, 0.061253186, 1.327338...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.33</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.043</td>\n",
              "      <td>28.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.52</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.011929624, 0.6696059, 0.31846386, 6.014404e...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.027</td>\n",
              "      <td>35.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.98945</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.42</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0012743054, 0.5761531, 0.41784593, 0.004726...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>42.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.99018</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.64</td>\n",
              "      <td>11.733333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0018336708, 0.62893975, 0.35771877, 0.01150...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.32</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.062</td>\n",
              "      <td>31.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99728</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.65</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[0.00017284814, 0.9027755, 0.09705144, 2.43064...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>Missed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.22</td>\n",
              "      <td>10.7</td>\n",
              "      <td>0.042</td>\n",
              "      <td>26.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.36</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0013025034, 0.9679767, 0.030720077, 6.63837...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39d39ea1-0f0e-490d-bedb-02c66d3698eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39d39ea1-0f0e-490d-bedb-02c66d3698eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39d39ea1-0f0e-490d-bedb-02c66d3698eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    f1    f2    f3    f4     f5    f6     f7       f8    f9   f10        f11  \\\n",
              "0  7.4  0.44  0.20  11.5  0.049  44.0  157.0  0.99800  3.27  0.44   9.000000   \n",
              "1  6.5  0.23  0.36  16.3  0.038  43.0  133.0  0.99924  3.26  0.41   8.800000   \n",
              "2  5.6  0.41  0.24   1.9  0.034  10.0   53.0  0.98815  3.32  0.50  13.500000   \n",
              "3  6.4  0.67  0.08   2.1  0.045  19.0   48.0  0.99490  3.49  0.49  11.400000   \n",
              "4  6.8  0.18  0.37   1.6  0.055  47.0  154.0  0.99340  3.08  0.45   9.100000   \n",
              "5  6.9  0.41  0.33  10.1  0.043  28.0  152.0  0.99680  3.20  0.52   9.400000   \n",
              "6  5.9  0.32  0.33   2.1  0.027  35.0  138.0  0.98945  3.37  0.42  12.700000   \n",
              "7  6.0  0.24  0.41   1.3  0.036  42.0  118.0  0.99018  3.04  0.64  11.733333   \n",
              "8  7.3  0.48  0.32   2.1  0.062  31.0   54.0  0.99728  3.30  0.65  10.000000   \n",
              "9  7.4  0.24  0.22  10.7  0.042  26.0   81.0  0.99540  2.86  0.36   9.700000   \n",
              "\n",
              "   f12                                         activation  \\\n",
              "0  0.0  [0.0031860892, 0.64141995, 0.35539395, 1.44440...   \n",
              "1  0.0  [0.00013117753, 0.9493072, 0.050561704, 1.1904...   \n",
              "2  0.0   [0.005315407, 0.64430344, 0.34066117, 0.0097199]   \n",
              "3  1.0  [0.00068076415, 0.99382967, 0.005489281, 3.191...   \n",
              "4  0.0  [0.008190612, 0.9305429, 0.061253186, 1.327338...   \n",
              "5  0.0  [0.011929624, 0.6696059, 0.31846386, 6.014404e...   \n",
              "6  0.0  [0.0012743054, 0.5761531, 0.41784593, 0.004726...   \n",
              "7  0.0  [0.0018336708, 0.62893975, 0.35771877, 0.01150...   \n",
              "8  1.0  [0.00017284814, 0.9027755, 0.09705144, 2.43064...   \n",
              "9  0.0  [0.0013025034, 0.9679767, 0.030720077, 6.63837...   \n",
              "\n",
              "                 target accuracy  \n",
              "0  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "1  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "2  [0.0, 0.0, 1.0, 0.0]   Missed  \n",
              "3  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "4  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "5  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "6  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "7  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "8  [0.0, 0.0, 1.0, 0.0]   Missed  \n",
              "9  [0.0, 1.0, 0.0, 0.0]      Hit  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
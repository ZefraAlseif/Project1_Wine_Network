{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassificationModel_Wine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "D5MXeNqXMXe6",
        "umwZABDXo4FT",
        "6sMVEJYkt6hO",
        "qUavWkEcvnCj",
        "uyPkgYySwlGS",
        "Ug0InJvL07v-",
        "aH9nWFQq2zd3",
        "nCo55yH45zx2",
        "ktMf2VVrARVH"
      ],
      "history_visible": true,
      "authorship_tag": "ABX9TyOFxmuTDZF5Zt0Q3bdFcT+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZefraAlseif/Project1_Wine_Network/blob/main/ClassificationModel_Wine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adapting the original wine data to a regression model and classification model"
      ],
      "metadata": {
        "id": "D5MXeNqXMXe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data as Numpy Arrays\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# This time we need to also import pandas\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Read in white wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
        "\n",
        "# Read in red wine data\n",
        "# Uses PANDAS (pd) to create a PANDAS DataFrame Object:\n",
        "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep =';')\n",
        "\n",
        "red['type'] = 1\n",
        "white['type'] = 0\n",
        "\n",
        "wines = red.append(white, ignore_index = True)\n",
        "\n",
        "# Import SKLEARN\n",
        "import sklearn\n",
        "\n",
        "# Import `train_test_split` from `sklearn.model_selection`\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Specify the data -\n",
        "X1 = wines.iloc[:, 0:11]\n",
        "X2 = wines.iloc[:,12]\n",
        "X = pd.concat([X1,X2],axis = 1)\n",
        "\n",
        "y = np.ravel(wines.quality)\n",
        "\n",
        "# Splitting the data set for training and validating - Done with SKLEARN\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size = 0.25, random_state = 45)\n",
        "\n",
        "# Converting X_train & X_test DataFrame s to TF sensors\n",
        "# Will use NumPy, TF, & Keras after this\n",
        "# import tensorflow as tf\n",
        "\n",
        "Xtrain = X_train.to_numpy()\n",
        "X_valid = X_valid.to_numpy()\n",
        "\n",
        "X_valid\n",
        "# In reality:\n",
        "# [1] ALL THE Xtrain patterns (with their y_train targets)\n",
        "# will be used for TRAINING ([TR]), as Xtrain & y_train\n",
        "# [2] MOST OF THE X_valid patterns (and their y_valid targets)\n",
        "# will be used for VALIDATION ([TT]), as X_val & y_val\n",
        "# BUT WE WILL SET ASIDE THE LAST 10 for \"testing\" ([TS])\n",
        "# as X_tst & y_tst\n",
        "\n",
        "# Retain the first 1615 patterns for validation ([TT])\n",
        "Xval = X_valid[:1615]\n",
        "Xval.shape\n",
        "\n",
        "# and now set aside the last 10 for test\n",
        "Xtst = X_valid[1615:]\n",
        "Xtst.shape\n",
        "\n",
        "# Same for the corresponding targets\n",
        "# Retain the first 1615 for validation ([TT])\n",
        "y_val = y_valid[:1615]\n",
        "y_val.shape\n",
        "\n",
        "y_tst = y_valid[1615:]\n",
        "y_tst.shape \n",
        "y_tst\n",
        "\n",
        "# Now, in addition, create the targets as one-hot-encoded 4 quality levels\n",
        "# We will track these few targets through the conversion process\n",
        "y_train[272:283]\n",
        "\n",
        "# Function create rank-1 arrays where 3,4,5,6,7,8,9 are mapped to 1 or 2 or 3 or 4 \n",
        "def to_4cs(x):\n",
        "  lx = len(x)\n",
        "  results = np.zeros(lx)\n",
        "  for i in range(lx):\n",
        "    # print(\"start\")\n",
        "    xa = x[i];\n",
        "    if xa <= 3:\n",
        "      results[i] = 1\n",
        "    elif xa <= 6:\n",
        "      results[i] = 2\n",
        "    elif xa <= 8:\n",
        "      results[i] = 3\n",
        "    else:\n",
        "      results[i] = 4\n",
        "    # results [i, label] = 1\n",
        "  results = results.astype(int)\n",
        "  return results\n",
        "\n",
        "train_labels = to_4cs(y_train)\n",
        "val_labels = to_4cs(y_val)\n",
        "tst_labels = to_4cs(y_tst)\n",
        "\n",
        "# Let's verify that the training targets that we are tracking \n",
        "# were converted to levels (1 = BAD; 2 = Medium; 3 = GOOD; 4- Excellent) correctly:\n",
        "train_labels[272:283]\n",
        "\n",
        "# Now, one shot encoding of all 3 target arrays\n",
        "# define a function to do the \n",
        "\n",
        "def to_one_hot(labels, dimension = 4):\n",
        "  results = np.zeros((len(labels), dimension))\n",
        "  for i, label in enumerate(labels-1):\n",
        "    results[i, label] = 1.\n",
        "  return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_val_labels = to_one_hot(val_labels)\n",
        "one_hot_tst_labels = to_one_hot(tst_labels)\n",
        "\n",
        "#Let's verify that the training targets we have tracked were\n",
        "# one-hot encoded correctly\n",
        "Xtrain.shape\n",
        "\n",
        "# SO, AFTER EXECUTING THIS CELL, YOU WILL HAVE:\n",
        "# FOR TRAINING:\n",
        "# Xtrain (4872, 12)...y_train (4872,)...train_labels(4872,)....one_hot_train_labels (4872,4)\n",
        "# FOR VALIDATING:\n",
        "# Xval (1615, 12)...y_val (1615,)...val_labels(1615,)...one_hot_val_labels (1615,4)\n",
        "# FOR TESTING:\n",
        "# Xtst (10, 12)...y_tst (10,)...tst_labels(10,)... one_hot_tst_labels (10,4)\n",
        "# PLEASE DO NOT CHANGE THE NAMES OF THESE VARIABLES (So that instructor can use them)\n"
      ],
      "metadata": {
        "id": "RALOila3bW_c",
        "cellView": "code",
        "outputId": "85a124f9-5599-4412-8011-d8b4db3dc41a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4872, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NrLabofBokqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.0 Estimating"
      ],
      "metadata": {
        "id": "umwZABDXo4FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "y_val_copy = copy.copy(y_val)\n",
        "np.random.shuffle(y_val)\n",
        "hits_array = np.array(y_val) == np.array(y_val_copy)\n",
        "print(\"Accuracy using random classifier \",hits_array.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9r_dUNIo_0q",
        "outputId": "51f3bac5-9678-4b3a-ebc3-031f9cb19429"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using random classifier  0.33622291021671824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.1 Classification Model 1 (clasmodl1)"
      ],
      "metadata": {
        "id": "6sMVEJYkt6hO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl1():\n",
        "  clasmodl1 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(8, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl1.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl1\n",
        "\n",
        "clasmodl1 = build_clasmodl1()\n",
        "history_clasmodl1 = clasmodl1.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 32, epochs = 50, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "\n",
        "clasmodl1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efgVAKb2uAn6",
        "outputId": "13f81706-167f-4bfa-a8cb-046f150eb812"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "153/153 - 1s - loss: 2.0238 - accuracy: 0.6517 - val_loss: 1.4084 - val_accuracy: 0.5313 - 878ms/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "153/153 - 0s - loss: 0.8669 - accuracy: 0.7685 - val_loss: 0.8796 - val_accuracy: 0.7845 - 280ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "153/153 - 0s - loss: 0.6998 - accuracy: 0.7869 - val_loss: 0.6690 - val_accuracy: 0.7845 - 341ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "153/153 - 0s - loss: 0.6400 - accuracy: 0.7880 - val_loss: 0.8309 - val_accuracy: 0.7839 - 253ms/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "153/153 - 0s - loss: 0.6007 - accuracy: 0.7904 - val_loss: 0.6707 - val_accuracy: 0.7214 - 253ms/epoch - 2ms/step\n",
            "Epoch 6/50\n",
            "153/153 - 0s - loss: 0.5852 - accuracy: 0.7869 - val_loss: 0.5767 - val_accuracy: 0.7858 - 271ms/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "153/153 - 0s - loss: 0.5717 - accuracy: 0.7865 - val_loss: 0.6972 - val_accuracy: 0.6898 - 252ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "153/153 - 0s - loss: 0.5666 - accuracy: 0.7855 - val_loss: 0.5585 - val_accuracy: 0.7802 - 258ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "153/153 - 0s - loss: 0.5480 - accuracy: 0.7945 - val_loss: 1.8977 - val_accuracy: 0.3399 - 253ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "153/153 - 0s - loss: 0.5556 - accuracy: 0.7872 - val_loss: 0.5593 - val_accuracy: 0.7858 - 259ms/epoch - 2ms/step\n",
            "Epoch 11/50\n",
            "153/153 - 0s - loss: 0.5478 - accuracy: 0.7892 - val_loss: 1.6074 - val_accuracy: 0.3579 - 261ms/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "153/153 - 0s - loss: 0.5411 - accuracy: 0.7859 - val_loss: 0.5819 - val_accuracy: 0.7820 - 259ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "153/153 - 0s - loss: 0.5351 - accuracy: 0.7900 - val_loss: 0.7554 - val_accuracy: 0.7833 - 266ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "153/153 - 0s - loss: 0.5294 - accuracy: 0.7853 - val_loss: 0.6202 - val_accuracy: 0.7833 - 258ms/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "153/153 - 0s - loss: 0.5139 - accuracy: 0.7966 - val_loss: 0.5119 - val_accuracy: 0.7864 - 253ms/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "153/153 - 0s - loss: 0.5125 - accuracy: 0.7925 - val_loss: 0.7462 - val_accuracy: 0.5870 - 259ms/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "153/153 - 0s - loss: 0.5094 - accuracy: 0.7906 - val_loss: 0.5982 - val_accuracy: 0.7684 - 357ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "153/153 - 0s - loss: 0.5054 - accuracy: 0.7921 - val_loss: 0.5145 - val_accuracy: 0.7851 - 252ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "153/153 - 0s - loss: 0.4988 - accuracy: 0.7962 - val_loss: 0.6281 - val_accuracy: 0.7146 - 260ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "153/153 - 0s - loss: 0.5024 - accuracy: 0.7929 - val_loss: 0.5078 - val_accuracy: 0.7827 - 261ms/epoch - 2ms/step\n",
            "Epoch 21/50\n",
            "153/153 - 0s - loss: 0.5024 - accuracy: 0.7880 - val_loss: 0.6813 - val_accuracy: 0.7833 - 264ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "153/153 - 0s - loss: 0.4951 - accuracy: 0.7947 - val_loss: 0.6383 - val_accuracy: 0.7833 - 248ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "153/153 - 0s - loss: 0.4990 - accuracy: 0.7917 - val_loss: 0.5551 - val_accuracy: 0.7721 - 265ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "153/153 - 0s - loss: 0.4962 - accuracy: 0.7947 - val_loss: 0.7356 - val_accuracy: 0.7839 - 258ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "153/153 - 0s - loss: 0.4896 - accuracy: 0.7972 - val_loss: 0.5139 - val_accuracy: 0.7839 - 269ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "153/153 - 0s - loss: 0.4895 - accuracy: 0.7962 - val_loss: 0.5500 - val_accuracy: 0.7684 - 257ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "153/153 - 0s - loss: 0.4960 - accuracy: 0.7917 - val_loss: 0.5243 - val_accuracy: 0.7858 - 256ms/epoch - 2ms/step\n",
            "Epoch 28/50\n",
            "153/153 - 0s - loss: 0.4870 - accuracy: 0.7970 - val_loss: 0.6470 - val_accuracy: 0.7839 - 251ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "153/153 - 0s - loss: 0.4850 - accuracy: 0.7974 - val_loss: 0.5633 - val_accuracy: 0.7653 - 276ms/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "153/153 - 0s - loss: 0.4920 - accuracy: 0.7863 - val_loss: 0.5086 - val_accuracy: 0.7901 - 270ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "153/153 - 0s - loss: 0.4823 - accuracy: 0.7976 - val_loss: 0.4984 - val_accuracy: 0.7870 - 262ms/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "153/153 - 0s - loss: 0.4853 - accuracy: 0.7972 - val_loss: 0.5369 - val_accuracy: 0.7820 - 266ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "153/153 - 0s - loss: 0.4875 - accuracy: 0.7974 - val_loss: 0.5069 - val_accuracy: 0.7833 - 260ms/epoch - 2ms/step\n",
            "Epoch 34/50\n",
            "153/153 - 0s - loss: 0.4828 - accuracy: 0.7935 - val_loss: 0.5162 - val_accuracy: 0.7833 - 255ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "153/153 - 0s - loss: 0.4824 - accuracy: 0.8007 - val_loss: 0.5016 - val_accuracy: 0.7882 - 253ms/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "153/153 - 0s - loss: 0.4793 - accuracy: 0.7966 - val_loss: 0.5998 - val_accuracy: 0.7827 - 258ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "153/153 - 0s - loss: 0.4777 - accuracy: 0.8001 - val_loss: 0.5444 - val_accuracy: 0.7820 - 258ms/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "153/153 - 0s - loss: 0.4738 - accuracy: 0.7991 - val_loss: 1.0631 - val_accuracy: 0.4483 - 276ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "153/153 - 0s - loss: 0.4765 - accuracy: 0.8011 - val_loss: 0.5530 - val_accuracy: 0.7814 - 261ms/epoch - 2ms/step\n",
            "Epoch 40/50\n",
            "153/153 - 0s - loss: 0.4830 - accuracy: 0.7976 - val_loss: 0.6018 - val_accuracy: 0.7839 - 272ms/epoch - 2ms/step\n",
            "Epoch 41/50\n",
            "153/153 - 0s - loss: 0.4810 - accuracy: 0.7964 - val_loss: 0.6010 - val_accuracy: 0.7839 - 255ms/epoch - 2ms/step\n",
            "Epoch 42/50\n",
            "153/153 - 0s - loss: 0.4798 - accuracy: 0.7892 - val_loss: 0.5365 - val_accuracy: 0.7678 - 259ms/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "153/153 - 0s - loss: 0.4832 - accuracy: 0.7989 - val_loss: 0.5773 - val_accuracy: 0.7839 - 249ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "153/153 - 0s - loss: 0.4753 - accuracy: 0.8017 - val_loss: 0.5556 - val_accuracy: 0.7591 - 265ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "153/153 - 0s - loss: 0.4814 - accuracy: 0.7960 - val_loss: 0.4894 - val_accuracy: 0.7950 - 268ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "153/153 - 0s - loss: 0.4716 - accuracy: 0.8040 - val_loss: 0.6334 - val_accuracy: 0.6935 - 254ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "153/153 - 0s - loss: 0.4665 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7938 - 273ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "153/153 - 0s - loss: 0.4810 - accuracy: 0.8013 - val_loss: 0.4956 - val_accuracy: 0.7907 - 260ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "153/153 - 0s - loss: 0.4776 - accuracy: 0.7960 - val_loss: 0.5806 - val_accuracy: 0.7845 - 251ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "153/153 - 0s - loss: 0.4757 - accuracy: 0.8042 - val_loss: 0.4919 - val_accuracy: 0.7920 - 262ms/epoch - 2ms/step\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 140\n",
            "Trainable params: 140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Classification Model 1 and Final Values"
      ],
      "metadata": {
        "id": "qUavWkEcvnCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl1.history['val_loss']) + 1), history_clasmodl1.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl1.history['loss']) + 1), history_clasmodl1.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl1.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl1.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl1.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl1.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "SAUCbNZpvsG7",
        "outputId": "60d8f505-99cc-40fc-d2f9-382cecef6276"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.475739061832428 \n",
            "Final Training Accuracy:  0.8041871786117554\n",
            "Final Validation loss:  0.4918537437915802 \n",
            "Final Validation Accuracy:  0.7919504642486572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.2 Classification Model 2 (clasmodl2)"
      ],
      "metadata": {
        "id": "uyPkgYySwlGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl2():\n",
        "  clasmodl2 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(512, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(30, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl2.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl2\n",
        "\n",
        "clasmodl2 = build_clasmodl2()\n",
        "history_clasmodl2 = clasmodl2.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 128, epochs = 200, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "\n",
        "#clasmodl2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YtEXogowx_y",
        "outputId": "f7fbef32-f3ad-4c70-fd61-fdc0716cca25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 - 1s - loss: 1.0255 - accuracy: 0.7410 - val_loss: 0.6067 - val_accuracy: 0.7839 - 1s/epoch - 28ms/step\n",
            "Epoch 2/200\n",
            "39/39 - 0s - loss: 0.6788 - accuracy: 0.7705 - val_loss: 0.7608 - val_accuracy: 0.7839 - 197ms/epoch - 5ms/step\n",
            "Epoch 3/200\n",
            "39/39 - 0s - loss: 0.5451 - accuracy: 0.8034 - val_loss: 0.6564 - val_accuracy: 0.6656 - 186ms/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "39/39 - 0s - loss: 0.5776 - accuracy: 0.7849 - val_loss: 0.5734 - val_accuracy: 0.7820 - 232ms/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "39/39 - 0s - loss: 0.5363 - accuracy: 0.8032 - val_loss: 0.6347 - val_accuracy: 0.7839 - 240ms/epoch - 6ms/step\n",
            "Epoch 6/200\n",
            "39/39 - 0s - loss: 0.5489 - accuracy: 0.7894 - val_loss: 0.5551 - val_accuracy: 0.7839 - 232ms/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "39/39 - 0s - loss: 0.5265 - accuracy: 0.8030 - val_loss: 0.5475 - val_accuracy: 0.7839 - 194ms/epoch - 5ms/step\n",
            "Epoch 8/200\n",
            "39/39 - 0s - loss: 0.5256 - accuracy: 0.8032 - val_loss: 0.6166 - val_accuracy: 0.7839 - 201ms/epoch - 5ms/step\n",
            "Epoch 9/200\n",
            "39/39 - 0s - loss: 0.5132 - accuracy: 0.8034 - val_loss: 0.5763 - val_accuracy: 0.7820 - 192ms/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "39/39 - 0s - loss: 0.5146 - accuracy: 0.8015 - val_loss: 0.5691 - val_accuracy: 0.7839 - 225ms/epoch - 6ms/step\n",
            "Epoch 11/200\n",
            "39/39 - 0s - loss: 0.5071 - accuracy: 0.8040 - val_loss: 0.7081 - val_accuracy: 0.7839 - 195ms/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "39/39 - 0s - loss: 0.5087 - accuracy: 0.8025 - val_loss: 0.6773 - val_accuracy: 0.7839 - 191ms/epoch - 5ms/step\n",
            "Epoch 13/200\n",
            "39/39 - 0s - loss: 0.5013 - accuracy: 0.8034 - val_loss: 0.5490 - val_accuracy: 0.7845 - 236ms/epoch - 6ms/step\n",
            "Epoch 14/200\n",
            "39/39 - 0s - loss: 0.4940 - accuracy: 0.8042 - val_loss: 1.0040 - val_accuracy: 0.7839 - 188ms/epoch - 5ms/step\n",
            "Epoch 15/200\n",
            "39/39 - 0s - loss: 0.5072 - accuracy: 0.8009 - val_loss: 0.6865 - val_accuracy: 0.7839 - 208ms/epoch - 5ms/step\n",
            "Epoch 16/200\n",
            "39/39 - 0s - loss: 0.4908 - accuracy: 0.8030 - val_loss: 0.6347 - val_accuracy: 0.6279 - 193ms/epoch - 5ms/step\n",
            "Epoch 17/200\n",
            "39/39 - 0s - loss: 0.4889 - accuracy: 0.7993 - val_loss: 0.5022 - val_accuracy: 0.7839 - 235ms/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "39/39 - 0s - loss: 0.4730 - accuracy: 0.8038 - val_loss: 0.7165 - val_accuracy: 0.7839 - 231ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "39/39 - 0s - loss: 0.4864 - accuracy: 0.8015 - val_loss: 0.6837 - val_accuracy: 0.7839 - 189ms/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "39/39 - 0s - loss: 0.4715 - accuracy: 0.8030 - val_loss: 0.5509 - val_accuracy: 0.7827 - 245ms/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "39/39 - 0s - loss: 0.4671 - accuracy: 0.8050 - val_loss: 0.9163 - val_accuracy: 0.7845 - 230ms/epoch - 6ms/step\n",
            "Epoch 22/200\n",
            "39/39 - 0s - loss: 0.4737 - accuracy: 0.8030 - val_loss: 0.4978 - val_accuracy: 0.7833 - 231ms/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "39/39 - 0s - loss: 0.4609 - accuracy: 0.8034 - val_loss: 0.5155 - val_accuracy: 0.7870 - 212ms/epoch - 5ms/step\n",
            "Epoch 24/200\n",
            "39/39 - 0s - loss: 0.4625 - accuracy: 0.8023 - val_loss: 0.5725 - val_accuracy: 0.7845 - 252ms/epoch - 6ms/step\n",
            "Epoch 25/200\n",
            "39/39 - 0s - loss: 0.4564 - accuracy: 0.8058 - val_loss: 0.5382 - val_accuracy: 0.7833 - 196ms/epoch - 5ms/step\n",
            "Epoch 26/200\n",
            "39/39 - 0s - loss: 0.4819 - accuracy: 0.8044 - val_loss: 0.6448 - val_accuracy: 0.6155 - 234ms/epoch - 6ms/step\n",
            "Epoch 27/200\n",
            "39/39 - 0s - loss: 0.4650 - accuracy: 0.8007 - val_loss: 0.5201 - val_accuracy: 0.7845 - 203ms/epoch - 5ms/step\n",
            "Epoch 28/200\n",
            "39/39 - 0s - loss: 0.4531 - accuracy: 0.8042 - val_loss: 0.5270 - val_accuracy: 0.7839 - 223ms/epoch - 6ms/step\n",
            "Epoch 29/200\n",
            "39/39 - 0s - loss: 0.4553 - accuracy: 0.7999 - val_loss: 0.5882 - val_accuracy: 0.7839 - 205ms/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "39/39 - 0s - loss: 0.4525 - accuracy: 0.8009 - val_loss: 0.5272 - val_accuracy: 0.7851 - 190ms/epoch - 5ms/step\n",
            "Epoch 31/200\n",
            "39/39 - 0s - loss: 0.4477 - accuracy: 0.8060 - val_loss: 0.8253 - val_accuracy: 0.7839 - 190ms/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "39/39 - 0s - loss: 0.4453 - accuracy: 0.8064 - val_loss: 0.6017 - val_accuracy: 0.7839 - 197ms/epoch - 5ms/step\n",
            "Epoch 33/200\n",
            "39/39 - 0s - loss: 0.4451 - accuracy: 0.8048 - val_loss: 0.7386 - val_accuracy: 0.5839 - 193ms/epoch - 5ms/step\n",
            "Epoch 34/200\n",
            "39/39 - 0s - loss: 0.4471 - accuracy: 0.8013 - val_loss: 0.6817 - val_accuracy: 0.7851 - 210ms/epoch - 5ms/step\n",
            "Epoch 35/200\n",
            "39/39 - 0s - loss: 0.4432 - accuracy: 0.8034 - val_loss: 0.5958 - val_accuracy: 0.7851 - 236ms/epoch - 6ms/step\n",
            "Epoch 36/200\n",
            "39/39 - 0s - loss: 0.4447 - accuracy: 0.8114 - val_loss: 0.4888 - val_accuracy: 0.7889 - 224ms/epoch - 6ms/step\n",
            "Epoch 37/200\n",
            "39/39 - 0s - loss: 0.4488 - accuracy: 0.8042 - val_loss: 0.5066 - val_accuracy: 0.7820 - 187ms/epoch - 5ms/step\n",
            "Epoch 38/200\n",
            "39/39 - 0s - loss: 0.4432 - accuracy: 0.8048 - val_loss: 0.5822 - val_accuracy: 0.7845 - 222ms/epoch - 6ms/step\n",
            "Epoch 39/200\n",
            "39/39 - 0s - loss: 0.4432 - accuracy: 0.8050 - val_loss: 0.5491 - val_accuracy: 0.7498 - 194ms/epoch - 5ms/step\n",
            "Epoch 40/200\n",
            "39/39 - 0s - loss: 0.4393 - accuracy: 0.8064 - val_loss: 0.4737 - val_accuracy: 0.7920 - 202ms/epoch - 5ms/step\n",
            "Epoch 41/200\n",
            "39/39 - 0s - loss: 0.4365 - accuracy: 0.8071 - val_loss: 0.5284 - val_accuracy: 0.7864 - 237ms/epoch - 6ms/step\n",
            "Epoch 42/200\n",
            "39/39 - 0s - loss: 0.4396 - accuracy: 0.8097 - val_loss: 0.5435 - val_accuracy: 0.7827 - 194ms/epoch - 5ms/step\n",
            "Epoch 43/200\n",
            "39/39 - 0s - loss: 0.4401 - accuracy: 0.8054 - val_loss: 0.6628 - val_accuracy: 0.7839 - 228ms/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "39/39 - 0s - loss: 0.4503 - accuracy: 0.8110 - val_loss: 0.5748 - val_accuracy: 0.7715 - 196ms/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "39/39 - 0s - loss: 0.4361 - accuracy: 0.8071 - val_loss: 0.6212 - val_accuracy: 0.6743 - 235ms/epoch - 6ms/step\n",
            "Epoch 46/200\n",
            "39/39 - 0s - loss: 0.4372 - accuracy: 0.8071 - val_loss: 0.6319 - val_accuracy: 0.7876 - 229ms/epoch - 6ms/step\n",
            "Epoch 47/200\n",
            "39/39 - 0s - loss: 0.4274 - accuracy: 0.8128 - val_loss: 0.7891 - val_accuracy: 0.7845 - 200ms/epoch - 5ms/step\n",
            "Epoch 48/200\n",
            "39/39 - 0s - loss: 0.4366 - accuracy: 0.8124 - val_loss: 0.4837 - val_accuracy: 0.7889 - 202ms/epoch - 5ms/step\n",
            "Epoch 49/200\n",
            "39/39 - 0s - loss: 0.4299 - accuracy: 0.8073 - val_loss: 0.6742 - val_accuracy: 0.7851 - 193ms/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "39/39 - 0s - loss: 0.4322 - accuracy: 0.8126 - val_loss: 0.4808 - val_accuracy: 0.7876 - 199ms/epoch - 5ms/step\n",
            "Epoch 51/200\n",
            "39/39 - 0s - loss: 0.4277 - accuracy: 0.8118 - val_loss: 1.0504 - val_accuracy: 0.7839 - 210ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "39/39 - 0s - loss: 0.4349 - accuracy: 0.8122 - val_loss: 0.5011 - val_accuracy: 0.7765 - 207ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "39/39 - 0s - loss: 0.4275 - accuracy: 0.8132 - val_loss: 0.4810 - val_accuracy: 0.7950 - 218ms/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "39/39 - 0s - loss: 0.4304 - accuracy: 0.8108 - val_loss: 0.6299 - val_accuracy: 0.7845 - 207ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "39/39 - 0s - loss: 0.4304 - accuracy: 0.8120 - val_loss: 0.4865 - val_accuracy: 0.7864 - 234ms/epoch - 6ms/step\n",
            "Epoch 56/200\n",
            "39/39 - 0s - loss: 0.4164 - accuracy: 0.8181 - val_loss: 0.5778 - val_accuracy: 0.7858 - 198ms/epoch - 5ms/step\n",
            "Epoch 57/200\n",
            "39/39 - 0s - loss: 0.4253 - accuracy: 0.8114 - val_loss: 0.4681 - val_accuracy: 0.7969 - 238ms/epoch - 6ms/step\n",
            "Epoch 58/200\n",
            "39/39 - 0s - loss: 0.4221 - accuracy: 0.8186 - val_loss: 0.4837 - val_accuracy: 0.7975 - 211ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "39/39 - 0s - loss: 0.4185 - accuracy: 0.8202 - val_loss: 0.4871 - val_accuracy: 0.7920 - 210ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "39/39 - 0s - loss: 0.4253 - accuracy: 0.8155 - val_loss: 0.4876 - val_accuracy: 0.7808 - 210ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "39/39 - 0s - loss: 0.4180 - accuracy: 0.8144 - val_loss: 0.4989 - val_accuracy: 0.7839 - 193ms/epoch - 5ms/step\n",
            "Epoch 62/200\n",
            "39/39 - 0s - loss: 0.4181 - accuracy: 0.8167 - val_loss: 0.5214 - val_accuracy: 0.7851 - 191ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "39/39 - 0s - loss: 0.4165 - accuracy: 0.8171 - val_loss: 0.6535 - val_accuracy: 0.6526 - 201ms/epoch - 5ms/step\n",
            "Epoch 64/200\n",
            "39/39 - 0s - loss: 0.4260 - accuracy: 0.8151 - val_loss: 0.4948 - val_accuracy: 0.7895 - 207ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "39/39 - 0s - loss: 0.4118 - accuracy: 0.8179 - val_loss: 0.5408 - val_accuracy: 0.7864 - 191ms/epoch - 5ms/step\n",
            "Epoch 66/200\n",
            "39/39 - 0s - loss: 0.4163 - accuracy: 0.8114 - val_loss: 0.4660 - val_accuracy: 0.7969 - 236ms/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "39/39 - 0s - loss: 0.4170 - accuracy: 0.8151 - val_loss: 0.5898 - val_accuracy: 0.7858 - 233ms/epoch - 6ms/step\n",
            "Epoch 68/200\n",
            "39/39 - 0s - loss: 0.4102 - accuracy: 0.8181 - val_loss: 0.5104 - val_accuracy: 0.7789 - 207ms/epoch - 5ms/step\n",
            "Epoch 69/200\n",
            "39/39 - 0s - loss: 0.4193 - accuracy: 0.8159 - val_loss: 0.5648 - val_accuracy: 0.7882 - 207ms/epoch - 5ms/step\n",
            "Epoch 70/200\n",
            "39/39 - 0s - loss: 0.4217 - accuracy: 0.8218 - val_loss: 0.5387 - val_accuracy: 0.7858 - 208ms/epoch - 5ms/step\n",
            "Epoch 71/200\n",
            "39/39 - 0s - loss: 0.4119 - accuracy: 0.8239 - val_loss: 0.5680 - val_accuracy: 0.7882 - 198ms/epoch - 5ms/step\n",
            "Epoch 72/200\n",
            "39/39 - 0s - loss: 0.4143 - accuracy: 0.8177 - val_loss: 0.5642 - val_accuracy: 0.7622 - 246ms/epoch - 6ms/step\n",
            "Epoch 73/200\n",
            "39/39 - 0s - loss: 0.4115 - accuracy: 0.8175 - val_loss: 0.8377 - val_accuracy: 0.7870 - 200ms/epoch - 5ms/step\n",
            "Epoch 74/200\n",
            "39/39 - 0s - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.6414 - val_accuracy: 0.7864 - 197ms/epoch - 5ms/step\n",
            "Epoch 75/200\n",
            "39/39 - 0s - loss: 0.4078 - accuracy: 0.8259 - val_loss: 0.6064 - val_accuracy: 0.7864 - 198ms/epoch - 5ms/step\n",
            "Epoch 76/200\n",
            "39/39 - 0s - loss: 0.4090 - accuracy: 0.8196 - val_loss: 0.5077 - val_accuracy: 0.7913 - 227ms/epoch - 6ms/step\n",
            "Epoch 77/200\n",
            "39/39 - 0s - loss: 0.4142 - accuracy: 0.8142 - val_loss: 0.4708 - val_accuracy: 0.8012 - 249ms/epoch - 6ms/step\n",
            "Epoch 78/200\n",
            "39/39 - 0s - loss: 0.4070 - accuracy: 0.8206 - val_loss: 0.6450 - val_accuracy: 0.6737 - 200ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "39/39 - 0s - loss: 0.4077 - accuracy: 0.8186 - val_loss: 0.5932 - val_accuracy: 0.7858 - 209ms/epoch - 5ms/step\n",
            "Epoch 80/200\n",
            "39/39 - 0s - loss: 0.4061 - accuracy: 0.8175 - val_loss: 0.5550 - val_accuracy: 0.7381 - 199ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "39/39 - 0s - loss: 0.4075 - accuracy: 0.8165 - val_loss: 0.6035 - val_accuracy: 0.6954 - 231ms/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "39/39 - 0s - loss: 0.4002 - accuracy: 0.8233 - val_loss: 0.5969 - val_accuracy: 0.7381 - 202ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "39/39 - 0s - loss: 0.4065 - accuracy: 0.8198 - val_loss: 0.6432 - val_accuracy: 0.7870 - 233ms/epoch - 6ms/step\n",
            "Epoch 84/200\n",
            "39/39 - 0s - loss: 0.4058 - accuracy: 0.8243 - val_loss: 0.4805 - val_accuracy: 0.7839 - 236ms/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "39/39 - 0s - loss: 0.3996 - accuracy: 0.8245 - val_loss: 0.4823 - val_accuracy: 0.8093 - 241ms/epoch - 6ms/step\n",
            "Epoch 86/200\n",
            "39/39 - 0s - loss: 0.4051 - accuracy: 0.8208 - val_loss: 0.4659 - val_accuracy: 0.7969 - 212ms/epoch - 5ms/step\n",
            "Epoch 87/200\n",
            "39/39 - 0s - loss: 0.4063 - accuracy: 0.8227 - val_loss: 0.5171 - val_accuracy: 0.7771 - 212ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "39/39 - 0s - loss: 0.4140 - accuracy: 0.8239 - val_loss: 0.5801 - val_accuracy: 0.7870 - 240ms/epoch - 6ms/step\n",
            "Epoch 89/200\n",
            "39/39 - 0s - loss: 0.3971 - accuracy: 0.8243 - val_loss: 0.7456 - val_accuracy: 0.7845 - 187ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "39/39 - 0s - loss: 0.4054 - accuracy: 0.8266 - val_loss: 0.5790 - val_accuracy: 0.7207 - 224ms/epoch - 6ms/step\n",
            "Epoch 91/200\n",
            "39/39 - 0s - loss: 0.4015 - accuracy: 0.8183 - val_loss: 0.5175 - val_accuracy: 0.7882 - 218ms/epoch - 6ms/step\n",
            "Epoch 92/200\n",
            "39/39 - 0s - loss: 0.3991 - accuracy: 0.8229 - val_loss: 0.5859 - val_accuracy: 0.7876 - 206ms/epoch - 5ms/step\n",
            "Epoch 93/200\n",
            "39/39 - 0s - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.6763 - val_accuracy: 0.7839 - 196ms/epoch - 5ms/step\n",
            "Epoch 94/200\n",
            "39/39 - 0s - loss: 0.4038 - accuracy: 0.8229 - val_loss: 0.4671 - val_accuracy: 0.8050 - 191ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "39/39 - 0s - loss: 0.3917 - accuracy: 0.8264 - val_loss: 0.6030 - val_accuracy: 0.7876 - 220ms/epoch - 6ms/step\n",
            "Epoch 96/200\n",
            "39/39 - 0s - loss: 0.3981 - accuracy: 0.8225 - val_loss: 0.5937 - val_accuracy: 0.7684 - 207ms/epoch - 5ms/step\n",
            "Epoch 97/200\n",
            "39/39 - 0s - loss: 0.4018 - accuracy: 0.8216 - val_loss: 0.5870 - val_accuracy: 0.7449 - 211ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "39/39 - 0s - loss: 0.3955 - accuracy: 0.8227 - val_loss: 0.6941 - val_accuracy: 0.7690 - 198ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "39/39 - 0s - loss: 0.3995 - accuracy: 0.8229 - val_loss: 0.6623 - val_accuracy: 0.7833 - 225ms/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "39/39 - 0s - loss: 0.4007 - accuracy: 0.8192 - val_loss: 0.4681 - val_accuracy: 0.8080 - 217ms/epoch - 6ms/step\n",
            "Epoch 101/200\n",
            "39/39 - 0s - loss: 0.3956 - accuracy: 0.8259 - val_loss: 0.5092 - val_accuracy: 0.7932 - 239ms/epoch - 6ms/step\n",
            "Epoch 102/200\n",
            "39/39 - 0s - loss: 0.3986 - accuracy: 0.8251 - val_loss: 0.4982 - val_accuracy: 0.7944 - 232ms/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "39/39 - 0s - loss: 0.3913 - accuracy: 0.8286 - val_loss: 0.4821 - val_accuracy: 0.7926 - 228ms/epoch - 6ms/step\n",
            "Epoch 104/200\n",
            "39/39 - 0s - loss: 0.3931 - accuracy: 0.8282 - val_loss: 0.5156 - val_accuracy: 0.7851 - 196ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "39/39 - 0s - loss: 0.3982 - accuracy: 0.8229 - val_loss: 0.6442 - val_accuracy: 0.7851 - 200ms/epoch - 5ms/step\n",
            "Epoch 106/200\n",
            "39/39 - 0s - loss: 0.3948 - accuracy: 0.8276 - val_loss: 0.5534 - val_accuracy: 0.7864 - 196ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "39/39 - 0s - loss: 0.3874 - accuracy: 0.8241 - val_loss: 0.5072 - val_accuracy: 0.7833 - 205ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "39/39 - 0s - loss: 0.3967 - accuracy: 0.8257 - val_loss: 0.8933 - val_accuracy: 0.7814 - 203ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "39/39 - 0s - loss: 0.3924 - accuracy: 0.8282 - val_loss: 0.4698 - val_accuracy: 0.8080 - 255ms/epoch - 7ms/step\n",
            "Epoch 110/200\n",
            "39/39 - 0s - loss: 0.3925 - accuracy: 0.8255 - val_loss: 0.6085 - val_accuracy: 0.8006 - 250ms/epoch - 6ms/step\n",
            "Epoch 111/200\n",
            "39/39 - 0s - loss: 0.3887 - accuracy: 0.8292 - val_loss: 0.4995 - val_accuracy: 0.7913 - 215ms/epoch - 6ms/step\n",
            "Epoch 112/200\n",
            "39/39 - 0s - loss: 0.3903 - accuracy: 0.8303 - val_loss: 0.4963 - val_accuracy: 0.7969 - 190ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "39/39 - 0s - loss: 0.3915 - accuracy: 0.8305 - val_loss: 0.6726 - val_accuracy: 0.6916 - 195ms/epoch - 5ms/step\n",
            "Epoch 114/200\n",
            "39/39 - 0s - loss: 0.3893 - accuracy: 0.8251 - val_loss: 0.4886 - val_accuracy: 0.8087 - 207ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "39/39 - 0s - loss: 0.3891 - accuracy: 0.8239 - val_loss: 0.5812 - val_accuracy: 0.7467 - 205ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "39/39 - 0s - loss: 0.3867 - accuracy: 0.8311 - val_loss: 0.6491 - val_accuracy: 0.7994 - 197ms/epoch - 5ms/step\n",
            "Epoch 117/200\n",
            "39/39 - 0s - loss: 0.3930 - accuracy: 0.8280 - val_loss: 0.5535 - val_accuracy: 0.7957 - 241ms/epoch - 6ms/step\n",
            "Epoch 118/200\n",
            "39/39 - 0s - loss: 0.3935 - accuracy: 0.8300 - val_loss: 0.6556 - val_accuracy: 0.7827 - 212ms/epoch - 5ms/step\n",
            "Epoch 119/200\n",
            "39/39 - 0s - loss: 0.3849 - accuracy: 0.8268 - val_loss: 0.5134 - val_accuracy: 0.7845 - 206ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "39/39 - 0s - loss: 0.3855 - accuracy: 0.8286 - val_loss: 0.6746 - val_accuracy: 0.7839 - 225ms/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "39/39 - 0s - loss: 0.3914 - accuracy: 0.8309 - val_loss: 0.8542 - val_accuracy: 0.7814 - 194ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "39/39 - 0s - loss: 0.3954 - accuracy: 0.8290 - val_loss: 0.5322 - val_accuracy: 0.8012 - 233ms/epoch - 6ms/step\n",
            "Epoch 123/200\n",
            "39/39 - 0s - loss: 0.3832 - accuracy: 0.8313 - val_loss: 0.5494 - val_accuracy: 0.7944 - 212ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "39/39 - 0s - loss: 0.3894 - accuracy: 0.8202 - val_loss: 0.5508 - val_accuracy: 0.7901 - 190ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "39/39 - 0s - loss: 0.3878 - accuracy: 0.8296 - val_loss: 0.4910 - val_accuracy: 0.8056 - 232ms/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "39/39 - 0s - loss: 0.3883 - accuracy: 0.8290 - val_loss: 0.5601 - val_accuracy: 0.7827 - 192ms/epoch - 5ms/step\n",
            "Epoch 127/200\n",
            "39/39 - 0s - loss: 0.3859 - accuracy: 0.8309 - val_loss: 0.5638 - val_accuracy: 0.7975 - 203ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "39/39 - 0s - loss: 0.3866 - accuracy: 0.8270 - val_loss: 0.6816 - val_accuracy: 0.7672 - 247ms/epoch - 6ms/step\n",
            "Epoch 129/200\n",
            "39/39 - 0s - loss: 0.3913 - accuracy: 0.8313 - val_loss: 0.5599 - val_accuracy: 0.7864 - 192ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "39/39 - 0s - loss: 0.3859 - accuracy: 0.8245 - val_loss: 0.5671 - val_accuracy: 0.7820 - 199ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "39/39 - 0s - loss: 0.3779 - accuracy: 0.8329 - val_loss: 0.7205 - val_accuracy: 0.6774 - 193ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "39/39 - 0s - loss: 0.3824 - accuracy: 0.8266 - val_loss: 0.5885 - val_accuracy: 0.8006 - 197ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "39/39 - 0s - loss: 0.3781 - accuracy: 0.8327 - val_loss: 0.7055 - val_accuracy: 0.6731 - 208ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "39/39 - 0s - loss: 0.3907 - accuracy: 0.8259 - val_loss: 0.5252 - val_accuracy: 0.7932 - 187ms/epoch - 5ms/step\n",
            "Epoch 135/200\n",
            "39/39 - 0s - loss: 0.3814 - accuracy: 0.8292 - val_loss: 0.5576 - val_accuracy: 0.7765 - 192ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "39/39 - 0s - loss: 0.3823 - accuracy: 0.8272 - val_loss: 0.5069 - val_accuracy: 0.7988 - 202ms/epoch - 5ms/step\n",
            "Epoch 137/200\n",
            "39/39 - 0s - loss: 0.3740 - accuracy: 0.8294 - val_loss: 0.5717 - val_accuracy: 0.7808 - 203ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "39/39 - 0s - loss: 0.3831 - accuracy: 0.8311 - val_loss: 0.5884 - val_accuracy: 0.7406 - 244ms/epoch - 6ms/step\n",
            "Epoch 139/200\n",
            "39/39 - 0s - loss: 0.3779 - accuracy: 0.8268 - val_loss: 0.6942 - val_accuracy: 0.7802 - 187ms/epoch - 5ms/step\n",
            "Epoch 140/200\n",
            "39/39 - 0s - loss: 0.3817 - accuracy: 0.8272 - val_loss: 0.5888 - val_accuracy: 0.7944 - 181ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "39/39 - 0s - loss: 0.3810 - accuracy: 0.8315 - val_loss: 0.5120 - val_accuracy: 0.8062 - 192ms/epoch - 5ms/step\n",
            "Epoch 142/200\n",
            "39/39 - 0s - loss: 0.3764 - accuracy: 0.8303 - val_loss: 0.5226 - val_accuracy: 0.7950 - 231ms/epoch - 6ms/step\n",
            "Epoch 143/200\n",
            "39/39 - 0s - loss: 0.3742 - accuracy: 0.8274 - val_loss: 0.6425 - val_accuracy: 0.7932 - 234ms/epoch - 6ms/step\n",
            "Epoch 144/200\n",
            "39/39 - 0s - loss: 0.4011 - accuracy: 0.8315 - val_loss: 0.5626 - val_accuracy: 0.7938 - 192ms/epoch - 5ms/step\n",
            "Epoch 145/200\n",
            "39/39 - 0s - loss: 0.3855 - accuracy: 0.8307 - val_loss: 0.5930 - val_accuracy: 0.7802 - 195ms/epoch - 5ms/step\n",
            "Epoch 146/200\n",
            "39/39 - 0s - loss: 0.3847 - accuracy: 0.8253 - val_loss: 0.6950 - val_accuracy: 0.6848 - 201ms/epoch - 5ms/step\n",
            "Epoch 147/200\n",
            "39/39 - 0s - loss: 0.3830 - accuracy: 0.8303 - val_loss: 0.5402 - val_accuracy: 0.7994 - 194ms/epoch - 5ms/step\n",
            "Epoch 148/200\n",
            "39/39 - 0s - loss: 0.3699 - accuracy: 0.8298 - val_loss: 0.5892 - val_accuracy: 0.7827 - 193ms/epoch - 5ms/step\n",
            "Epoch 149/200\n",
            "39/39 - 0s - loss: 0.3773 - accuracy: 0.8337 - val_loss: 0.7559 - val_accuracy: 0.7833 - 194ms/epoch - 5ms/step\n",
            "Epoch 150/200\n",
            "39/39 - 0s - loss: 0.3835 - accuracy: 0.8300 - val_loss: 0.5123 - val_accuracy: 0.8050 - 191ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "39/39 - 0s - loss: 0.3828 - accuracy: 0.8282 - val_loss: 0.5589 - val_accuracy: 0.8012 - 195ms/epoch - 5ms/step\n",
            "Epoch 152/200\n",
            "39/39 - 0s - loss: 0.3814 - accuracy: 0.8319 - val_loss: 0.5804 - val_accuracy: 0.7882 - 230ms/epoch - 6ms/step\n",
            "Epoch 153/200\n",
            "39/39 - 0s - loss: 0.3775 - accuracy: 0.8317 - val_loss: 0.6552 - val_accuracy: 0.7666 - 204ms/epoch - 5ms/step\n",
            "Epoch 154/200\n",
            "39/39 - 0s - loss: 0.3790 - accuracy: 0.8278 - val_loss: 0.5405 - val_accuracy: 0.7882 - 189ms/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "39/39 - 0s - loss: 0.3776 - accuracy: 0.8323 - val_loss: 0.6350 - val_accuracy: 0.7851 - 227ms/epoch - 6ms/step\n",
            "Epoch 156/200\n",
            "39/39 - 0s - loss: 0.3694 - accuracy: 0.8397 - val_loss: 0.5771 - val_accuracy: 0.7895 - 222ms/epoch - 6ms/step\n",
            "Epoch 157/200\n",
            "39/39 - 0s - loss: 0.3774 - accuracy: 0.8305 - val_loss: 0.6192 - val_accuracy: 0.7839 - 183ms/epoch - 5ms/step\n",
            "Epoch 158/200\n",
            "39/39 - 0s - loss: 0.3784 - accuracy: 0.8276 - val_loss: 0.5174 - val_accuracy: 0.7882 - 244ms/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "39/39 - 0s - loss: 0.3748 - accuracy: 0.8335 - val_loss: 0.5427 - val_accuracy: 0.7926 - 201ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "39/39 - 0s - loss: 0.3758 - accuracy: 0.8327 - val_loss: 0.5654 - val_accuracy: 0.7895 - 193ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "39/39 - 0s - loss: 0.3735 - accuracy: 0.8300 - val_loss: 0.5118 - val_accuracy: 0.8037 - 230ms/epoch - 6ms/step\n",
            "Epoch 162/200\n",
            "39/39 - 0s - loss: 0.3754 - accuracy: 0.8337 - val_loss: 0.6074 - val_accuracy: 0.7647 - 192ms/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "39/39 - 0s - loss: 0.3864 - accuracy: 0.8266 - val_loss: 0.5381 - val_accuracy: 0.7833 - 234ms/epoch - 6ms/step\n",
            "Epoch 164/200\n",
            "39/39 - 0s - loss: 0.3693 - accuracy: 0.8374 - val_loss: 0.5447 - val_accuracy: 0.7808 - 239ms/epoch - 6ms/step\n",
            "Epoch 165/200\n",
            "39/39 - 0s - loss: 0.3721 - accuracy: 0.8331 - val_loss: 0.6545 - val_accuracy: 0.8087 - 190ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "39/39 - 0s - loss: 0.3678 - accuracy: 0.8350 - val_loss: 0.5351 - val_accuracy: 0.7876 - 223ms/epoch - 6ms/step\n",
            "Epoch 167/200\n",
            "39/39 - 0s - loss: 0.3697 - accuracy: 0.8342 - val_loss: 0.5446 - val_accuracy: 0.7889 - 239ms/epoch - 6ms/step\n",
            "Epoch 168/200\n",
            "39/39 - 0s - loss: 0.3685 - accuracy: 0.8358 - val_loss: 0.5877 - val_accuracy: 0.7851 - 229ms/epoch - 6ms/step\n",
            "Epoch 169/200\n",
            "39/39 - 0s - loss: 0.3740 - accuracy: 0.8370 - val_loss: 0.6003 - val_accuracy: 0.7659 - 197ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "39/39 - 0s - loss: 0.3681 - accuracy: 0.8348 - val_loss: 0.5982 - val_accuracy: 0.7950 - 236ms/epoch - 6ms/step\n",
            "Epoch 171/200\n",
            "39/39 - 0s - loss: 0.3725 - accuracy: 0.8317 - val_loss: 0.5593 - val_accuracy: 0.7975 - 239ms/epoch - 6ms/step\n",
            "Epoch 172/200\n",
            "39/39 - 0s - loss: 0.3699 - accuracy: 0.8376 - val_loss: 0.5728 - val_accuracy: 0.7889 - 193ms/epoch - 5ms/step\n",
            "Epoch 173/200\n",
            "39/39 - 0s - loss: 0.3608 - accuracy: 0.8405 - val_loss: 0.5798 - val_accuracy: 0.7889 - 191ms/epoch - 5ms/step\n",
            "Epoch 174/200\n",
            "39/39 - 0s - loss: 0.3723 - accuracy: 0.8342 - val_loss: 0.6122 - val_accuracy: 0.7882 - 191ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "39/39 - 0s - loss: 0.3745 - accuracy: 0.8298 - val_loss: 0.5728 - val_accuracy: 0.7994 - 202ms/epoch - 5ms/step\n",
            "Epoch 176/200\n",
            "39/39 - 0s - loss: 0.3709 - accuracy: 0.8305 - val_loss: 0.5420 - val_accuracy: 0.8099 - 195ms/epoch - 5ms/step\n",
            "Epoch 177/200\n",
            "39/39 - 0s - loss: 0.3775 - accuracy: 0.8395 - val_loss: 0.6610 - val_accuracy: 0.7882 - 215ms/epoch - 6ms/step\n",
            "Epoch 178/200\n",
            "39/39 - 0s - loss: 0.3680 - accuracy: 0.8370 - val_loss: 0.6116 - val_accuracy: 0.7882 - 189ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "39/39 - 0s - loss: 0.3692 - accuracy: 0.8337 - val_loss: 0.6227 - val_accuracy: 0.7474 - 228ms/epoch - 6ms/step\n",
            "Epoch 180/200\n",
            "39/39 - 0s - loss: 0.3717 - accuracy: 0.8329 - val_loss: 0.5858 - val_accuracy: 0.7851 - 200ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "39/39 - 0s - loss: 0.3702 - accuracy: 0.8364 - val_loss: 0.5410 - val_accuracy: 0.7845 - 192ms/epoch - 5ms/step\n",
            "Epoch 182/200\n",
            "39/39 - 0s - loss: 0.3625 - accuracy: 0.8381 - val_loss: 0.5476 - val_accuracy: 0.7932 - 196ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "39/39 - 0s - loss: 0.3689 - accuracy: 0.8360 - val_loss: 0.5938 - val_accuracy: 0.7926 - 238ms/epoch - 6ms/step\n",
            "Epoch 184/200\n",
            "39/39 - 0s - loss: 0.3690 - accuracy: 0.8356 - val_loss: 0.7160 - val_accuracy: 0.7889 - 210ms/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "39/39 - 0s - loss: 0.3683 - accuracy: 0.8348 - val_loss: 0.5777 - val_accuracy: 0.8087 - 192ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "39/39 - 0s - loss: 0.3644 - accuracy: 0.8364 - val_loss: 0.5597 - val_accuracy: 0.7901 - 231ms/epoch - 6ms/step\n",
            "Epoch 187/200\n",
            "39/39 - 0s - loss: 0.3681 - accuracy: 0.8317 - val_loss: 0.6330 - val_accuracy: 0.7777 - 205ms/epoch - 5ms/step\n",
            "Epoch 188/200\n",
            "39/39 - 0s - loss: 0.3681 - accuracy: 0.8344 - val_loss: 0.6768 - val_accuracy: 0.7858 - 240ms/epoch - 6ms/step\n",
            "Epoch 189/200\n",
            "39/39 - 0s - loss: 0.3712 - accuracy: 0.8339 - val_loss: 0.5967 - val_accuracy: 0.7777 - 230ms/epoch - 6ms/step\n",
            "Epoch 190/200\n",
            "39/39 - 0s - loss: 0.3676 - accuracy: 0.8288 - val_loss: 0.5431 - val_accuracy: 0.7988 - 239ms/epoch - 6ms/step\n",
            "Epoch 191/200\n",
            "39/39 - 0s - loss: 0.3704 - accuracy: 0.8342 - val_loss: 0.6213 - val_accuracy: 0.7740 - 192ms/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "39/39 - 0s - loss: 0.3711 - accuracy: 0.8342 - val_loss: 0.5273 - val_accuracy: 0.8062 - 221ms/epoch - 6ms/step\n",
            "Epoch 193/200\n",
            "39/39 - 0s - loss: 0.3669 - accuracy: 0.8325 - val_loss: 0.5578 - val_accuracy: 0.8050 - 188ms/epoch - 5ms/step\n",
            "Epoch 194/200\n",
            "39/39 - 0s - loss: 0.3590 - accuracy: 0.8364 - val_loss: 0.5835 - val_accuracy: 0.7709 - 191ms/epoch - 5ms/step\n",
            "Epoch 195/200\n",
            "39/39 - 0s - loss: 0.3740 - accuracy: 0.8315 - val_loss: 0.5273 - val_accuracy: 0.7950 - 189ms/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "39/39 - 0s - loss: 0.3665 - accuracy: 0.8309 - val_loss: 0.5674 - val_accuracy: 0.8080 - 198ms/epoch - 5ms/step\n",
            "Epoch 197/200\n",
            "39/39 - 0s - loss: 0.3597 - accuracy: 0.8409 - val_loss: 0.5229 - val_accuracy: 0.8111 - 230ms/epoch - 6ms/step\n",
            "Epoch 198/200\n",
            "39/39 - 0s - loss: 0.3663 - accuracy: 0.8321 - val_loss: 0.6825 - val_accuracy: 0.7424 - 213ms/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "39/39 - 0s - loss: 0.3681 - accuracy: 0.8337 - val_loss: 0.5790 - val_accuracy: 0.7994 - 193ms/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "39/39 - 0s - loss: 0.3695 - accuracy: 0.8362 - val_loss: 0.5642 - val_accuracy: 0.8229 - 195ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Classification Model 2 and Final Values"
      ],
      "metadata": {
        "id": "Ug0InJvL07v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl2.history['val_loss']) + 1), history_clasmodl2.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl2.history['loss']) + 1), history_clasmodl2.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl2.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl2.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl2.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl2.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "pSEQkTqp1HRn",
        "outputId": "ada58485-c764-44e4-b95c-406fe4f9fa8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.3695135712623596 \n",
            "Final Training Accuracy:  0.8362069129943848\n",
            "Final Validation loss:  0.5642444491386414 \n",
            "Final Validation Accuracy:  0.8229101896286011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.3 Classification Model 3 (clasmodl3)"
      ],
      "metadata": {
        "id": "aH9nWFQq2zd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.input_layer import Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_clasmodl3():\n",
        "  clasmodl3 = keras.Sequential(\n",
        "      [\n",
        "        layers.Dense(512, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(30, activation = 'relu'),\n",
        "        layers.Dense(100, activation = 'relu'),\n",
        "        layers.Dense(4, activation = 'softmax')\n",
        "      ]\n",
        ")\n",
        "  clasmodl3.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return clasmodl3\n",
        "\n",
        "clasmodl3 = build_clasmodl3()\n",
        "history_clasmodl3 = clasmodl3.fit(x = Xtrain,y = one_hot_train_labels, batch_size = 128, epochs = 50, verbose = 2, validation_data = (Xval,one_hot_val_labels), validation_freq = 1)\n",
        "clasmodl3.save('my_clasmodl3.h5')\n",
        "\n",
        "#clasmodl3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbNm6nJG3mBE",
        "outputId": "66940e42-5a2e-4939-9bd3-9ddfe2ab70bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "39/39 - 1s - loss: 0.8338 - accuracy: 0.7488 - val_loss: 0.6245 - val_accuracy: 0.7839 - 1s/epoch - 29ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.6102 - accuracy: 0.7904 - val_loss: 0.6061 - val_accuracy: 0.7839 - 231ms/epoch - 6ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.5699 - accuracy: 0.7921 - val_loss: 0.7504 - val_accuracy: 0.7839 - 180ms/epoch - 5ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.5323 - accuracy: 0.8025 - val_loss: 0.8990 - val_accuracy: 0.7839 - 236ms/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.5366 - accuracy: 0.8030 - val_loss: 0.8148 - val_accuracy: 0.7839 - 241ms/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.5282 - accuracy: 0.8040 - val_loss: 0.5793 - val_accuracy: 0.7845 - 206ms/epoch - 5ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.5193 - accuracy: 0.8034 - val_loss: 0.5680 - val_accuracy: 0.7839 - 196ms/epoch - 5ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.5291 - accuracy: 0.7935 - val_loss: 0.8936 - val_accuracy: 0.7839 - 235ms/epoch - 6ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.5391 - accuracy: 0.7960 - val_loss: 0.5577 - val_accuracy: 0.7839 - 231ms/epoch - 6ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.5061 - accuracy: 0.8036 - val_loss: 0.7804 - val_accuracy: 0.7839 - 214ms/epoch - 5ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.5115 - accuracy: 0.8030 - val_loss: 0.5670 - val_accuracy: 0.7839 - 195ms/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.5036 - accuracy: 0.8021 - val_loss: 0.7878 - val_accuracy: 0.7876 - 235ms/epoch - 6ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.5053 - accuracy: 0.8038 - val_loss: 0.7321 - val_accuracy: 0.7406 - 203ms/epoch - 5ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.5001 - accuracy: 0.8011 - val_loss: 0.6760 - val_accuracy: 0.7839 - 293ms/epoch - 8ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.4970 - accuracy: 0.8028 - val_loss: 0.6096 - val_accuracy: 0.7839 - 432ms/epoch - 11ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.4878 - accuracy: 0.8038 - val_loss: 0.8342 - val_accuracy: 0.7839 - 367ms/epoch - 9ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.4846 - accuracy: 0.8046 - val_loss: 0.5524 - val_accuracy: 0.7839 - 241ms/epoch - 6ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.4840 - accuracy: 0.8032 - val_loss: 0.7001 - val_accuracy: 0.7839 - 398ms/epoch - 10ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.4849 - accuracy: 0.8040 - val_loss: 0.5590 - val_accuracy: 0.7839 - 441ms/epoch - 11ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.4763 - accuracy: 0.7952 - val_loss: 0.6222 - val_accuracy: 0.7740 - 318ms/epoch - 8ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.4757 - accuracy: 0.8032 - val_loss: 1.2643 - val_accuracy: 0.7839 - 191ms/epoch - 5ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.4816 - accuracy: 0.8048 - val_loss: 0.6566 - val_accuracy: 0.7839 - 484ms/epoch - 12ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.4737 - accuracy: 0.8019 - val_loss: 0.8732 - val_accuracy: 0.7845 - 412ms/epoch - 11ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.4665 - accuracy: 0.8067 - val_loss: 0.5280 - val_accuracy: 0.7616 - 229ms/epoch - 6ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.4651 - accuracy: 0.8021 - val_loss: 0.5675 - val_accuracy: 0.7839 - 193ms/epoch - 5ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.4622 - accuracy: 0.8028 - val_loss: 0.7413 - val_accuracy: 0.7839 - 233ms/epoch - 6ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.4546 - accuracy: 0.8048 - val_loss: 0.6302 - val_accuracy: 0.6885 - 200ms/epoch - 5ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.4633 - accuracy: 0.7995 - val_loss: 1.4571 - val_accuracy: 0.7839 - 234ms/epoch - 6ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.4725 - accuracy: 0.8064 - val_loss: 0.5596 - val_accuracy: 0.7065 - 213ms/epoch - 5ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.4566 - accuracy: 0.7980 - val_loss: 0.5702 - val_accuracy: 0.7839 - 198ms/epoch - 5ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.4490 - accuracy: 0.8085 - val_loss: 0.5155 - val_accuracy: 0.7845 - 234ms/epoch - 6ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.4558 - accuracy: 0.8032 - val_loss: 0.5917 - val_accuracy: 0.7839 - 192ms/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.4450 - accuracy: 0.8064 - val_loss: 0.5047 - val_accuracy: 0.7864 - 189ms/epoch - 5ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.4469 - accuracy: 0.8042 - val_loss: 0.5820 - val_accuracy: 0.7851 - 240ms/epoch - 6ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.4481 - accuracy: 0.8087 - val_loss: 1.0176 - val_accuracy: 0.7839 - 227ms/epoch - 6ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.4509 - accuracy: 0.8114 - val_loss: 0.6040 - val_accuracy: 0.7263 - 231ms/epoch - 6ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.4495 - accuracy: 0.8060 - val_loss: 0.4794 - val_accuracy: 0.7932 - 206ms/epoch - 5ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.4445 - accuracy: 0.8106 - val_loss: 0.4954 - val_accuracy: 0.7913 - 234ms/epoch - 6ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.4382 - accuracy: 0.8091 - val_loss: 0.5353 - val_accuracy: 0.7628 - 255ms/epoch - 7ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.4430 - accuracy: 0.8011 - val_loss: 0.4949 - val_accuracy: 0.8031 - 232ms/epoch - 6ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.4384 - accuracy: 0.8103 - val_loss: 0.5262 - val_accuracy: 0.7771 - 200ms/epoch - 5ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.4370 - accuracy: 0.8087 - val_loss: 0.6245 - val_accuracy: 0.7845 - 238ms/epoch - 6ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.4385 - accuracy: 0.8097 - val_loss: 0.6020 - val_accuracy: 0.6985 - 234ms/epoch - 6ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.4387 - accuracy: 0.8048 - val_loss: 0.8508 - val_accuracy: 0.7845 - 194ms/epoch - 5ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.4382 - accuracy: 0.8085 - val_loss: 0.4711 - val_accuracy: 0.7870 - 205ms/epoch - 5ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.4284 - accuracy: 0.8103 - val_loss: 0.7830 - val_accuracy: 0.7839 - 221ms/epoch - 6ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.4343 - accuracy: 0.8134 - val_loss: 0.4860 - val_accuracy: 0.7845 - 219ms/epoch - 6ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.4340 - accuracy: 0.8112 - val_loss: 0.6130 - val_accuracy: 0.7845 - 211ms/epoch - 5ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.4246 - accuracy: 0.8108 - val_loss: 0.5150 - val_accuracy: 0.7864 - 191ms/epoch - 5ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.4317 - accuracy: 0.8128 - val_loss: 0.4793 - val_accuracy: 0.7882 - 215ms/epoch - 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots for Classification Model 3 and Final Values"
      ],
      "metadata": {
        "id": "nCo55yH45zx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training loss\n",
        "plt.plot(range(1, len(history_clasmodl3.history['val_loss']) + 1), history_clasmodl3.history['val_loss'], 'go', label = \"Validation Loss\")\n",
        "plt.plot(range(1, len(history_clasmodl3.history['loss']) + 1), history_clasmodl3.history['loss'],label = \"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Final Values\n",
        "print(\"Final Training loss: \",history_clasmodl3.history['loss'][-1],\"\\nFinal Training Accuracy: \", history_clasmodl3.history['accuracy'][-1])\n",
        "print(\"Final Validation loss: \",history_clasmodl3.history['val_loss'][-1],\"\\nFinal Validation Accuracy: \", history_clasmodl3.history['val_accuracy'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "T5K4Hirh55WY",
        "outputId": "dd482a7b-c6e0-4af7-e29c-a8dad2498613"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Training loss:  0.4316848814487457 \n",
            "Final Training Accuracy:  0.8128078579902649\n",
            "Final Validation loss:  0.4793102443218231 \n",
            "Final Validation Accuracy:  0.7882353067398071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting the Output"
      ],
      "metadata": {
        "id": "ktMf2VVrARVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the activation and inputting it alongside the targets\n",
        "# into the predict_table \n",
        "from pandas.core.arrays.sparse import dtype\n",
        "predict_labels = clasmodl3.predict(Xtst)\n",
        "predict_table = pd.DataFrame(Xtst)\n",
        "predict_table[\"activation\"]=[predict_labels[x,:] for x in range(len(predict_labels))]\n",
        "predict_table[\"target\"]=[one_hot_tst_labels[x,:] for x in range(len(one_hot_tst_labels))]\n",
        "predict_labels = np.around(predict_labels)\n",
        "# Checking which activations match their target i.e accuracy\n",
        "check = np.empty((10,4), dtype=bool)\n",
        "hits = []\n",
        "for i in range(len(predict_labels)):\n",
        "  check[i,:] = predict_labels[i,:] == one_hot_tst_labels[i,:] \n",
        "  if (np.count_nonzero(check[i,:]) == 4):\n",
        "    hits.append(\"Hit\")\n",
        "  else:\n",
        "    hits.append(\"Missed\")\n",
        "predict_table[\"accuracy\"] = hits\n",
        "\n",
        "# Renaming the columns of the table\n",
        "predict_table.columns.values[0] = \"f1\"\n",
        "predict_table.columns.values[1] = \"f2\"\n",
        "predict_table.columns.values[2] = \"f3\"\n",
        "predict_table.columns.values[3] = \"f4\"\n",
        "predict_table.columns.values[4] = \"f5\"\n",
        "predict_table.columns.values[5] = \"f6\"\n",
        "predict_table.columns.values[6] = \"f7\"\n",
        "predict_table.columns.values[7] = \"f8\"\n",
        "predict_table.columns.values[8] = \"f9\"\n",
        "predict_table.columns.values[9] = \"f10\"\n",
        "predict_table.columns.values[10] = \"f11\"\n",
        "predict_table.columns.values[11] = \"f12\"\n",
        "display(predict_table)"
      ],
      "metadata": {
        "id": "uA_kLXhgDF-s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "d8cbc8bd-8e4e-4aa7-c9cf-c8f8e210195c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b46c94e-3e0a-4ea7-8954-f447867cfcdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>activation</th>\n",
              "      <th>target</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.20</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.049</td>\n",
              "      <td>44.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.44</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0010848407, 0.9573048, 0.041609883, 6.24627...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>16.3</td>\n",
              "      <td>0.038</td>\n",
              "      <td>43.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>0.99924</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.41</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[6.786809e-06, 0.9801516, 0.019841518, 1.14908...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.034</td>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.98815</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.50</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0016311877, 0.5857639, 0.4092513, 0.0033536...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>Missed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.045</td>\n",
              "      <td>19.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.49</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[0.0010622812, 0.93931246, 0.05961919, 6.09281...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.8</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.055</td>\n",
              "      <td>47.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>0.99340</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.45</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.00043470034, 0.9150235, 0.08454132, 4.32676...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.33</td>\n",
              "      <td>10.1</td>\n",
              "      <td>0.043</td>\n",
              "      <td>28.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.52</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.003761721, 0.906404, 0.08975945, 7.4819094e...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.9</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.027</td>\n",
              "      <td>35.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.98945</td>\n",
              "      <td>3.37</td>\n",
              "      <td>0.42</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.00018569552, 0.62310886, 0.37645802, 0.0002...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.036</td>\n",
              "      <td>42.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>0.99018</td>\n",
              "      <td>3.04</td>\n",
              "      <td>0.64</td>\n",
              "      <td>11.733333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0006020492, 0.5680213, 0.42969406, 0.001682...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.32</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.062</td>\n",
              "      <td>31.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99728</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.65</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[0.0002626776, 0.83705467, 0.16262574, 5.69911...</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
              "      <td>Missed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.22</td>\n",
              "      <td>10.7</td>\n",
              "      <td>0.042</td>\n",
              "      <td>26.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.99540</td>\n",
              "      <td>2.86</td>\n",
              "      <td>0.36</td>\n",
              "      <td>9.700000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.0023069573, 0.86245453, 0.13375148, 0.00148...</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>Hit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b46c94e-3e0a-4ea7-8954-f447867cfcdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b46c94e-3e0a-4ea7-8954-f447867cfcdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b46c94e-3e0a-4ea7-8954-f447867cfcdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    f1    f2    f3    f4     f5    f6     f7       f8    f9   f10        f11  \\\n",
              "0  7.4  0.44  0.20  11.5  0.049  44.0  157.0  0.99800  3.27  0.44   9.000000   \n",
              "1  6.5  0.23  0.36  16.3  0.038  43.0  133.0  0.99924  3.26  0.41   8.800000   \n",
              "2  5.6  0.41  0.24   1.9  0.034  10.0   53.0  0.98815  3.32  0.50  13.500000   \n",
              "3  6.4  0.67  0.08   2.1  0.045  19.0   48.0  0.99490  3.49  0.49  11.400000   \n",
              "4  6.8  0.18  0.37   1.6  0.055  47.0  154.0  0.99340  3.08  0.45   9.100000   \n",
              "5  6.9  0.41  0.33  10.1  0.043  28.0  152.0  0.99680  3.20  0.52   9.400000   \n",
              "6  5.9  0.32  0.33   2.1  0.027  35.0  138.0  0.98945  3.37  0.42  12.700000   \n",
              "7  6.0  0.24  0.41   1.3  0.036  42.0  118.0  0.99018  3.04  0.64  11.733333   \n",
              "8  7.3  0.48  0.32   2.1  0.062  31.0   54.0  0.99728  3.30  0.65  10.000000   \n",
              "9  7.4  0.24  0.22  10.7  0.042  26.0   81.0  0.99540  2.86  0.36   9.700000   \n",
              "\n",
              "   f12                                         activation  \\\n",
              "0  0.0  [0.0010848407, 0.9573048, 0.041609883, 6.24627...   \n",
              "1  0.0  [6.786809e-06, 0.9801516, 0.019841518, 1.14908...   \n",
              "2  0.0  [0.0016311877, 0.5857639, 0.4092513, 0.0033536...   \n",
              "3  1.0  [0.0010622812, 0.93931246, 0.05961919, 6.09281...   \n",
              "4  0.0  [0.00043470034, 0.9150235, 0.08454132, 4.32676...   \n",
              "5  0.0  [0.003761721, 0.906404, 0.08975945, 7.4819094e...   \n",
              "6  0.0  [0.00018569552, 0.62310886, 0.37645802, 0.0002...   \n",
              "7  0.0  [0.0006020492, 0.5680213, 0.42969406, 0.001682...   \n",
              "8  1.0  [0.0002626776, 0.83705467, 0.16262574, 5.69911...   \n",
              "9  0.0  [0.0023069573, 0.86245453, 0.13375148, 0.00148...   \n",
              "\n",
              "                 target accuracy  \n",
              "0  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "1  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "2  [0.0, 0.0, 1.0, 0.0]   Missed  \n",
              "3  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "4  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "5  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "6  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "7  [0.0, 1.0, 0.0, 0.0]      Hit  \n",
              "8  [0.0, 0.0, 1.0, 0.0]   Missed  \n",
              "9  [0.0, 1.0, 0.0, 0.0]      Hit  "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}